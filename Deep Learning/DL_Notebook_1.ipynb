{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffe4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7d7d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tensorflow:\n",
      "\n",
      "NAME\n",
      "    tensorflow\n",
      "\n",
      "DESCRIPTION\n",
      "    Top-level module of TensorFlow. By convention, we refer to this module as\n",
      "    `tf` instead of `tensorflow`, following the common practice of importing\n",
      "    TensorFlow via the command `import tensorflow as tf`.\n",
      "    \n",
      "    The primary function of this module is to import all of the public TensorFlow\n",
      "    interfaces into a single place. The interfaces themselves are located in\n",
      "    sub-modules, as described below.\n",
      "    \n",
      "    Note that the file `__init__.py` in the TensorFlow source code tree is actually\n",
      "    only a placeholder to enable test cases to run. The TensorFlow build replaces\n",
      "    this file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __internal__ (package)\n",
      "    __operators__ (package)\n",
      "    _api (package)\n",
      "    audio (package)\n",
      "    autodiff (package)\n",
      "    autograph (package)\n",
      "    bitwise (package)\n",
      "    compat (package)\n",
      "    compiler (package)\n",
      "    config (package)\n",
      "    core (package)\n",
      "    data (package)\n",
      "    debugging (package)\n",
      "    distribute (package)\n",
      "    dtensor (package)\n",
      "    dtypes (package)\n",
      "    errors (package)\n",
      "    estimator (package)\n",
      "    experimental (package)\n",
      "    feature_column (package)\n",
      "    graph_util (package)\n",
      "    image (package)\n",
      "    io (package)\n",
      "    keras (package)\n",
      "    linalg (package)\n",
      "    lite (package)\n",
      "    lookup (package)\n",
      "    math (package)\n",
      "    mlir (package)\n",
      "    nest (package)\n",
      "    nn (package)\n",
      "    profiler (package)\n",
      "    python (package)\n",
      "    quantization (package)\n",
      "    queue (package)\n",
      "    ragged (package)\n",
      "    random (package)\n",
      "    raw_ops (package)\n",
      "    saved_model (package)\n",
      "    security (package)\n",
      "    sets (package)\n",
      "    signal (package)\n",
      "    sparse (package)\n",
      "    strings (package)\n",
      "    summary (package)\n",
      "    sysconfig (package)\n",
      "    test (package)\n",
      "    tools (package)\n",
      "    tpu (package)\n",
      "    train (package)\n",
      "    tsl (package)\n",
      "    types (package)\n",
      "    v2\n",
      "    version (package)\n",
      "    xla (package)\n",
      "\n",
      "SUBMODULES\n",
      "    _API_MODULE\n",
      "    _compat\n",
      "    _fi\n",
      "    _ll\n",
      "    _module_util\n",
      "    _tf2\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        tensorflow.python.eager.backprop.GradientTape\n",
      "        tensorflow.python.framework.device_spec.DeviceSpecV2\n",
      "        tensorflow.python.framework.ops.RegisterGradient\n",
      "        tensorflow.python.framework.ops.name_scope_v2\n",
      "        tensorflow.python.ops.critical_section_ops.CriticalSection\n",
      "        tensorflow.python.ops.gradients_util.AggregationMethod\n",
      "        tensorflow.python.ops.tensor_array_ops.TensorArray\n",
      "    enum.Enum(builtins.object)\n",
      "        tensorflow.python.ops.unconnected_gradients.UnconnectedGradients\n",
      "        tensorflow.python.ops.variables.VariableAggregationV2\n",
      "        tensorflow.python.ops.variables.VariableSynchronization\n",
      "    tensorflow.core.function.trace_type.serialization.Serializable(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.client._pywrap_tf_session.PyGraph(builtins.object)\n",
      "        tensorflow.python.framework.ops.Graph\n",
      "    tensorflow.python.client._pywrap_tf_session.PyOperation(builtins.object)\n",
      "        tensorflow.python.framework.ops.Operation\n",
      "    tensorflow.python.client._pywrap_tf_session.PyTensor(builtins.object)\n",
      "        tensorflow.python.framework.ops.Tensor(tensorflow.python.client._pywrap_tf_session.PyTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "    tensorflow.python.framework._dtypes.DType(pybind11_builtins.pybind11_object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "    tensorflow.python.framework.composite_tensor.CompositeTensor(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject)\n",
      "    tensorflow.python.framework.tensor.DenseSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.framework.type_spec.BatchableTypeSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorSpec\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec\n",
      "    tensorflow.python.ops.init_ops_v2.Initializer(builtins.object)\n",
      "        tensorflow.python.ops.init_ops_v2.Constant\n",
      "        tensorflow.python.ops.init_ops_v2.Ones\n",
      "        tensorflow.python.ops.init_ops_v2.RandomNormal\n",
      "        tensorflow.python.ops.init_ops_v2.RandomUniform\n",
      "        tensorflow.python.ops.init_ops_v2.Zeros\n",
      "    tensorflow.python.trackable.autotrackable.AutoTrackable(tensorflow.python.trackable.base.Trackable)\n",
      "        tensorflow.python.module.module.Module\n",
      "    tensorflow.python.trackable.base.Trackable(builtins.object)\n",
      "        tensorflow.python.ops.variables.Variable\n",
      "    tensorflow.python.types.core.Symbol(tensorflow.python.types.core.Tensor)\n",
      "        tensorflow.python.framework.ops.Tensor(tensorflow.python.client._pywrap_tf_session.PyTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "    tensorflow.python.types.internal.IndexedSlices(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "    tensorflow.python.types.internal.NativeObject(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.ops.Tensor(tensorflow.python.client._pywrap_tf_session.PyTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject)\n",
      "    tensorflow.python.types.internal.TensorSpec(builtins.object)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.types.internal.TypeSpec(builtins.object)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.types.trace.TraceType(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    \n",
      "    class AggregationMethod(builtins.object)\n",
      "     |  A class listing aggregation methods used to combine gradients.\n",
      "     |  \n",
      "     |  Computing partial derivatives can require aggregating gradient\n",
      "     |  contributions. This class lists the various methods that can\n",
      "     |  be used to combine gradients in the graph.\n",
      "     |  \n",
      "     |  The following aggregation methods are part of the stable API for\n",
      "     |  aggregating gradients:\n",
      "     |  \n",
      "     |  *  `ADD_N`: All of the gradient terms are summed as part of one\n",
      "     |     operation using the \"AddN\" op (see `tf.add_n`). This\n",
      "     |     method has the property that all gradients must be ready and\n",
      "     |     buffered separately in memory before any aggregation is performed.\n",
      "     |  *  `DEFAULT`: The system-chosen default aggregation method.\n",
      "     |  \n",
      "     |  The following aggregation methods are experimental and may not\n",
      "     |  be supported in future releases:\n",
      "     |  \n",
      "     |  * `EXPERIMENTAL_TREE`: Gradient terms are summed in pairs using\n",
      "     |    the \"AddN\" op. This method of summing gradients may reduce\n",
      "     |    performance, but it can improve memory utilization because the\n",
      "     |    gradients can be released earlier.\n",
      "     |  * `EXPERIMENTAL_ACCUMULATE_N`: Same as `EXPERIMENTAL_TREE`.\n",
      "     |  \n",
      "     |  Example usage when computing gradient:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def example():\n",
      "     |  ...   x = tf.constant(1.0)\n",
      "     |  ...   y = x * 2.0\n",
      "     |  ...   z = y + y + y + y\n",
      "     |  ...   return tf.gradients(z, [x, y],\n",
      "     |  ...     aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n",
      "     |  >>> example()\n",
      "     |  [<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
      "     |   <tf.Tensor: shape=(), dtype=float32, numpy=4.0>]\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADD_N = 0\n",
      "     |  \n",
      "     |  DEFAULT = 0\n",
      "     |  \n",
      "     |  EXPERIMENTAL_ACCUMULATE_N = 2\n",
      "     |  \n",
      "     |  EXPERIMENTAL_TREE = 1\n",
      "    \n",
      "    class CriticalSection(builtins.object)\n",
      "     |  CriticalSection(name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |  \n",
      "     |  Critical section.\n",
      "     |  \n",
      "     |  A `CriticalSection` object is a resource in the graph which executes subgraphs\n",
      "     |  in **serial** order.  A common example of a subgraph one may wish to run\n",
      "     |  exclusively is the one given by the following function:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = resource_variable_ops.ResourceVariable(0.0, name=\"v\")\n",
      "     |  \n",
      "     |  def count():\n",
      "     |    value = v.read_value()\n",
      "     |    with tf.control_dependencies([value]):\n",
      "     |      with tf.control_dependencies([v.assign_add(1)]):\n",
      "     |        return tf.identity(value)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, a snapshot of `v` is captured in `value`; and then `v` is updated.\n",
      "     |  The snapshot value is returned.\n",
      "     |  \n",
      "     |  If multiple workers or threads all execute `count` in parallel, there is no\n",
      "     |  guarantee that access to the variable `v` is atomic at any point within\n",
      "     |  any thread's calculation of `count`.  In fact, even implementing an atomic\n",
      "     |  counter that guarantees that the user will see each value `0, 1, ...,` is\n",
      "     |  currently impossible.\n",
      "     |  \n",
      "     |  The solution is to ensure any access to the underlying resource `v` is\n",
      "     |  only processed through a critical section:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  cs = CriticalSection()\n",
      "     |  f1 = cs.execute(count)\n",
      "     |  f2 = cs.execute(count)\n",
      "     |  output = f1 + f2\n",
      "     |  session.run(output)\n",
      "     |  ```\n",
      "     |  The functions `f1` and `f2` will be executed serially, and updates to `v`\n",
      "     |  will be atomic.\n",
      "     |  \n",
      "     |  **NOTES**\n",
      "     |  \n",
      "     |  All resource objects, including the critical section and any captured\n",
      "     |  variables of functions executed on that critical section, will be\n",
      "     |  colocated to the same device (host and cpu/gpu).\n",
      "     |  \n",
      "     |  When using multiple critical sections on the same resources, there is no\n",
      "     |  guarantee of exclusive access to those resources.  This behavior is disallowed\n",
      "     |  by default (but see the kwarg `exclusive_resource_access`).\n",
      "     |  \n",
      "     |  For example, running the same function in two separate critical sections\n",
      "     |  will not ensure serial execution:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = tf.compat.v1.get_variable(\"v\", initializer=0.0, use_resource=True)\n",
      "     |  def accumulate(up):\n",
      "     |    x = v.read_value()\n",
      "     |    with tf.control_dependencies([x]):\n",
      "     |      with tf.control_dependencies([v.assign_add(up)]):\n",
      "     |        return tf.identity(x)\n",
      "     |  ex1 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  ex2 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  bad_sum = ex1 + ex2\n",
      "     |  sess.run(v.initializer)\n",
      "     |  sess.run(bad_sum)  # May return 0.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |      Creates a critical section.\n",
      "     |  \n",
      "     |  execute(self, fn, exclusive_resource_access=True, name=None)\n",
      "     |      Execute function `fn()` inside the critical section.\n",
      "     |      \n",
      "     |      `fn` should not accept any arguments.  To add extra arguments to when\n",
      "     |      calling `fn` in the critical section, create a lambda:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      critical_section.execute(lambda: fn(*my_args, **my_kwargs))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fn: The function to execute.  Must return at least one tensor.\n",
      "     |        exclusive_resource_access: Whether the resources required by\n",
      "     |          `fn` should be exclusive to this `CriticalSection`.  Default: `True`.\n",
      "     |          You may want to set this to `False` if you will be accessing a\n",
      "     |          resource in read-only mode in two different CriticalSections.\n",
      "     |        name: The name to use when creating the execute operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors returned from `fn()`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `fn` attempts to lock this `CriticalSection` in any nested\n",
      "     |          or lazy way that may cause a deadlock.\n",
      "     |        ValueError: If `exclusive_resource_access == True` and\n",
      "     |          another `CriticalSection` has an execution requesting the same\n",
      "     |          resources as `fn``.  Note, even if `exclusive_resource_access` is\n",
      "     |          `True`, if another execution in another `CriticalSection` was created\n",
      "     |          without `exclusive_resource_access=True`, a `ValueError` will be raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  DType(type_enum, handle_data=None)\n",
      "     |  \n",
      "     |  Represents the type of the elements in a `Tensor`.\n",
      "     |  \n",
      "     |  `DType`'s are used to specify the output data type for operations which\n",
      "     |  require it, or to inspect the data type of existing `Tensor`'s.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> tf.constant(1, dtype=tf.int64)\n",
      "     |  <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "     |  >>> tf.constant(1.0).dtype\n",
      "     |  tf.float32\n",
      "     |  \n",
      "     |  See `tf.dtypes` for a complete list of `DType`'s defined.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DType\n",
      "     |      tensorflow.python.framework._dtypes.DType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True iff this DType refers to the same type as `other`.\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: tensorflow.python.framework._dtypes.DType) -> int\n",
      "     |  \n",
      "     |  __init__(self, type_enum, handle_data=None)\n",
      "     |      __init__(self: tensorflow.python.framework._dtypes.DType, arg0: object) -> None\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns True iff self != other.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.types_pb2.SerializedDType\n",
      "     |      Returns a proto representation of the Dtype instance.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True if the `other` DType will be converted to this DType.\n",
      "     |      \n",
      "     |      The conversion rules are as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      DType(T)       .is_compatible_with(DType(T))        == True\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `DType` (or object that may be converted to a `DType`).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if a Tensor of the `other` `DType` will be implicitly converted to\n",
      "     |        this `DType`.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, types: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('DType'), NoneType]\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      TensorShape does not support placeholder values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.types_pb2.SerializedDType) -> 'DType' from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns a Dtype instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.types_pb2.SerializedDType] from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns the type of proto associated with DType serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  as_numpy_dtype\n",
      "     |      Returns a Python `type` object based on this `DType`.\n",
      "     |  \n",
      "     |  base_dtype\n",
      "     |      Returns a non-reference `DType` based on this `DType`.\n",
      "     |  \n",
      "     |  limits\n",
      "     |      Return intensity limits, i.e.\n",
      "     |      \n",
      "     |      (min, max) tuple, of the dtype.\n",
      "     |      Args:\n",
      "     |        clip_negative : bool, optional If True, clip the negative range (i.e.\n",
      "     |          return 0 for min intensity) even if the image dtype allows negative\n",
      "     |          values. Returns\n",
      "     |        min, max : tuple Lower and upper intensity limits.\n",
      "     |  \n",
      "     |  max\n",
      "     |      Returns the maximum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  min\n",
      "     |      Returns the minimum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  real_dtype\n",
      "     |      Returns the `DType` corresponding to this `DType`'s real part.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  as_datatype_enum\n",
      "     |      Returns a `types_pb2.DataType` enum value based on this data type.\n",
      "     |  \n",
      "     |  is_bool\n",
      "     |      Returns whether this is a boolean data type.\n",
      "     |  \n",
      "     |  is_complex\n",
      "     |      Returns whether this is a complex floating point type.\n",
      "     |  \n",
      "     |  is_floating\n",
      "     |      Returns whether this is a (non-quantized, real) floating point type.\n",
      "     |  \n",
      "     |  is_integer\n",
      "     |      Returns whether this is a (non-quantized) integer type.\n",
      "     |  \n",
      "     |  is_numpy_compatible\n",
      "     |      Returns whether this data type has a compatible NumPy data type.\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Returns whether this is a quantized data type.\n",
      "     |  \n",
      "     |  is_unsigned\n",
      "     |      Returns whether this type is unsigned.\n",
      "     |      \n",
      "     |      Non-numeric, unordered, and quantized types are not considered unsigned, and\n",
      "     |      this function returns `False`.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    DeviceSpec = class DeviceSpecV2(builtins.object)\n",
      "     |  DeviceSpec(job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |  \n",
      "     |  Represents a (possibly partial) specification for a TensorFlow device.\n",
      "     |  \n",
      "     |  `DeviceSpec`s are used throughout TensorFlow to describe where state is stored\n",
      "     |  and computations occur. Using `DeviceSpec` allows you to parse device spec\n",
      "     |  strings to verify their validity, merge them or compose them programmatically.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Place the operations on device \"GPU:0\" in the \"ps\" job.\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(device_spec.to_string()):\n",
      "     |    # Both my_var and squared_var will be placed on /job:ps/device:GPU:0.\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  With eager execution disabled (by default in TensorFlow 1.x and by calling\n",
      "     |  disable_eager_execution() in TensorFlow 2.x), the following syntax\n",
      "     |  can be used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution()\n",
      "     |  \n",
      "     |  # Same as previous\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  # No need of .to_string() method.\n",
      "     |  with tf.device(device_spec):\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If a `DeviceSpec` is partially specified, it will be merged with other\n",
      "     |  `DeviceSpec`s according to the scope in which it is defined. `DeviceSpec`\n",
      "     |  components defined in inner scopes take precedence over those defined in\n",
      "     |  outer scopes.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  gpu0_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(DeviceSpec(job=\"train\").to_string()):\n",
      "     |    with tf.device(gpu0_spec.to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:ps/device:GPU:0.\n",
      "     |    with tf.device(DeviceSpec(device_type=\"GPU\", device_index=1).to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:train/device:GPU:1.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A `DeviceSpec` consists of 5 components -- each of\n",
      "     |  which is optionally specified:\n",
      "     |  \n",
      "     |  * Job: The job name.\n",
      "     |  * Replica: The replica index.\n",
      "     |  * Task: The task index.\n",
      "     |  * Device type: The device type string (e.g. \"CPU\" or \"GPU\").\n",
      "     |  * Device index: The device index.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Checks if the `other` DeviceSpec is same as the current instance, eg have\n",
      "     |      \n",
      "     |         same value for all the internal fields.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another DeviceSpec\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Return `True` if `other` is also a DeviceSpec instance and has same value\n",
      "     |        as the current instance.\n",
      "     |        Return `False` otherwise.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |      Create a new `DeviceSpec` object.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        job: string.  Optional job name.\n",
      "     |        replica: int.  Optional replica index.\n",
      "     |        task: int.  Optional task index.\n",
      "     |        device_type: Optional device type string (e.g. \"CPU\" or \"GPU\")\n",
      "     |        device_index: int.  Optional device index.  If left unspecified, device\n",
      "     |          represents 'any' device_index.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  make_merged_spec(self, dev)\n",
      "     |      Returns a new DeviceSpec which incorporates `dev`.\n",
      "     |      \n",
      "     |      When combining specs, `dev` will take precedence over the current spec.\n",
      "     |      So for instance:\n",
      "     |      ```\n",
      "     |      first_spec = tf.DeviceSpec(job=0, device_type=\"CPU\")\n",
      "     |      second_spec = tf.DeviceSpec(device_type=\"GPU\")\n",
      "     |      combined_spec = first_spec.make_merged_spec(second_spec)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      is equivalent to:\n",
      "     |      ```\n",
      "     |      combined_spec = tf.DeviceSpec(job=0, device_type=\"GPU\")\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new `DeviceSpec` which combines `self` and `dev`\n",
      "     |  \n",
      "     |  parse_from_string(self, spec)\n",
      "     |      Parse a `DeviceSpec` name into its components.\n",
      "     |      \n",
      "     |      **2.x behavior change**:\n",
      "     |      \n",
      "     |      In TensorFlow 1.x, this function mutates its own state and returns itself.\n",
      "     |      In 2.x, DeviceSpecs are immutable, and this function will return a\n",
      "     |        DeviceSpec which contains the spec.\n",
      "     |      \n",
      "     |      * Recommended:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        # my_spec and my_updated_spec are unrelated.\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = tf.DeviceSpec.from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will work in 1.x and 2.x (though deprecated in 2.x):\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = my_spec.parse_from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will NOT work in 2.x:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_spec.parse_from_string(\"/GPU:0\")  # <== Will not update my_spec\n",
      "     |        with tf.device(my_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      In general, `DeviceSpec.from_string` should completely replace\n",
      "     |      `DeviceSpec.parse_from_string`, and `DeviceSpec.replace` should\n",
      "     |      completely replace setting attributes directly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: an optional string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `DeviceSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the spec was not valid.\n",
      "     |  \n",
      "     |  replace(self, **kwargs)\n",
      "     |      Convenience method for making a new DeviceSpec by overriding fields.\n",
      "     |      \n",
      "     |      For instance:\n",
      "     |      ```\n",
      "     |      my_spec = DeviceSpec=(job=\"my_job\", device=\"CPU\")\n",
      "     |      my_updated_spec = my_spec.replace(device=\"GPU\")\n",
      "     |      my_other_spec = my_spec.replace(device=None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        **kwargs: This method takes the same args as the DeviceSpec constructor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec with the fields specified in kwargs overridden.\n",
      "     |  \n",
      "     |  to_string(self)\n",
      "     |      Return a string representation of this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a string of the form\n",
      "     |        /job:<name>/replica:<id>/task:<id>/device:<device_type>:<id>.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_string(spec) from builtins.type\n",
      "     |      Construct a `DeviceSpec` from a string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: a string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  device_index\n",
      "     |  \n",
      "     |  device_type\n",
      "     |  \n",
      "     |  job\n",
      "     |  \n",
      "     |  replica\n",
      "     |  \n",
      "     |  task\n",
      "    \n",
      "    class GradientTape(builtins.object)\n",
      "     |  GradientTape(persistent=False, watch_accessed_variables=True)\n",
      "     |  \n",
      "     |  Record operations for automatic differentiation.\n",
      "     |  \n",
      "     |  Operations are recorded if they are executed within this context manager and\n",
      "     |  at least one of their inputs is being \"watched\".\n",
      "     |  \n",
      "     |  Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
      "     |  where `trainable=True` is default in both cases) are automatically watched.\n",
      "     |  Tensors can be manually watched by invoking the `watch` method on this context\n",
      "     |  manager.\n",
      "     |  \n",
      "     |  For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
      "     |  be computed as:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  GradientTapes can be nested to compute higher-order derivatives. For example,\n",
      "     |  \n",
      "     |  >>> x = tf.constant(5.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   with tf.GradientTape() as gg:\n",
      "     |  ...     gg.watch(x)\n",
      "     |  ...     y = x * x\n",
      "     |  ...   dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
      "     |  >>> d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "     |  >>> print(d2y_dx2)\n",
      "     |  tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default, the resources held by a GradientTape are released as soon as\n",
      "     |  GradientTape.gradient() method is called. To compute multiple gradients over\n",
      "     |  the same computation, create a persistent gradient tape. This allows multiple\n",
      "     |  calls to the gradient() method as resources are released when the tape object\n",
      "     |  is garbage collected. For example:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape(persistent=True) as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  ...   z = y * y\n",
      "     |  >>> dz_dx = g.gradient(z, x)  # (4*x^3 at x = 3)\n",
      "     |  >>> print(dz_dx)\n",
      "     |  tf.Tensor(108.0, shape=(), dtype=float32)\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default GradientTape will automatically watch any trainable variables that\n",
      "     |  are accessed inside the context. If you want fine grained control over which\n",
      "     |  variables are watched you can disable automatic tracking by passing\n",
      "     |  `watch_accessed_variables=False` to the tape constructor:\n",
      "     |  \n",
      "     |  >>> x = tf.Variable(2.0)\n",
      "     |  >>> w = tf.Variable(5.0)\n",
      "     |  >>> with tf.GradientTape(\n",
      "     |  ...     watch_accessed_variables=False, persistent=True) as tape:\n",
      "     |  ...   tape.watch(x)\n",
      "     |  ...   y = x ** 2  # Gradients will be available for `x`.\n",
      "     |  ...   z = w ** 3  # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dy_dx = tape.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "     |  >>> # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dz_dw = tape.gradient(z, w)\n",
      "     |  >>> print(dz_dw)\n",
      "     |  None\n",
      "     |  \n",
      "     |  Note that when using models you should ensure that your variables exist when\n",
      "     |  using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
      "     |  first iteration not have any gradients:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.keras.layers.Dense(32)\n",
      "     |  b = tf.keras.layers.Dense(32)\n",
      "     |  \n",
      "     |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      "     |    tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
      "     |                             # `a.variables` will return an empty list and the\n",
      "     |                             # tape will not be watching anything.\n",
      "     |    result = b(a(inputs))\n",
      "     |    tape.gradient(result, a.variables)  # The result of this computation will be\n",
      "     |                                        # a list of `None`s since a's variables\n",
      "     |                                        # are not being watched.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that only tensors with real or complex dtypes are differentiable.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Enters a context inside which operations are recorded on this tape.\n",
      "     |  \n",
      "     |  __exit__(self, typ, value, traceback)\n",
      "     |      Exits the recording context, no further operations are traced.\n",
      "     |  \n",
      "     |  __init__(self, persistent=False, watch_accessed_variables=True)\n",
      "     |      Creates a new GradientTape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        persistent: Boolean controlling whether a persistent gradient tape\n",
      "     |          is created. False by default, which means at most one call can\n",
      "     |          be made to the gradient() method on this object.\n",
      "     |        watch_accessed_variables: Boolean controlling whether the tape will\n",
      "     |          automatically `watch` any (trainable) variables accessed while the tape\n",
      "     |          is active. Defaults to True meaning gradients can be requested from any\n",
      "     |          result computed in the tape derived from reading a trainable `Variable`.\n",
      "     |          If False users must explicitly `watch` any `Variable`s they want to\n",
      "     |          request gradients from.\n",
      "     |  \n",
      "     |  batch_jacobian(self, target, source, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes and stacks per-example jacobians.\n",
      "     |      \n",
      "     |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian. This function is essentially an efficient\n",
      "     |      implementation of the following:\n",
      "     |      \n",
      "     |      `tf.stack([self.jacobian(y[i], x[i]) for i in range(x.shape[0])])`.\n",
      "     |      \n",
      "     |      Note that compared to `GradientTape.jacobian` which computes gradient of\n",
      "     |      each output value w.r.t each input value, this function is useful when\n",
      "     |      `target[i,...]` is independent of `source[j,...]` for `j != i`. This\n",
      "     |      assumption allows more efficient computation as compared to\n",
      "     |      `GradientTape.jacobian`. The output, as well as intermediate activations,\n",
      "     |      are lower dimensional and avoid a bunch of redundant zeros which would\n",
      "     |      result in the jacobian computation given the independence assumption.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the batch_jacobian implementation uses parallel for (pfor),\n",
      "     |      which creates a tf.function under the hood for each batch_jacobian call.\n",
      "     |      For better performance, and to avoid recompilation and vectorization\n",
      "     |      rewrites on each call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      batch_jacobian = g.batch_jacobian(y, x)\n",
      "     |      # batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n].\n",
      "     |          `target[i,...]` should only depend on `source[i,...]`.\n",
      "     |        source: A tensor with rank 2 or higher and with shape [b, x1, ..., x_m].\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, uses pfor for computing the Jacobian. Else\n",
      "     |          uses a tf.while_loop.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor `t` with shape [b, y_1, ..., y_n, x1, ..., x_m] where `t[i, ...]`\n",
      "     |        is the jacobian of `target[i, ...]` w.r.t. `source[i, ...]`, i.e. stacked\n",
      "     |        per-example jacobians.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails or if first\n",
      "     |          dimension of `target` and `source` do not match.\n",
      "     |  \n",
      "     |  gradient(self, target, sources, output_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "     |      Computes the gradient using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      In addition to Tensors, gradient also supports RaggedTensors. For example,\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1.0, 2.0], [3.0]])\n",
      "     |      >>> with tf.GradientTape() as g:\n",
      "     |      ...   g.watch(x)\n",
      "     |      ...   y = x * x\n",
      "     |      >>> g.gradient(y, x)\n",
      "     |      <tf.RaggedTensor [[2.0, 4.0], [6.0]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors. `target` will be differentiated against elements in\n",
      "     |          `sources`.\n",
      "     |        output_gradients: a list of gradients, one for each differentiable\n",
      "     |          element of target. Defaults to None.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a list or nested structure of Tensors (or IndexedSlices, or None, or\n",
      "     |        CompositeTensor), one for each element in `sources`. Returned structure\n",
      "     |        is the same as the structure of `sources`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called inside the context of the tape.\n",
      "     |        TypeError: If the target is a None object.\n",
      "     |        ValueError: If the target is a variable or if unconnected gradients is\n",
      "     |         called with an unknown value.\n",
      "     |  \n",
      "     |  jacobian(self, target, sources, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes the jacobian using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the jacobian implementation uses parallel for (pfor), which\n",
      "     |      creates a tf.function under the hood for each jacobian call. For better\n",
      "     |      performance, and to avoid recompilation and vectorization rewrites on each\n",
      "     |      call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      See[wikipedia\n",
      "     |      article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x  = tf.constant([1.0, 2.0])\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      jacobian = g.jacobian(y, x)\n",
      "     |      # jacobian value is [[2., 0.], [0., 4.]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: Tensor to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      "     |          will be differentiated against elements in `sources`.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, vectorizes the jacobian computation. Else\n",
      "     |          falls back to a sequential while_loop. Vectorization can sometimes fail\n",
      "     |          or lead to excessive memory usage. This option can be used to disable\n",
      "     |          vectorization in such cases.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list or nested structure of Tensors (or None), one for each element in\n",
      "     |        `sources`. Returned structure is the same as the structure of `sources`.\n",
      "     |        Note if any gradient is sparse (IndexedSlices), jacobian function\n",
      "     |        currently makes it dense and returns a Tensor instead. This may change in\n",
      "     |        the future.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Clears all information stored in this tape.\n",
      "     |      \n",
      "     |      Equivalent to exiting and reentering the tape context manager with a new\n",
      "     |      tape. For example, the two following code blocks are equivalent:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      \n",
      "     |      \n",
      "     |      # The following is equivalent to the above\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |        t.reset()\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is useful if you don't want to exit the context manager for the tape,\n",
      "     |      or can't because the desired reset point is inside a control flow construct:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = ...\n",
      "     |        if loss > k:\n",
      "     |          t.reset()\n",
      "     |      ```\n",
      "     |  \n",
      "     |  stop_recording(self)\n",
      "     |      Temporarily stops recording operations on this tape.\n",
      "     |      \n",
      "     |      Operations executed while this context manager is active will not be\n",
      "     |      recorded on the tape. This is useful for reducing the memory used by tracing\n",
      "     |      all computations.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(4.0)\n",
      "     |      >>> with tf.GradientTape() as tape:\n",
      "     |      ...   with tape.stop_recording():\n",
      "     |      ...     y = x ** 2\n",
      "     |      >>> dy_dx = tape.gradient(y, x)\n",
      "     |      >>> print(dy_dx)\n",
      "     |      None\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        None\n",
      "     |      Raises:\n",
      "     |        RuntimeError: if the tape is not currently recording.\n",
      "     |  \n",
      "     |  watch(self, tensor)\n",
      "     |      Ensures that `tensor` is being traced by this tape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: a Tensor/Variable or list of Tensors/Variables.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if it encounters something that is not a tensor.\n",
      "     |  \n",
      "     |  watched_variables(self)\n",
      "     |      Returns variables watched by this tape in order of construction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Graph(tensorflow.python.client._pywrap_tf_session.PyGraph)\n",
      "     |  A TensorFlow computation, represented as a dataflow graph.\n",
      "     |  \n",
      "     |  Graphs are used by `tf.function`s to represent the function's computations.\n",
      "     |  Each graph contains a set of `tf.Operation` objects, which represent units of\n",
      "     |  computation; and `tf.Tensor` objects, which represent the units of data that\n",
      "     |  flow between operations.\n",
      "     |  \n",
      "     |  ### Using graphs directly (deprecated)\n",
      "     |  \n",
      "     |  A `tf.Graph` can be constructed and used directly without a `tf.function`, as\n",
      "     |  was required in TensorFlow 1, but this is deprecated and it is recommended to\n",
      "     |  use a `tf.function` instead. If a graph is directly used, other deprecated\n",
      "     |  TensorFlow 1 classes are also required to execute the graph, such as a\n",
      "     |  `tf.compat.v1.Session`.\n",
      "     |  \n",
      "     |  A default graph can be registered with the `tf.Graph.as_default` context\n",
      "     |  manager. Then, operations will be added to the graph instead of being executed\n",
      "     |  eagerly. For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  g = tf.Graph()\n",
      "     |  with g.as_default():\n",
      "     |    # Define operations and tensors in `g`.\n",
      "     |    c = tf.constant(30.0)\n",
      "     |    assert c.graph is g\n",
      "     |  ```\n",
      "     |  \n",
      "     |  `tf.compat.v1.get_default_graph()` can be used to obtain the default graph.\n",
      "     |  \n",
      "     |  Important note: This class *is not* thread-safe for graph construction. All\n",
      "     |  operations should be created from a single thread, or external\n",
      "     |  synchronization must be provided. Unless otherwise specified, all methods\n",
      "     |  are not thread-safe.\n",
      "     |  \n",
      "     |  A `Graph` instance supports an arbitrary number of \"collections\"\n",
      "     |  that are identified by name. For convenience when building a large\n",
      "     |  graph, collections can store groups of related objects: for\n",
      "     |  example, the `tf.Variable` uses a collection (named\n",
      "     |  `tf.GraphKeys.GLOBAL_VARIABLES`) for\n",
      "     |  all variables that are created during the construction of a graph. The caller\n",
      "     |  may define additional collections by specifying a new name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyGraph\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Creates a new, empty Graph.\n",
      "     |  \n",
      "     |  add_to_collection(self, name, value)\n",
      "     |      Stores `value` in the collection with the given `name`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |        value: The value to add to the collection.\n",
      "     |  \n",
      "     |  add_to_collections(self, names, value)\n",
      "     |      Stores `value` in the collections given by `names`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times. This function makes sure that duplicates in\n",
      "     |      `names` are ignored, but it will not check for pre-existing membership of\n",
      "     |      `value` in any of the collections in `names`.\n",
      "     |      \n",
      "     |      `names` can be any iterable, but if `names` is a string, it is treated as a\n",
      "     |      single collection name.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        names: The keys for the collections to add to. The `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        value: The value to add to the collections.\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this `Graph` the default graph.\n",
      "     |      \n",
      "     |      This method should be used if you want to create multiple graphs\n",
      "     |      in the same process. For convenience, a global default graph is\n",
      "     |      provided, and all ops will be added to this graph if you do not\n",
      "     |      create a new graph explicitly.\n",
      "     |      \n",
      "     |      Use this method with the `with` keyword to specify that ops created within\n",
      "     |      the scope of a block should be added to this graph. In this case, once\n",
      "     |      the scope of the `with` is exited, the previous default graph is set again\n",
      "     |      as default. There is a stack, so it's ok to have multiple nested levels\n",
      "     |      of `as_default` calls.\n",
      "     |      \n",
      "     |      The default graph is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default graph in that\n",
      "     |      thread, you must explicitly add a `with g.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      The following code examples are equivalent:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 1. Using Graph.as_default():\n",
      "     |      g = tf.Graph()\n",
      "     |      with g.as_default():\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      \n",
      "     |      # 2. Constructing and making default:\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If eager execution is enabled ops created under this context manager will be\n",
      "     |      added to the graph instead of executed eagerly.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for using this graph as the default graph.\n",
      "     |  \n",
      "     |  as_graph_def(self, from_version=None, add_shapes=False)\n",
      "     |      Returns a serialized `GraphDef` representation of this graph.\n",
      "     |      \n",
      "     |      The serialized `GraphDef` can be imported into another `Graph`\n",
      "     |      (using `tf.import_graph_def`) or used with the\n",
      "     |      [C++ Session API](../../api_docs/cc/index.md).\n",
      "     |      \n",
      "     |      This method is thread-safe.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        from_version: Optional.  If this is set, returns a `GraphDef` containing\n",
      "     |          only the nodes that were added to this graph since its `version`\n",
      "     |          property had the given value.\n",
      "     |        add_shapes: If true, adds an \"_output_shapes\" list attr to each node with\n",
      "     |          the inferred shapes of each of its outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A\n",
      "     |        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "     |        protocol buffer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the `graph_def` would be too large.\n",
      "     |  \n",
      "     |  as_graph_element(self, obj, allow_tensor=True, allow_operation=True)\n",
      "     |      Returns the object referred to by `obj`, as an `Operation` or `Tensor`.\n",
      "     |      \n",
      "     |      This function validates that `obj` represents an element of this\n",
      "     |      graph, and gives an informative error message if it is not.\n",
      "     |      \n",
      "     |      This function is the canonical way to get/validate an object of\n",
      "     |      one of the allowed types from an external argument reference in the\n",
      "     |      Session API.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        obj: A `Tensor`, an `Operation`, or the name of a tensor or operation. Can\n",
      "     |          also be any object with an `_as_graph_element()` method that returns a\n",
      "     |          value of one of these types. Note: `_as_graph_element` will be called\n",
      "     |          inside the graph's lock and so may not modify the graph.\n",
      "     |        allow_tensor: If true, `obj` may refer to a `Tensor`.\n",
      "     |        allow_operation: If true, `obj` may refer to an `Operation`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` or `Operation` in the Graph corresponding to `obj`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `obj` is not a type we support attempting to convert\n",
      "     |          to types.\n",
      "     |        ValueError: If `obj` is of an appropriate type but invalid. For\n",
      "     |          example, an invalid string.\n",
      "     |        KeyError: If `obj` is not an object in the graph.\n",
      "     |  \n",
      "     |  clear_collection(self, name)\n",
      "     |      Clears all values in a collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |  \n",
      "     |  colocate_with(self, op, ignore_existing=False)\n",
      "     |      Returns a context manager that specifies an op to colocate with.\n",
      "     |      \n",
      "     |      Note: this function is not for public use, only for internal libraries.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = tf.Variable([1.0])\n",
      "     |      with g.colocate_with(a):\n",
      "     |        b = tf.constant(1.0)\n",
      "     |        c = tf.add(a, b)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      `b` and `c` will always be colocated with `a`, no matter where `a`\n",
      "     |      is eventually placed.\n",
      "     |      \n",
      "     |      **NOTE** Using a colocation scope resets any existing device constraints.\n",
      "     |      \n",
      "     |      If `op` is `None` then `ignore_existing` must be `True` and the new\n",
      "     |      scope resets all colocation and device constraints.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op: The op to colocate all created ops with, or `None`.\n",
      "     |        ignore_existing: If true, only applies colocation of this op within the\n",
      "     |          context, rather than applying all colocation properties on the stack.\n",
      "     |          If `op` is `None`, this value must be `True`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if op is None but ignore_existing is False.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the op with which to colocate\n",
      "     |        newly created ops.\n",
      "     |  \n",
      "     |  container(self, container_name)\n",
      "     |      Returns a context manager that specifies the resource container to use.\n",
      "     |      \n",
      "     |      Stateful operations, such as variables and queues, can maintain their\n",
      "     |      states on devices so that they can be shared by multiple processes.\n",
      "     |      A resource container is a string name under which these stateful\n",
      "     |      operations are tracked. These resources can be released or cleared\n",
      "     |      with `tf.Session.reset()`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.container('experiment0'):\n",
      "     |        # All stateful Operations constructed in this context will be placed\n",
      "     |        # in resource container \"experiment0\".\n",
      "     |        v1 = tf.Variable([1.0])\n",
      "     |        v2 = tf.Variable([2.0])\n",
      "     |        with g.container(\"experiment1\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # placed in resource container \"experiment1\".\n",
      "     |          v3 = tf.Variable([3.0])\n",
      "     |          q1 = tf.queue.FIFOQueue(10, tf.float32)\n",
      "     |        # All stateful Operations constructed in this context will be\n",
      "     |        # be created in the \"experiment0\".\n",
      "     |        v4 = tf.Variable([4.0])\n",
      "     |        q1 = tf.queue.FIFOQueue(20, tf.float32)\n",
      "     |        with g.container(\"\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # be placed in the default resource container.\n",
      "     |          v5 = tf.Variable([5.0])\n",
      "     |          q3 = tf.queue.FIFOQueue(30, tf.float32)\n",
      "     |      \n",
      "     |      # Resets container \"experiment0\", after which the state of v1, v2, v4, q1\n",
      "     |      # will become undefined (such as uninitialized).\n",
      "     |      tf.Session.reset(target, [\"experiment0\"])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        container_name: container name string.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for defining resource containers for stateful ops,\n",
      "     |          yields the container name.\n",
      "     |  \n",
      "     |  control_dependencies(self, control_inputs)\n",
      "     |      Returns a context manager that specifies control dependencies.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that all operations constructed\n",
      "     |      within the context should have control dependencies on\n",
      "     |      `control_inputs`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b, c]):\n",
      "     |        # `d` and `e` will only run after `a`, `b`, and `c` have executed.\n",
      "     |        d = ...\n",
      "     |        e = ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Multiple calls to `control_dependencies()` can be nested, and in\n",
      "     |      that case a new `Operation` will have control dependencies on the union\n",
      "     |      of `control_inputs` from all active contexts.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies([c, d]):\n",
      "     |          # Ops constructed here run after `a`, `b`, `c`, and `d`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      You can pass None to clear the control dependencies:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies(None):\n",
      "     |          # Ops constructed here run normally, not waiting for either `a` or `b`.\n",
      "     |          with g.control_dependencies([c, d]):\n",
      "     |            # Ops constructed here run after `c` and `d`, also not waiting\n",
      "     |            # for either `a` or `b`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      *N.B.* The control dependencies context applies *only* to ops that\n",
      "     |      are constructed within the context. Merely using an op or tensor\n",
      "     |      in the context does not add a control dependency. The following\n",
      "     |      example illustrates this point:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # WRONG\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        t = tf.matmul(tensor, tensor)\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created outside the context, so no control\n",
      "     |          # dependency will be added.\n",
      "     |          return t\n",
      "     |      \n",
      "     |      # RIGHT\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created in the context, so a control dependency\n",
      "     |          # will be added.\n",
      "     |          return tf.matmul(tensor, tensor)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also note that though execution of ops created under this scope will trigger\n",
      "     |      execution of the dependencies, the ops created under this scope might still\n",
      "     |      be pruned from a normal tensorflow graph. For example, in the following\n",
      "     |      snippet of code the dependencies are never executed:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |        loss = model.loss()\n",
      "     |        with tf.control_dependencies(dependencies):\n",
      "     |          loss = loss + tf.constant(1)  # note: dependencies ignored in the\n",
      "     |                                        # backward pass\n",
      "     |        return tf.gradients(loss, model.variables)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is because evaluating the gradient graph does not require evaluating\n",
      "     |      the constant(1) op created in the forward pass.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "     |          executed or computed before running the operations defined in the\n",
      "     |          context.  Can also be `None` to clear the control dependencies.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |       A context manager that specifies control dependencies for all\n",
      "     |       operations constructed within the context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `control_inputs` is not a list of `Operation` or\n",
      "     |          `Tensor` objects.\n",
      "     |  \n",
      "     |  create_op(self, op_type, inputs, dtypes=None, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True, compute_device=True)\n",
      "     |      Creates an `Operation` in this graph. (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "     |      \n",
      "     |      This is a low-level interface for creating an `Operation`. Most\n",
      "     |      programs will not call this method directly, and instead use the\n",
      "     |      Python op constructors, such as `tf.constant()`, which add ops to\n",
      "     |      the default graph.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The `Operation` type to create. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      "     |        dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      "     |          tensors that the operation produces.\n",
      "     |        input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      "     |          tensors that the operation consumes. By default, uses the base `DType`\n",
      "     |          of each input in `inputs`. Operations that expect reference-typed inputs\n",
      "     |          must specify `input_types` explicitly.\n",
      "     |        name: (Optional.) A string name for the operation. If not specified, a\n",
      "     |          name is generated based on `op_type`.\n",
      "     |        attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      "     |          string) and the value is the respective `attr` attribute of the\n",
      "     |          `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      "     |          proto).\n",
      "     |        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      "     |          the operation will have.\n",
      "     |        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      "     |          computed).\n",
      "     |        compute_device: (Optional.) If True, device functions will be executed to\n",
      "     |          compute the device property of the Operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if any of the inputs is not a `Tensor`.\n",
      "     |        ValueError: if colocation conflicts with existing device assignment.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `Operation` object.\n",
      "     |  \n",
      "     |  device(self, device_name_or_function)\n",
      "     |      Returns a context manager that specifies the default device to use.\n",
      "     |      \n",
      "     |      The `device_name_or_function` argument may either be a device name\n",
      "     |      string, a device function, or None:\n",
      "     |      \n",
      "     |      * If it is a device name string, all operations constructed in\n",
      "     |        this context will be assigned to the device with that name, unless\n",
      "     |        overridden by a nested `device()` context.\n",
      "     |      * If it is a function, it will be treated as a function from\n",
      "     |        Operation objects to device name strings, and invoked each time\n",
      "     |        a new Operation is created. The Operation will be assigned to\n",
      "     |        the device with the returned name.\n",
      "     |      * If it is None, all `device()` invocations from the enclosing context\n",
      "     |        will be ignored.\n",
      "     |      \n",
      "     |      For information about the valid syntax of device name strings, see\n",
      "     |      the documentation in\n",
      "     |      [`DeviceNameUtils`](https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.device('/device:GPU:0'):\n",
      "     |        # All operations constructed in this context will be placed\n",
      "     |        # on GPU 0.\n",
      "     |        with g.device(None):\n",
      "     |          # All operations constructed in this context will have no\n",
      "     |          # assigned device.\n",
      "     |      \n",
      "     |      # Defines a function from `Operation` to device string.\n",
      "     |      def matmul_on_gpu(n):\n",
      "     |        if n.type == \"MatMul\":\n",
      "     |          return \"/device:GPU:0\"\n",
      "     |        else:\n",
      "     |          return \"/cpu:0\"\n",
      "     |      \n",
      "     |      with g.device(matmul_on_gpu):\n",
      "     |        # All operations of type \"MatMul\" constructed in this context\n",
      "     |        # will be placed on GPU 0; all other operations will be placed\n",
      "     |        # on CPU 0.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      **N.B.** The device scope may be overridden by op wrappers or\n",
      "     |      other library code. For example, a variable assignment op\n",
      "     |      `v.assign()` must be colocated with the `tf.Variable` `v`, and\n",
      "     |      incompatible device scopes will be ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        device_name_or_function: The device name or function to use in the\n",
      "     |          context.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the default device to use for newly\n",
      "     |        created ops.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If device scopes are not properly nested.\n",
      "     |  \n",
      "     |  finalize(self)\n",
      "     |      Finalizes this graph, making it read-only.\n",
      "     |      \n",
      "     |      After calling `g.finalize()`, no new operations can be added to\n",
      "     |      `g`.  This method is used to ensure that no operations are added\n",
      "     |      to a graph when it is shared between multiple threads, for example\n",
      "     |      when using a `tf.compat.v1.train.QueueRunner`.\n",
      "     |  \n",
      "     |  get(self)\n",
      "     |  \n",
      "     |  get_all_collection_keys(self)\n",
      "     |      Returns a list of collections used in this graph.\n",
      "     |  \n",
      "     |  get_collection(self, name, scope=None)\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      This is different from `get_collection_ref()` which always returns the\n",
      "     |      actual collection list if it exists in that it returns a new list each time\n",
      "     |      it is called.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        scope: (Optional.) A string. If supplied, the resulting list is filtered\n",
      "     |          to include only items whose `name` attribute matches `scope` using\n",
      "     |          `re.match`. Items without a `name` attribute are never returned if a\n",
      "     |          scope is supplied. The choice of `re.match` means that a `scope` without\n",
      "     |          special tokens filters by prefix.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or\n",
      "     |        an empty list if no value has been added to that collection. The\n",
      "     |        list contains the values in the order under which they were\n",
      "     |        collected.\n",
      "     |  \n",
      "     |  get_collection_ref(self, name)\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      If the collection exists, this returns the list itself, which can\n",
      "     |      be modified in place to change the collection.  If the collection does\n",
      "     |      not exist, it is created as an empty list and the list is returned.\n",
      "     |      \n",
      "     |      This is different from `get_collection()` which always returns a copy of\n",
      "     |      the collection list if it exists and never creates an empty collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or an empty\n",
      "     |        list if no value has been added to that collection.\n",
      "     |  \n",
      "     |  get_name_scope(self)\n",
      "     |      Returns the current name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.name_scope('scope1'):\n",
      "     |        with tf.name_scope('scope2'):\n",
      "     |          print(tf.compat.v1.get_default_graph().get_name_scope())\n",
      "     |      ```\n",
      "     |      would print the string `scope1/scope2`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string representing the current name scope.\n",
      "     |  \n",
      "     |  get_operation_by_name(self, name)\n",
      "     |      Returns the `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Operation` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to an operation in this graph.\n",
      "     |  \n",
      "     |  get_tensor_by_name(self, name)\n",
      "     |      Returns the `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Tensor` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to a tensor in this graph.\n",
      "     |  \n",
      "     |  gradient_override_map(self, op_type_map)\n",
      "     |      EXPERIMENTAL: A context manager for overriding gradient functions.\n",
      "     |      \n",
      "     |      This context manager can be used to override the gradient function\n",
      "     |      that will be used for ops within the scope of the context.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      @tf.RegisterGradient(\"CustomSquare\")\n",
      "     |      def _custom_square_grad(op, grad):\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        s_1 = tf.square(c)  # Uses the default gradient for tf.square.\n",
      "     |        with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\n",
      "     |          s_2 = tf.square(s_2)  # Uses _custom_square_grad to compute the\n",
      "     |                                # gradient of s_2.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type_map: A dictionary mapping op type strings to alternative op type\n",
      "     |          strings.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that sets the alternative op type to be used for one\n",
      "     |        or more ops created in that context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type_map` is not a dictionary mapping strings to\n",
      "     |          strings.\n",
      "     |  \n",
      "     |  is_feedable(self, tensor)\n",
      "     |      Returns `True` if and only if `tensor` is feedable.\n",
      "     |  \n",
      "     |  is_fetchable(self, tensor_or_op)\n",
      "     |      Returns `True` if and only if `tensor_or_op` is fetchable.\n",
      "     |  \n",
      "     |  name_scope(self, name)\n",
      "     |      Returns a context manager that creates hierarchical names for operations.\n",
      "     |      \n",
      "     |      A graph maintains a stack of name scopes. A `with name_scope(...):`\n",
      "     |      statement pushes a new name onto the stack for the lifetime of the context.\n",
      "     |      \n",
      "     |      The `name` argument will be interpreted as follows:\n",
      "     |      \n",
      "     |      * A string (not ending with '/') will create a new name scope, in which\n",
      "     |        `name` is appended to the prefix of all operations created in the\n",
      "     |        context. If `name` has been used before, it will be made unique by\n",
      "     |        calling `self.unique_name(name)`.\n",
      "     |      * A scope previously captured from a `with g.name_scope(...) as\n",
      "     |        scope:` statement will be treated as an \"absolute\" name scope, which\n",
      "     |        makes it possible to re-enter existing scopes.\n",
      "     |      * A value of `None` or the empty string will reset the current name scope\n",
      "     |        to the top-level (empty) name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0, name=\"c\")\n",
      "     |        assert c.op.name == \"c\"\n",
      "     |        c_1 = tf.constant(6.0, name=\"c\")\n",
      "     |        assert c_1.op.name == \"c_1\"\n",
      "     |      \n",
      "     |        # Creates a scope called \"nested\"\n",
      "     |        with g.name_scope(\"nested\") as scope:\n",
      "     |          nested_c = tf.constant(10.0, name=\"c\")\n",
      "     |          assert nested_c.op.name == \"nested/c\"\n",
      "     |      \n",
      "     |          # Creates a nested scope called \"inner\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_c = tf.constant(20.0, name=\"c\")\n",
      "     |            assert nested_inner_c.op.name == \"nested/inner/c\"\n",
      "     |      \n",
      "     |          # Create a nested scope called \"inner_1\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
      "     |            assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
      "     |      \n",
      "     |            # Treats `scope` as an absolute name scope, and\n",
      "     |            # switches to the \"nested/\" scope.\n",
      "     |            with g.name_scope(scope):\n",
      "     |              nested_d = tf.constant(40.0, name=\"d\")\n",
      "     |              assert nested_d.op.name == \"nested/d\"\n",
      "     |      \n",
      "     |              with g.name_scope(\"\"):\n",
      "     |                e = tf.constant(50.0, name=\"e\")\n",
      "     |                assert e.op.name == \"e\"\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The name of the scope itself can be captured by `with\n",
      "     |      g.name_scope(...) as scope:`, which stores the name of the scope\n",
      "     |      in the variable `scope`. This value can be used to name an\n",
      "     |      operation that represents the overall result of executing the ops\n",
      "     |      in a scope. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.constant(...)\n",
      "     |      with g.name_scope('my_layer') as scope:\n",
      "     |        weights = tf.Variable(..., name=\"weights\")\n",
      "     |        biases = tf.Variable(..., name=\"biases\")\n",
      "     |        affine = tf.matmul(inputs, weights) + biases\n",
      "     |        output = tf.nn.relu(affine, name=scope)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the given `name`. Valid scope\n",
      "     |      names match one of the following regular expressions:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\-/]* (for scopes at the root)\n",
      "     |          [A-Za-z0-9_.\\-/]* (for other scopes)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that installs `name` as a new name scope.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `name` is not a valid scope name, according to the rules\n",
      "     |          above.\n",
      "     |  \n",
      "     |  op_def_for_type(self, type)\n",
      "     |      Returns the `OpDef` proto for `type`. `type` is a string.\n",
      "     |  \n",
      "     |  prevent_feeding(self, tensor)\n",
      "     |      Marks the given `tensor` as unfeedable in this graph.\n",
      "     |  \n",
      "     |  prevent_fetching(self, op)\n",
      "     |      Marks the given `op` as unfetchable in this graph.\n",
      "     |  \n",
      "     |  switch_to_thread_local(self)\n",
      "     |      Make device, colocation and dependencies stacks thread-local.\n",
      "     |      \n",
      "     |      Device, colocation and dependencies stacks are not thread-local be default.\n",
      "     |      If multiple threads access them, then the state is shared.  This means that\n",
      "     |      one thread may affect the behavior of another thread.\n",
      "     |      \n",
      "     |      After this method is called, the stacks become thread-local.  If multiple\n",
      "     |      threads access them, then the state is not shared.  Each thread uses its own\n",
      "     |      value; a thread doesn't affect other threads by mutating such a stack.\n",
      "     |      \n",
      "     |      The initial value for every thread's stack is set to the current value\n",
      "     |      of the stack when `switch_to_thread_local()` was first called.\n",
      "     |  \n",
      "     |  unique_name(self, name, mark_as_used=True)\n",
      "     |      Return a unique operation name for `name`.\n",
      "     |      \n",
      "     |      Note: You rarely need to call `unique_name()` directly.  Most of\n",
      "     |      the time you just need to create `with g.name_scope()` blocks to\n",
      "     |      generate structured names.\n",
      "     |      \n",
      "     |      `unique_name` is used to generate structured names, separated by\n",
      "     |      `\"/\"`, to help identify operations when debugging a graph.\n",
      "     |      Operation names are displayed in error messages reported by the\n",
      "     |      TensorFlow runtime, and in various visualization tools such as\n",
      "     |      TensorBoard.\n",
      "     |      \n",
      "     |      If `mark_as_used` is set to `True`, which is the default, a new\n",
      "     |      unique name is created and marked as in use. If it's set to `False`,\n",
      "     |      the unique name is returned without actually being marked as used.\n",
      "     |      This is useful when the caller simply wants to know what the name\n",
      "     |      to be created will be.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name for an operation.\n",
      "     |        mark_as_used: Whether to mark this name as being used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string to be passed to `create_op()` that will be used\n",
      "     |        to name the operation being created.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  building_function\n",
      "     |      Returns True iff this graph represents a function.\n",
      "     |  \n",
      "     |  collections\n",
      "     |      Returns the names of the collections known to this graph.\n",
      "     |  \n",
      "     |  finalized\n",
      "     |      True if this graph has been finalized.\n",
      "     |  \n",
      "     |  graph_def_versions\n",
      "     |      The GraphDef version information of this graph.\n",
      "     |      \n",
      "     |      For details on the meaning of each version, see\n",
      "     |      [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VersionDef`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  seed\n",
      "     |      The graph-level random seed of this graph.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  Dismantle = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> None\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> list\n",
      "     |  \n",
      "     |  new_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> List[TF_Operation]\n",
      "     |  \n",
      "     |  num_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  operations\n",
      "     |  \n",
      "     |  version\n",
      "    \n",
      "    class IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  IndexedSlices(values, indices, dense_shape=None)\n",
      "     |  \n",
      "     |  A sparse representation of a set of tensor slices at given indices.\n",
      "     |  \n",
      "     |  This class is a simple wrapper for a pair of `Tensor` objects:\n",
      "     |  \n",
      "     |  * `values`: A `Tensor` of any dtype with shape `[D0, D1, ..., Dn]`.\n",
      "     |  * `indices`: A 1-D integer `Tensor` with shape `[D0]`.\n",
      "     |  \n",
      "     |  An `IndexedSlices` is typically used to represent a subset of a larger\n",
      "     |  tensor `dense` of shape `[LARGE0, D1, .. , DN]` where `LARGE0 >> D0`.\n",
      "     |  The values in `indices` are the indices in the first dimension of\n",
      "     |  the slices that have been extracted from the larger tensor.\n",
      "     |  \n",
      "     |  The dense tensor `dense` represented by an `IndexedSlices` `slices` has\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense[slices.indices[i], :, :, :, ...] = slices.values[i, :, :, :, ...]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The `IndexedSlices` class is used principally in the definition of\n",
      "     |  gradients for operations that have sparse gradients\n",
      "     |  (e.g. `tf.gather`).\n",
      "     |  \n",
      "     |  >>> v = tf.Variable([[0.,1, 2], [2, 3, 4], [4, 5, 6], [6, 7, 8]])\n",
      "     |  >>> with tf.GradientTape() as tape:\n",
      "     |  ...   r = tf.gather(v, [1,3])\n",
      "     |  >>> index_slices = tape.gradient(r,v)\n",
      "     |  >>> index_slices\n",
      "     |  <...IndexedSlices object ...>\n",
      "     |  >>> index_slices.indices.numpy()\n",
      "     |  array([1, 3], dtype=int32)\n",
      "     |  >>> index_slices.values.numpy()\n",
      "     |  array([[1., 1., 1.],\n",
      "     |         [1., 1., 1.]], dtype=float32)\n",
      "     |  \n",
      "     |  Contrast this representation with\n",
      "     |  `tf.sparse.SparseTensor`,\n",
      "     |  which uses multi-dimensional indices and scalar values.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlices\n",
      "     |      tensorflow.python.types.internal.IndexedSlices\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, values, indices, dense_shape=None)\n",
      "     |      Creates an `IndexedSlices`.\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D `Tensor` containing the shape of the corresponding dense tensor.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device on which `values` will be produced, or `None`.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the values, indices, and shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      A 1-D `Tensor` containing the indices of the slices.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this `IndexedSlices`.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Gets the `tf.TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      A `Tensor` containing the values of the slices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.indexed_slices.I...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.IndexedSlices:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class IndexedSlicesSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  IndexedSlicesSpec(shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.IndexedSlices`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlicesSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |      Constructs a type specification for a `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `IndexedSlices`, or `None` to allow any\n",
      "     |          dense shape.\n",
      "     |        dtype: `tf.DType` of values in the `IndexedSlices`.\n",
      "     |        indices_dtype: `tf.DType` of the `indices` in the `IndexedSlices`.  One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        dense_shape_dtype: `tf.DType` of the `dense_shape` in the `IndexedSlices`.\n",
      "     |          One of `tf.int32`, `tf.int64`, or `None` (if the `IndexedSlices` has\n",
      "     |          no `dense_shape` tensor).\n",
      "     |        indices_shape: The shape of the `indices` component, which indicates\n",
      "     |          how many slices are in the `IndexedSlices`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Module(tensorflow.python.trackable.autotrackable.AutoTrackable)\n",
      "     |  Module(name=None)\n",
      "     |  \n",
      "     |  Base neural network module class.\n",
      "     |  \n",
      "     |  A module is a named container for `tf.Variable`s, other `tf.Module`s and\n",
      "     |  functions which apply to user input. For example a dense layer in a neural\n",
      "     |  network might be implemented as a `tf.Module`:\n",
      "     |  \n",
      "     |  >>> class Dense(tf.Module):\n",
      "     |  ...   def __init__(self, input_dim, output_size, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.w = tf.Variable(\n",
      "     |  ...       tf.random.normal([input_dim, output_size]), name='w')\n",
      "     |  ...     self.b = tf.Variable(tf.zeros([output_size]), name='b')\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     y = tf.matmul(x, self.w) + self.b\n",
      "     |  ...     return tf.nn.relu(y)\n",
      "     |  \n",
      "     |  You can use the Dense layer as you would expect:\n",
      "     |  \n",
      "     |  >>> d = Dense(input_dim=3, output_size=2)\n",
      "     |  >>> d(tf.ones([1, 3]))\n",
      "     |  <tf.Tensor: shape=(1, 2), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |  \n",
      "     |  \n",
      "     |  By subclassing `tf.Module` instead of `object` any `tf.Variable` or\n",
      "     |  `tf.Module` instances assigned to object properties can be collected using\n",
      "     |  the `variables`, `trainable_variables` or `submodules` property:\n",
      "     |  \n",
      "     |  >>> d.variables\n",
      "     |      (<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=...,\n",
      "     |      dtype=float32)>,\n",
      "     |      <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=..., dtype=float32)>)\n",
      "     |  \n",
      "     |  \n",
      "     |  Subclasses of `tf.Module` can also take advantage of the `_flatten` method\n",
      "     |  which can be used to implement tracking of any other types.\n",
      "     |  \n",
      "     |  All `tf.Module` classes have an associated `tf.name_scope` which can be used\n",
      "     |  to group operations in TensorBoard and create hierarchies for variable names\n",
      "     |  which can help with debugging. We suggest using the name scope when creating\n",
      "     |  nested submodules/parameters or for forward methods whose graph you might want\n",
      "     |  to inspect in TensorBoard. You can enter the name scope explicitly using\n",
      "     |  `with self.name_scope:` or you can annotate methods (apart from `__init__`)\n",
      "     |  with `@tf.Module.with_name_scope`.\n",
      "     |  \n",
      "     |  >>> class MLP(tf.Module):\n",
      "     |  ...   def __init__(self, input_size, sizes, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.layers = []\n",
      "     |  ...     with self.name_scope:\n",
      "     |  ...       for size in sizes:\n",
      "     |  ...         self.layers.append(Dense(input_dim=input_size, output_size=size))\n",
      "     |  ...         input_size = size\n",
      "     |  ...   @tf.Module.with_name_scope\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     for layer in self.layers:\n",
      "     |  ...       x = layer(x)\n",
      "     |  ...     return x\n",
      "     |  \n",
      "     |  >>> module = MLP(input_size=5, sizes=[5, 5])\n",
      "     |  >>> module.variables\n",
      "     |  (<tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Module\n",
      "     |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  non_trainable_variables\n",
      "     |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Operation(tensorflow.python.client._pywrap_tf_session.PyOperation)\n",
      "     |  Represents a graph node that performs computation on tensors.\n",
      "     |  \n",
      "     |  An `Operation` is a node in a `tf.Graph` that takes zero or more `Tensor`\n",
      "     |  objects as input, and produces zero or more `Tensor` objects as output.\n",
      "     |  Objects of type `Operation` are created by calling a Python op constructor\n",
      "     |  (such as `tf.matmul`) within a `tf.function` or under a `tf.Graph.as_default`\n",
      "     |  context manager.\n",
      "     |  \n",
      "     |  For example, within a `tf.function`, `c = tf.matmul(a, b)` creates an\n",
      "     |  `Operation` of type \"MatMul\" that takes tensors `a` and `b` as input, and\n",
      "     |  produces `c` as output.\n",
      "     |  \n",
      "     |  If a `tf.compat.v1.Session` is used, an `Operation` of a `tf.Graph` can be\n",
      "     |  executed by passing it to `tf.Session.run`. `op.run()` is a shortcut for\n",
      "     |  calling `tf.compat.v1.get_default_session().run(op)`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Operation\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyOperation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype=None, name=None)\n",
      "     |      Raises a helpful error.\n",
      "     |  \n",
      "     |  colocation_groups(self)\n",
      "     |      Returns the list of colocation groups of the op.\n",
      "     |  \n",
      "     |  experimental_set_type(self, type_proto)\n",
      "     |      Sets the corresponding node's `experimental_type` field.\n",
      "     |      \n",
      "     |      See the description of `NodeDef.experimental_type` for more info.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        type_proto: A FullTypeDef proto message. The root type_if of this object\n",
      "     |          must be `TFT_PRODUCT`, even for ops which only have a singlre return\n",
      "     |          value.\n",
      "     |  \n",
      "     |  get_attr(self, name)\n",
      "     |      Returns the value of the attr of this op with the given `name`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the attr to fetch.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of the attr, as a Python object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If this op does not have an attr with the given `name`.\n",
      "     |  \n",
      "     |  run(self, feed_dict=None, session=None)\n",
      "     |      Runs this operation in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for this operation.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Operation.run()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to run to this operation. If\n",
      "     |          none, the default session will be used.\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      DEPRECATED: Use outputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_node_def(node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None) from builtins.type\n",
      "     |      Creates an `Operation`.\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the name of the `Operation` (passed\n",
      "     |      as `node_def.name`). Valid `Operation` names match the following\n",
      "     |      regular expression:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\\\-/]*\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for\n",
      "     |          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and\n",
      "     |          `device`.  The `input` attribute is irrelevant here as it will be\n",
      "     |          computed when generating the model.\n",
      "     |        g: `Graph`. The parent graph.\n",
      "     |        inputs: list of `Tensor` objects. The inputs to this `Operation`.\n",
      "     |        output_types: list of `DType` objects.  List of the types of the `Tensors`\n",
      "     |          computed by this operation.  The length of this list indicates the\n",
      "     |          number of output endpoints of the `Operation`.\n",
      "     |        control_inputs: list of operations or tensors from which to have a control\n",
      "     |          dependency.\n",
      "     |        input_types: List of `DType` objects representing the types of the tensors\n",
      "     |          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x\n",
      "     |          in inputs]`.  Operations that expect reference-typed inputs must specify\n",
      "     |          these explicitly.\n",
      "     |        original_op: Optional. Used to associate the new `Operation` with an\n",
      "     |          existing `Operation` (for example, a replica with the op that was\n",
      "     |          replicated).\n",
      "     |        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type\n",
      "     |          that this `Operation` represents.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if control inputs are not Operations or Tensors,\n",
      "     |          or if `node_def` is not a `NodeDef`,\n",
      "     |          or if `g` is not a `Graph`,\n",
      "     |          or if `inputs` are not tensors,\n",
      "     |          or if `inputs` and `input_types` are incompatible.\n",
      "     |        ValueError: if the `node_def` name is not valid.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device to which this op has been assigned, if any.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The string name of the device to which this op has been\n",
      "     |        assigned, or an empty string if it has not been assigned to a\n",
      "     |        device.\n",
      "     |  \n",
      "     |  inputs\n",
      "     |      The sequence of `Tensor` objects representing the data inputs of this op.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |  \n",
      "     |  op_def\n",
      "     |  \n",
      "     |  traceback\n",
      "     |      Returns the call stack from when this operation was constructed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  control_inputs\n",
      "     |      The `Operation` objects on which this op has a control dependency.\n",
      "     |      \n",
      "     |      Before this op is executed, TensorFlow will ensure that the\n",
      "     |      operations in `self.control_inputs` have finished executing. This\n",
      "     |      mechanism can be used to run ops sequentially for performance\n",
      "     |      reasons, or to ensure that the side effects of an op are observed\n",
      "     |      in the correct order.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of `Operation` objects.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  outputs\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  graph\n",
      "    \n",
      "    class OptionalSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  OptionalSpec(element_spec)\n",
      "     |  \n",
      "     |  Type specification for `tf.experimental.Optional`.\n",
      "     |  \n",
      "     |  For instance, `tf.OptionalSpec` can be used to define a tf.function that takes\n",
      "     |  `tf.experimental.Optional` as an input argument:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.OptionalSpec(\n",
      "     |  ...   tf.TensorSpec(shape=(), dtype=tf.int32, name=None))])\n",
      "     |  ... def maybe_square(optional):\n",
      "     |  ...   if optional.has_value():\n",
      "     |  ...     x = optional.get_value()\n",
      "     |  ...     return x * x\n",
      "     |  ...   return -1\n",
      "     |  >>> optional = tf.experimental.Optional.from_value(5)\n",
      "     |  >>> print(maybe_square(optional))\n",
      "     |  tf.Tensor(25, shape=(), dtype=int32)\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    element_spec: A (nested) structure of `TypeSpec` objects that represents the\n",
      "     |      type specification of the optional element.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OptionalSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_spec)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject)\n",
      "     |  RaggedTensor(values, row_partition, internal=False)\n",
      "     |  \n",
      "     |  Represents a ragged tensor.\n",
      "     |  \n",
      "     |  A `RaggedTensor` is a tensor with one or more *ragged dimensions*, which are\n",
      "     |  dimensions whose slices may have different lengths.  For example, the inner\n",
      "     |  (column) dimension of `rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is ragged,\n",
      "     |  since the column slices (`rt[0, :]`, ..., `rt[4, :]`) have different lengths.\n",
      "     |  Dimensions whose slices all have the same length are called *uniform\n",
      "     |  dimensions*.  The outermost dimension of a `RaggedTensor` is always uniform,\n",
      "     |  since it consists of a single slice (and so there is no possibility for\n",
      "     |  differing slice lengths).\n",
      "     |  \n",
      "     |  The total number of dimensions in a `RaggedTensor` is called its *rank*,\n",
      "     |  and the number of ragged dimensions in a `RaggedTensor` is called its\n",
      "     |  *ragged-rank*.  A `RaggedTensor`'s ragged-rank is fixed at graph creation\n",
      "     |  time: it can't depend on the runtime values of `Tensor`s, and can't vary\n",
      "     |  dynamically for different session runs.\n",
      "     |  \n",
      "     |  Note that the `__init__` constructor is private. Please use one of the\n",
      "     |  following methods to construct a `RaggedTensor`:\n",
      "     |  \n",
      "     |  * `tf.RaggedTensor.from_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_value_rowids`\n",
      "     |  * `tf.RaggedTensor.from_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_row_starts`\n",
      "     |  * `tf.RaggedTensor.from_row_limits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |  \n",
      "     |  ### Potentially Ragged Tensors\n",
      "     |  \n",
      "     |  Many ops support both `Tensor`s and `RaggedTensor`s\n",
      "     |  (see [tf.ragged](https://www.tensorflow.org/api_docs/python/tf/ragged) for a\n",
      "     |  full listing). The term \"potentially ragged tensor\" may be used to refer to a\n",
      "     |  tensor that might be either a `Tensor` or a `RaggedTensor`.  The ragged-rank\n",
      "     |  of a `Tensor` is zero.\n",
      "     |  \n",
      "     |  ### Documenting RaggedTensor Shapes\n",
      "     |  \n",
      "     |  When documenting the shape of a RaggedTensor, ragged dimensions can be\n",
      "     |  indicated by enclosing them in parentheses.  For example, the shape of\n",
      "     |  a 3-D `RaggedTensor` that stores the fixed-size word embedding for each\n",
      "     |  word in a sentence, for each sentence in a batch, could be written as\n",
      "     |  `[num_sentences, (num_words), embedding_size]`.  The parentheses around\n",
      "     |  `(num_words)` indicate that dimension is ragged, and that the length\n",
      "     |  of each element list in that dimension may vary for each item.\n",
      "     |  \n",
      "     |  ### Component Tensors\n",
      "     |  \n",
      "     |  Internally, a `RaggedTensor` consists of a concatenated list of values that\n",
      "     |  are partitioned into variable-length rows.  In particular, each `RaggedTensor`\n",
      "     |  consists of:\n",
      "     |  \n",
      "     |    * A `values` tensor, which concatenates the variable-length rows into a\n",
      "     |      flattened list.  For example, the `values` tensor for\n",
      "     |      `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is `[3, 1, 4, 1, 5, 9, 2, 6]`.\n",
      "     |  \n",
      "     |    * A `row_splits` vector, which indicates how those flattened values are\n",
      "     |      divided into rows.  In particular, the values for row `rt[i]` are stored\n",
      "     |      in the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |  ...       values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...       row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ### Alternative Row-Partitioning Schemes\n",
      "     |  \n",
      "     |  In addition to `row_splits`, ragged tensors provide support for five other\n",
      "     |  row-partitioning schemes:\n",
      "     |  \n",
      "     |    * `row_lengths`: a vector with shape `[nrows]`, which specifies the length\n",
      "     |      of each row.\n",
      "     |  \n",
      "     |    * `value_rowids` and `nrows`: `value_rowids` is a vector with shape\n",
      "     |      `[nvals]`, corresponding one-to-one with `values`, which specifies\n",
      "     |      each value's row index.  In particular, the row `rt[row]` consists of the\n",
      "     |      values `rt.values[j]` where `value_rowids[j]==row`.  `nrows` is an\n",
      "     |      integer scalar that specifies the number of rows in the\n",
      "     |      `RaggedTensor`. (`nrows` is used to indicate trailing empty rows.)\n",
      "     |  \n",
      "     |    * `row_starts`: a vector with shape `[nrows]`, which specifies the start\n",
      "     |      offset of each row.  Equivalent to `row_splits[:-1]`.\n",
      "     |  \n",
      "     |    * `row_limits`: a vector with shape `[nrows]`, which specifies the stop\n",
      "     |      offset of each row.  Equivalent to `row_splits[1:]`.\n",
      "     |  \n",
      "     |    * `uniform_row_length`: A scalar tensor, specifying the length of every\n",
      "     |      row.  This row-partitioning scheme may only be used if all rows have\n",
      "     |      the same length.\n",
      "     |  \n",
      "     |  Example: The following ragged tensors are equivalent, and all represent the\n",
      "     |  nested list `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`.\n",
      "     |  \n",
      "     |  >>> values = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "     |  >>> RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_value_rowids(\n",
      "     |  ...     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)\n",
      "     |  <tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>\n",
      "     |  \n",
      "     |  ### Multiple Ragged Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with multiple ragged dimensions can be defined by using\n",
      "     |  a nested `RaggedTensor` for the `values` tensor.  Each nested `RaggedTensor`\n",
      "     |  adds a single ragged dimension.\n",
      "     |  \n",
      "     |  >>> inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above\n",
      "     |  ...     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  >>> outer_rt = RaggedTensor.from_row_splits(\n",
      "     |  ...     values=inner_rt, row_splits=[0, 3, 3, 5])\n",
      "     |  >>> print(outer_rt.to_list())\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  >>> print(outer_rt.ragged_rank)\n",
      "     |  2\n",
      "     |  \n",
      "     |  The factory function `RaggedTensor.from_nested_row_splits` may be used to\n",
      "     |  construct a `RaggedTensor` with multiple ragged dimensions directly, by\n",
      "     |  providing a list of `row_splits` tensors:\n",
      "     |  \n",
      "     |  >>> RaggedTensor.from_nested_row_splits(\n",
      "     |  ...     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  \n",
      "     |  ### Uniform Inner Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform inner dimensions can be defined\n",
      "     |  by using a multidimensional `Tensor` for `values`.\n",
      "     |  \n",
      "     |  >>> rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),\n",
      "     |  ...                                   row_splits=[0, 2, 5])\n",
      "     |  >>> print(rt.to_list())\n",
      "     |  [[[1, 1, 1], [1, 1, 1]],\n",
      "     |   [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]\n",
      "     |  >>> print(rt.shape)\n",
      "     |  (2, None, 3)\n",
      "     |  \n",
      "     |  ### Uniform Outer Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform outer dimensions can be defined by using\n",
      "     |  one or more `RaggedTensor` with a `uniform_row_length` row-partitioning\n",
      "     |  tensor.  For example, a `RaggedTensor` with shape `[2, 2, None]` can be\n",
      "     |  constructed with this method from a `RaggedTensor` values with shape\n",
      "     |  `[4, None]`:\n",
      "     |  \n",
      "     |  >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |  >>> print(values.shape)\n",
      "     |  (4, None)\n",
      "     |  >>> rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |  >>> print(rt6)\n",
      "     |  <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |  >>> print(rt6.shape)\n",
      "     |  (2, 2, None)\n",
      "     |  \n",
      "     |  Note that `rt6` only contains one ragged dimension (the innermost\n",
      "     |  dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |  `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |  \n",
      "     |  >>> rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |  >>> print(rt7.shape)\n",
      "     |  (2, None, None)\n",
      "     |  \n",
      "     |  Uniform and ragged outer dimensions may be interleaved, meaning that a\n",
      "     |  tensor with any combination of ragged and uniform dimensions may be created.\n",
      "     |  For example, a RaggedTensor `t4` with shape `[3, None, 4, 8, None, 2]` could\n",
      "     |  be constructed as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]\n",
      "     |  t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]\n",
      "     |  t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]\n",
      "     |  t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]\n",
      "     |  t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensor\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = ragged_abs(self, name=None)\n",
      "     |      Computes the absolute value of a ragged tensor.\n",
      "     |      \n",
      "     |      Given a ragged tensor of integer or floating-point values, this operation\n",
      "     |      returns a ragged tensor of the same type, where each element contains the\n",
      "     |      absolute value of the corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a ragged tensor `x` of complex numbers, this operation returns a tensor\n",
      "     |      of type `float32` or `float64` that is the absolute value of each element in\n",
      "     |      `x`. For a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "     |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # real number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2, 3.2], [-4.2]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[2.2, 3.2], [4.2]]>\n",
      "     |      \n",
      "     |      >>> # complex number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2 + 4.7j], [-3.2 + 5.7j], [-4.2 + 6.7j]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[5.189412298131649],\n",
      "     |       [6.536818798161687],\n",
      "     |       [7.907591289387685]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` of the same size and type as `x`, with absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `RaggedTensor`\n",
      "     |        will be of type `float32` or `float64`, respectively.\n",
      "     |  \n",
      "     |  __add__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __and__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __bool__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __div__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__ = ragged_eq(self, other)\n",
      "     |      Returns result of elementwise `==` or False if not broadcast-compatible.\n",
      "     |      \n",
      "     |      Compares two ragged tensors elemewise for equality if they are\n",
      "     |      broadcast-compatible; or returns False if they are not\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n",
      "     |      \n",
      "     |      Note that this behavior differs from `tf.math.equal`, which raises an\n",
      "     |      exception if the two ragged tensors are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 == rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[1, 2], [4]])\n",
      "     |      >>> rt1 == rt2\n",
      "     |      <tf.RaggedTensor [[True, True], [False]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 == rt3\n",
      "     |      False\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> t = tf.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt1 == t\n",
      "     |      False\n",
      "     |      >>> t == rt1\n",
      "     |      False\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt4 == t\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      >>> t == rt4\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `==` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The ragged tensor result of the elementwise `==` operation, or `False` if\n",
      "     |        the arguments are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __floordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = ragged_ge(self, other)\n",
      "     |      Elementwise `>=` comparison of two convertible-to-ragged-tensor values.\n",
      "     |      \n",
      "     |      Computes the elemewise `>=` comparison of two values that are convertible to\n",
      "     |      ragged tenors, with [broadcasting]\n",
      "     |      (http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) support.\n",
      "     |      Raises an exception if two values are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 >= rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[2, 1], [3]])\n",
      "     |      >>> rt1 >= rt2\n",
      "     |      <tf.RaggedTensor [[False, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 >= rt3\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      InvalidArgumentError: ...\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2],[3, 4]])\n",
      "     |      >>> t1 = tf.constant([[2, 1], [4, 3]])\n",
      "     |      >>> rt4 >= t1\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [False, True]]>\n",
      "     |      >>> t1 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, False],\n",
      "     |       [True, False]]>\n",
      "     |      \n",
      "     |      >>> # Compares a `tf.RaggedTensor` to a `tf.Tensor` with broadcasting.\n",
      "     |      >>> t2 = tf.constant([[2]])\n",
      "     |      >>> rt4 >= t2\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [True, True]]>\n",
      "     |      >>> t2 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, True],\n",
      "     |       [False, False]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `>=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `self` and\n",
      "     |        `other` broadcast to.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `self` and `other` are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __getitem__ = ragged_tensor_getitem(rt_input, key)\n",
      "     |      Returns the specified piece of this RaggedTensor.\n",
      "     |      \n",
      "     |      Supports multidimensional indexing and slicing, with one restriction:\n",
      "     |      indexing into a ragged inner dimension is not allowed.  This case is\n",
      "     |      problematic because the indicated value may exist in some rows but not\n",
      "     |      others.  In such cases, it's not obvious whether we should (1) report an\n",
      "     |      IndexError; (2) use a default value; or (3) skip that value and return a\n",
      "     |      tensor with fewer rows than we started with.  Following the guiding\n",
      "     |      principles of Python (\"In the face of ambiguity, refuse the temptation to\n",
      "     |      guess\"), we simply disallow this operation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rt_input: The RaggedTensor to slice.\n",
      "     |        key: Indicates which piece of the RaggedTensor to return, using standard\n",
      "     |          Python semantics (e.g., negative values index from the end).  `key`\n",
      "     |          may have any of the following types:\n",
      "     |      \n",
      "     |          * `int` constant\n",
      "     |          * Scalar integer `Tensor`\n",
      "     |          * `slice` containing integer constants and/or scalar integer\n",
      "     |            `Tensor`s\n",
      "     |          * `Ellipsis`\n",
      "     |          * `tf.newaxis`\n",
      "     |          * `tuple` containing any of the above (for multidimensional indexing)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `RaggedTensor` object.  Values that include at least one\n",
      "     |        ragged dimension are returned as `RaggedTensor`.  Values that include no\n",
      "     |        ragged dimensions are returned as `Tensor`.  See above for examples of\n",
      "     |        expressions that return `Tensor`s vs `RaggedTensor`s.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is out of bounds.\n",
      "     |        ValueError: If `key` is not supported.\n",
      "     |        TypeError: If the indices in `key` have an unsupported type.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> # A 2-D ragged tensor with 1 ragged dimension.\n",
      "     |      >>> rt = tf.ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])\n",
      "     |      >>> rt[0].numpy()                 # First row (1-D `Tensor`)\n",
      "     |      array([b'a', b'b', b'c'], dtype=object)\n",
      "     |      >>> rt[:3].to_list()              # First three rows (2-D RaggedTensor)\n",
      "     |      [[b'a', b'b', b'c'], [b'd', b'e'], [b'f']]\n",
      "     |      >>> rt[3, 0].numpy()              # 1st element of 4th row (scalar)\n",
      "     |      b'g'\n",
      "     |      \n",
      "     |      >>> # A 3-D ragged tensor with 2 ragged dimensions.\n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2, 3], [4]],\n",
      "     |      ...                          [[5], [], [6]],\n",
      "     |      ...                          [[7]],\n",
      "     |      ...                          [[8, 9], [10]]])\n",
      "     |      >>> rt[1].to_list()               # Second row (2-D RaggedTensor)\n",
      "     |      [[5], [], [6]]\n",
      "     |      >>> rt[3, 0].numpy()              # First element of fourth row (1-D Tensor)\n",
      "     |      array([8, 9], dtype=int32)\n",
      "     |      >>> rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[], [6]], [], [[10]]]\n",
      "     |      >>> rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[6]], [[7]], [[10]]]\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__ = ragged_hash(self)\n",
      "     |      The operation invoked by the `RaggedTensor.__hash__` operator.\n",
      "     |  \n",
      "     |  __init__(self, values, row_partition, internal=False)\n",
      "     |      Creates a `RaggedTensor` with a specified partitioning for `values`.\n",
      "     |      \n",
      "     |      This constructor is private -- please use one of the following ops to\n",
      "     |      build `RaggedTensor`s:\n",
      "     |      \n",
      "     |        * `tf.RaggedTensor.from_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_value_rowids`\n",
      "     |        * `tf.RaggedTensor.from_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_row_starts`\n",
      "     |        * `tf.RaggedTensor.from_row_limits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.\n",
      "     |        row_partition: A `RowPartition` object, representing the arrangement of\n",
      "     |          the lists at the top level.\n",
      "     |        internal: True if the constructor is being called by one of the factory\n",
      "     |          methods.  If false, an exception will be raised.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If internal = False. Note that this method is intended only\n",
      "     |                   for internal use.\n",
      "     |        TypeError: If values is not a `RaggedTensor` or `Tensor`, or\n",
      "     |                   row_partition is not a `RowPartition`.\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x, name=None)\n",
      "     |      Returns the truth value of `NOT x` element-wise.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __mod__ = floor_mod(x, y, name=None)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ne__ = tensor_not_equals(self, other)\n",
      "     |      The operation invoked by the `Tensor.__ne__` operator.\n",
      "     |      \n",
      "     |      Compares two tensors element-wise for inequality if they are\n",
      "     |      broadcast-compatible; or returns True if they are not broadcast-compatible.\n",
      "     |      (Note that this behavior differs from `tf.math.not_equal`, which raises an\n",
      "     |      exception if the two tensors are not broadcast-compatible.)\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__ne__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The left-hand side of the `!=` operator.\n",
      "     |        other: The right-hand side of the `!=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `!=` operation, or `True` if the arguments\n",
      "     |        are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __or__ = logical_or(x, y, name=None)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      \n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      \n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |      \n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |      \n",
      "     |        element in the larger Tensor.\n",
      "     |      \n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |      \n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |      \n",
      "     |        >>> b = tf.constant([False])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> a | b\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |      \n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> c | x\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |      \n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        >>> y | z\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |      \n",
      "     |        array([[ True,  True],\n",
      "     |      \n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |      \n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |      \n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |      \n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __rand__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __rdiv__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmod__ = floor_mod(x, y, name=None)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ror__ = logical_or(x, y, name=None)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      \n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      \n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |      \n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |      \n",
      "     |        element in the larger Tensor.\n",
      "     |      \n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |      \n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |      \n",
      "     |        >>> b = tf.constant([False])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> a | b\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |      \n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> c | x\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |      \n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |      \n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        >>> y | z\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |      \n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |      \n",
      "     |        array([[ True,  True],\n",
      "     |      \n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |      \n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |      \n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |      \n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __sub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  bounding_shape(self, axis=None, name=None, out_type=None)\n",
      "     |      Returns the tight bounding box shape for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer scalar or vector indicating which axes to return the\n",
      "     |          bounding box for.  If not specified, then the full bounding box is\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer `Tensor` (`dtype=self.row_splits.dtype`).  If `axis` is not\n",
      "     |        specified, then `output` is a vector with\n",
      "     |        `output.shape=[self.shape.ndims]`.  If `axis` is a scalar, then the\n",
      "     |        `output` is a scalar.  If `axis` is a vector, then `output` is a vector,\n",
      "     |        where `output[i]` is the bounding size for dimension `axis[i]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])\n",
      "     |      >>> rt.bounding_shape().numpy()\n",
      "     |      array([5, 4])\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Alias for `shape` property.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).get_shape()\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant(\n",
      "     |      ...    [[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).get_shape()\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  merge_dims(self, outer_axis, inner_axis)\n",
      "     |      Merges outer_axis...inner_axis into a single dimension.\n",
      "     |      \n",
      "     |      Returns a copy of this RaggedTensor with the specified range of dimensions\n",
      "     |      flattened into a single dimension, with elements in row-major order.\n",
      "     |      \n",
      "     |      #### Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]])\n",
      "     |      >>> print(rt.merge_dims(0, 1))\n",
      "     |      <tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(1, 2))\n",
      "     |      <tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(0, 2))\n",
      "     |      tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n",
      "     |      \n",
      "     |      To mimic the behavior of `np.flatten` (which flattens all dimensions), use\n",
      "     |      `rt.merge_dims(0, -1).  To mimic the behavior of `tf.layers.Flatten` (which\n",
      "     |      flattens all dimensions except the outermost batch dimension), use\n",
      "     |      `rt.merge_dims(1, -1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        outer_axis: `int`: The first dimension in the range of dimensions to\n",
      "     |          merge. May be negative if `self.shape.rank` is statically known.\n",
      "     |        inner_axis: `int`: The last dimension in the range of dimensions to merge.\n",
      "     |          May be negative if `self.shape.rank` is statically known.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this tensor, with the specified dimensions merged into a\n",
      "     |        single dimension.  The shape of the returned tensor will be\n",
      "     |        `self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]`, where `N`\n",
      "     |        is the total number of slices in the merged dimensions.\n",
      "     |  \n",
      "     |  nested_row_lengths(self, name=None)\n",
      "     |      Returns a tuple containing the row_lengths for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_lengths()` is a tuple containing the `row_lengths` tensors\n",
      "     |      for all ragged dimensions in `rt`, ordered from outermost to innermost.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensors`.  The length of the tuple is equal to\n",
      "     |        `self.ragged_rank`.\n",
      "     |  \n",
      "     |  nested_value_rowids(self, name=None)\n",
      "     |      Returns a tuple containing the value_rowids for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_value_rowids` is a tuple containing the `value_rowids` tensors\n",
      "     |      for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_value_rowids = (rt.value_rowids(),) + value_ids`\n",
      "     |      where:\n",
      "     |      \n",
      "     |      * `value_ids = ()` if `rt.values` is a `Tensor`.\n",
      "     |      * `value_ids = rt.values.nested_value_rowids` otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, ids in enumerate(rt.nested_value_rowids()):\n",
      "     |      ...   print('row ids for dimension %d: %s' % (i+1, ids.numpy()))\n",
      "     |      row ids for dimension 1: [0 0 0]\n",
      "     |      row ids for dimension 2: [0 0 0 2 2]\n",
      "     |      row ids for dimension 3: [0 0 0 0 2 2 2 3]\n",
      "     |  \n",
      "     |  nrows(self, out_type=None, name=None)\n",
      "     |      Returns the number of rows in this ragged tensor.\n",
      "     |      \n",
      "     |      I.e., the size of the outermost dimension of the tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar `Tensor` with dtype `out_type`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.nrows())  # rt has 5 rows.\n",
      "     |      tf.Tensor(5, shape=(), dtype=int64)\n",
      "     |  \n",
      "     |  numpy(self)\n",
      "     |      Returns a numpy `array` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that this `RaggedTensor` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Ragged dimensions are encoded using numpy `arrays` with `dtype=object` and\n",
      "     |      `rank=1`, where each element is a single row.\n",
      "     |      \n",
      "     |      #### Examples\n",
      "     |      \n",
      "     |      In the following example, the value returned by `RaggedTensor.numpy()`\n",
      "     |      contains three numpy `array` objects: one for each row (with `rank=1` and\n",
      "     |      `dtype=int64`), and one to combine them (with `rank=1` and `dtype=object`):\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5]], dtype=tf.int64).numpy()\n",
      "     |      array([array([1, 2, 3]), array([4, 5])], dtype=object)\n",
      "     |      \n",
      "     |      Uniform dimensions are encoded using multidimensional numpy `array`s.  In\n",
      "     |      the following example, the value returned by `RaggedTensor.numpy()` contains\n",
      "     |      a single numpy `array` object, with `rank=2` and `dtype=int64`:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int64).numpy()\n",
      "     |      array([[1, 2, 3], [4, 5, 6]])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `array`.\n",
      "     |  \n",
      "     |  row_lengths(self, axis=1, name=None)\n",
      "     |      Returns the lengths of the rows in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.row_lengths()[i]` indicates the number of values in the\n",
      "     |      `i`th row of `rt`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer constant indicating the axis whose row lengths should be\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged integer Tensor with shape `self.shape[:axis]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `axis` is out of bounds.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])\n",
      "     |      >>> print(rt.row_lengths())  # lengths of rows in rt\n",
      "     |      tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64)\n",
      "     |      >>> print(rt.row_lengths(axis=2))  # lengths of axis=2 rows.\n",
      "     |      <tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>\n",
      "     |  \n",
      "     |  row_limits(self, name=None)\n",
      "     |      Returns the limit indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row end in\n",
      "     |      `self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_limits())  # indices of row limits in rt.values\n",
      "     |      tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  row_starts(self, name=None)\n",
      "     |      Returns the start indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row begin in\n",
      "     |      `self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_starts())  # indices of row starts in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  to_list(self)\n",
      "     |      Returns a nested Python `list` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that `rt` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A nested Python `list`.\n",
      "     |  \n",
      "     |  to_sparse(self, name=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]])\n",
      "     |      >>> print(rt.to_sparse())\n",
      "     |      SparseTensor(indices=tf.Tensor(\n",
      "     |                       [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]],\n",
      "     |                       shape=(6, 2), dtype=int64),\n",
      "     |                   values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32),\n",
      "     |                   dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A SparseTensor with the same values as `self`.\n",
      "     |  \n",
      "     |  to_tensor(self, default_value=None, name=None, shape=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.Tensor`.\n",
      "     |      \n",
      "     |      If `shape` is specified, then the result is padded and/or truncated to\n",
      "     |      the specified shape.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
      "     |      >>> print(rt.to_tensor())\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32)\n",
      "     |      >>> print(rt.to_tensor(shape=[5, 2]))\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        default_value: Value to set for indices not specified in `self`. Defaults\n",
      "     |          to zero.  `default_value` must be broadcastable to\n",
      "     |          `self.shape[self.ragged_rank + 1:]`.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        shape: The shape of the resulting dense tensor.  In particular,\n",
      "     |          `result.shape[i]` is `shape[i]` (if `shape[i]` is not None), or\n",
      "     |          `self.bounding_shape(i)` (otherwise).`shape.rank` must be `None` or\n",
      "     |          equal to `self.rank`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` with shape `ragged.bounding_shape(self)` and the\n",
      "     |        values specified by the non-empty values in `self`.  Empty values are\n",
      "     |        assigned `default_value`.\n",
      "     |  \n",
      "     |  value_rowids(self, name=None)\n",
      "     |      Returns the row indices for the `values` in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.value_rowids()` corresponds one-to-one with the outermost dimension of\n",
      "     |      `rt.values`, and specifies the row containing each value.  In particular,\n",
      "     |      the row `rt[row]` consists of the values `rt.values[j]` where\n",
      "     |      `rt.value_rowids()[j] == row`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `self.values.shape[:1]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.value_rowids())  # corresponds 1:1 with rt.values\n",
      "     |      tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64)\n",
      "     |  \n",
      "     |  with_flat_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `flat_values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor that should replace\n",
      "     |          `self.flat_values`.  Must have `rank > 0`, and must have the same number\n",
      "     |          of rows as `self.flat_values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.\n",
      "     |        `result.rank = self.ragged_rank + new_values.rank`.\n",
      "     |        `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.\n",
      "     |  \n",
      "     |  with_row_splits_dtype(self, dtype)\n",
      "     |      Returns a copy of this RaggedTensor with the given `row_splits` dtype.\n",
      "     |      \n",
      "     |      For RaggedTensors with multiple ragged dimensions, the `row_splits` for all\n",
      "     |      nested `RaggedTensor` objects are cast to the given dtype.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: The dtype for `row_splits`.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this RaggedTensor, with the `row_splits` cast to the given\n",
      "     |        type.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor to use as the `values` for the\n",
      "     |          returned `RaggedTensor`.  Must have `rank > 0`, and must have the same\n",
      "     |          number of rows as `self.values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.\n",
      "     |        `result.ragged_rank = 1 + new_values.ragged_rank`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_nested_row_lengths(flat_values, nested_row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_lengths in reversed(nested_row_lengths):\n",
      "     |        result = from_row_lengths(result, row_lengths)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_lengths: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_lengths` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).\n",
      "     |  \n",
      "     |  from_nested_row_splits(flat_values, nested_row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_splits` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_splits in reversed(nested_row_splits):\n",
      "     |        result = from_row_splits(result, row_splits)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_splits: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_splits` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).\n",
      "     |  \n",
      "     |  from_nested_value_rowids(flat_values, nested_value_rowids, nested_nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):\n",
      "     |        result = from_value_rowids(result, rowids, nrows)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_value_rowids: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `value_rowids` for the `i`th ragged dimension.\n",
      "     |        nested_nrows: A list of integer scalars.  The `i`th scalar is used as the\n",
      "     |          `nrows` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.\n",
      "     |  \n",
      "     |  from_row_lengths(values, row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_lengths`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values.pop(0) for i in range(length)]\n",
      "     |                for length in row_lengths]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_lengths: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative.  `sum(row_lengths)` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_lengths(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_lengths=[4, 0, 3, 1, 0]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_limits(values, row_limits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_limits`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_limits: A 1-D integer tensor with shape `[nrows]`.  Must be sorted in\n",
      "     |          ascending order.  If `nrows>0`, then `row_limits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_limits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_limits=[4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_splits(values, row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_splits`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [values[row_splits[i]:row_splits[i + 1]]\n",
      "     |                for i in range(len(row_splits) - 1)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_splits: A 1-D integer tensor with shape `[nrows+1]`.  Must not be\n",
      "     |          empty, and must be sorted in ascending order.  `row_splits[0]` must be\n",
      "     |          zero and `row_splits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `row_splits` is an empty list.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_starts(values, row_starts, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_starts`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_starts: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative and sorted in ascending order.  If `nrows>0`, then\n",
      "     |          `row_starts[0]` must be zero.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_starts(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_starts=[0, 4, 4, 7, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_sparse(st_input, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a 2D `tf.sparse.SparseTensor` to a `RaggedTensor`.\n",
      "     |      \n",
      "     |      Each row of the `output` `RaggedTensor` will contain the explicit values\n",
      "     |      from the same row in `st_input`.  `st_input` must be ragged-right.  If not\n",
      "     |      it is not ragged-right, then an error will be generated.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]\n",
      "     |      >>> st = tf.sparse.SparseTensor(indices=indices,\n",
      "     |      ...                             values=[1, 2, 3, 4, 5],\n",
      "     |      ...                             dense_shape=[4, 3])\n",
      "     |      >>> tf.RaggedTensor.from_sparse(st).to_list()\n",
      "     |      [[1, 2, 3], [4], [], [5]]\n",
      "     |      \n",
      "     |      Currently, only two-dimensional `SparseTensors` are supported.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        st_input: The sparse tensor to convert.  Must have rank 2.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the same values as `st_input`.\n",
      "     |        `output.ragged_rank = rank(st_input) - 1`.\n",
      "     |        `output.shape = [st_input.dense_shape[0], None]`.\n",
      "     |      Raises:\n",
      "     |        ValueError: If the number of dimensions in `st_input` is not known\n",
      "     |          statically, or is not two.\n",
      "     |  \n",
      "     |  from_tensor(tensor, lengths=None, padding=None, ragged_rank=1, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a `tf.Tensor` into a `RaggedTensor`.\n",
      "     |      \n",
      "     |      The set of absent/default values may be specified using a vector of lengths\n",
      "     |      or a padding value (but not both).  If `lengths` is specified, then the\n",
      "     |      output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`. If\n",
      "     |      'lengths' is a list of lists or tuple of lists, those lists will be used\n",
      "     |      as nested row lengths. If `padding` is specified, then any row *suffix*\n",
      "     |      consisting entirely of `padding` will be excluded from the returned\n",
      "     |      `RaggedTensor`.  If neither `lengths` nor `padding` is specified, then the\n",
      "     |      returned `RaggedTensor` will have no absent/default values.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt)\n",
      "     |      <tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])\n",
      "     |      <tf.RaggedTensor [[5], [], [6, 0, 0]]>\n",
      "     |      \n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, padding=0)\n",
      "     |      <tf.RaggedTensor [[5, 7], [0, 3], [6]]>\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[[5, 0], [7, 0], [0, 0]],\n",
      "     |      ...                   [[0, 0], [3, 0], [0, 0]],\n",
      "     |      ...                   [[6, 0], [0, 0], [0, 0]]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))\n",
      "     |      <tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or\n",
      "     |          higher.\n",
      "     |        lengths: An optional set of row lengths, specified using a 1-D integer\n",
      "     |          `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows\n",
      "     |          in `tensor`).  If specified, then `output[row]` will contain\n",
      "     |          `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero. You\n",
      "     |            may optionally pass a list or tuple of lengths to this argument, which\n",
      "     |            will be used as nested row lengths to construct a ragged tensor with\n",
      "     |            multiple ragged dimensions.\n",
      "     |        padding: An optional padding value.  If specified, then any row suffix\n",
      "     |          consisting entirely of `padding` will be excluded from the returned\n",
      "     |          RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`\n",
      "     |          and with `shape=tensor.shape[ragged_rank + 1:]`.\n",
      "     |        ragged_rank: Integer specifying the ragged rank for the returned\n",
      "     |          `RaggedTensor`.  Must be greater than zero.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the specified `ragged_rank`.  The shape of the\n",
      "     |        returned ragged tensor is compatible with the shape of `tensor`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `lengths` and `padding` are specified.\n",
      "     |        ValueError: If the rank of `tensor` is 0 or 1.\n",
      "     |  \n",
      "     |  from_uniform_row_length(values, uniform_row_length, nrows=None, validate=True, name=None) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `uniform_row_length`.\n",
      "     |      \n",
      "     |      This method can be used to create `RaggedTensor`s with multiple uniform\n",
      "     |      outer dimensions.  For example, a `RaggedTensor` with shape `[2, 2, None]`\n",
      "     |      can be constructed with this method from a `RaggedTensor` values with shape\n",
      "     |      `[4, None]`:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(values.shape)\n",
      "     |      (4, None)\n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> print(rt1)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt1.shape)\n",
      "     |      (2, 2, None)\n",
      "     |      \n",
      "     |      Note that `rt1` only contains one ragged dimension (the innermost\n",
      "     |      dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |      `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |      >>> print(rt2.shape)\n",
      "     |      (2, None, None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        uniform_row_length: A scalar integer tensor.  Must be nonnegative. The\n",
      "     |          size of the outer axis of `values` must be evenly divisible by\n",
      "     |          `uniform_row_length`.\n",
      "     |        nrows: The number of rows in the constructed RaggedTensor.  If not\n",
      "     |          specified, then it defaults to `nvals/uniform_row_length` (or `0` if\n",
      "     |          `uniform_row_length==0`).  `nrows` only needs to be specified if\n",
      "     |          `uniform_row_length` might be zero.  `uniform_row_length*nrows` must be\n",
      "     |          `nvals`.\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` that corresponds with the python list defined by:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        result = [[values.pop(0) for i in range(uniform_row_length)]\n",
      "     |                  for _ in range(nrows)]\n",
      "     |        ```\n",
      "     |      \n",
      "     |        `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |  \n",
      "     |  from_value_rowids(values, value_rowids, nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `value_rowids`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]\n",
      "     |                for row in range(nrows)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        value_rowids: A 1-D integer tensor with shape `[nvals]`, which corresponds\n",
      "     |          one-to-one with `values`, and specifies each value's row index.  Must be\n",
      "     |          nonnegative, and must be sorted in ascending order.\n",
      "     |        nrows: An integer scalar specifying the number of rows.  This should be\n",
      "     |          specified if the `RaggedTensor` may containing empty training rows. Must\n",
      "     |          be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).\n",
      "     |          Defaults to `value_rowids[-1] + 1` (or zero if `value_rowids` is empty).\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `nrows` is incompatible with `value_rowids`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_value_rowids(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],\n",
      "     |      ...     nrows=5))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of values in this tensor.\n",
      "     |  \n",
      "     |  flat_values\n",
      "     |      The innermost `values` tensor for this ragged tensor.\n",
      "     |      \n",
      "     |      Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is\n",
      "     |      `rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.\n",
      "     |      \n",
      "     |      Conceptually, `flat_values` is the tensor formed by flattening the\n",
      "     |      outermost dimension and all of the ragged dimensions into a single\n",
      "     |      dimension.\n",
      "     |      \n",
      "     |      `rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`\n",
      "     |      (where `nvals` is the number of items in the flattened dimensions).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])\n",
      "     |      >>> print(rt.flat_values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  nested_row_splits\n",
      "     |      A tuple containing the row_splits for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_splits` is a tuple containing the `row_splits` tensors for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:\n",
      "     |      \n",
      "     |          * `value_splits = ()` if `rt.values` is a `Tensor`.\n",
      "     |          * `value_splits = rt.values.nested_row_splits` otherwise.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, splits in enumerate(rt.nested_row_splits):\n",
      "     |      ...   print('Splits for dimension %d: %s' % (i+1, splits.numpy()))\n",
      "     |      Splits for dimension 1: [0 3]\n",
      "     |      Splits for dimension 2: [0 3 3 5]\n",
      "     |      Splits for dimension 3: [0 4 4 7 8 8]\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> values.ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> rt.ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits\n",
      "     |      The row-split indices for this ragged tensor's `values`.\n",
      "     |      \n",
      "     |      `rt.row_splits` specifies where the values for each row begin and end in\n",
      "     |      `rt.values`.  In particular, the values for row `rt[i]` are stored in\n",
      "     |      the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `[self.nrows+1]`.\n",
      "     |        The returned tensor is non-empty, and is sorted in ascending order.\n",
      "     |        `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to\n",
      "     |        `self.values.shape[0]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.row_splits)  # indices of row splits in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  uniform_row_length\n",
      "     |      The length of each row in this ragged tensor, or None if rows are ragged.\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(rt1.uniform_row_length)  # rows are ragged.\n",
      "     |      None\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_uniform_row_length(\n",
      "     |      ...     values=rt1, uniform_row_length=2)\n",
      "     |      >>> print(rt2)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).\n",
      "     |      tf.Tensor(2, shape=(), dtype=int64)\n",
      "     |      \n",
      "     |      A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged)\n",
      "     |      if it can be determined statically (at graph construction time) that the\n",
      "     |      rows all have the same length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar integer `Tensor`, specifying the length of every row in this\n",
      "     |        ragged tensor (for ragged tensors whose rows are uniform); or `None`\n",
      "     |        (for ragged tensors whose rows are ragged).\n",
      "     |  \n",
      "     |  values\n",
      "     |      The concatenated rows for this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.values` is a potentially ragged tensor formed by flattening the two\n",
      "     |      outermost dimensions of `rt` into a single dimension.\n",
      "     |      \n",
      "     |      `rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the\n",
      "     |      number of items in the outer two dimensions of `rt`).\n",
      "     |      \n",
      "     |      `rt.ragged_rank = self.ragged_rank - 1`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged tensor.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.composite_tensor...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  RaggedTensorSpec(shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |      Constructs a type specification for a `tf.RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The shape of the RaggedTensor, or `None` to allow any shape.  If a\n",
      "     |          shape is specified, then all ragged dimensions must have size `None`.\n",
      "     |        dtype: `tf.DType` of values in the RaggedTensor.\n",
      "     |        ragged_rank: Python integer, the number of times the RaggedTensor's\n",
      "     |          flat_values is partitioned.  Defaults to `shape.ndims - 1`.\n",
      "     |        row_splits_dtype: `dtype` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        flat_values_spec: TypeSpec for flat_value of the RaggedTensor. It shall be\n",
      "     |          provided when the flat_values is a CompositeTensor rather then Tensor.\n",
      "     |          If both `dtype` and `flat_values_spec` and  are provided, `dtype` must\n",
      "     |          be the same as `flat_values_spec.dtype`. (experimental)\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[\"a\"], [\"b\", \"c\"]], dtype=tf.string)\n",
      "     |      >>> tf.type_spec_from_value(rt).dtype\n",
      "     |      tf.string\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` of the values in the RaggedTensor.\n",
      "     |  \n",
      "     |  flat_values_spec\n",
      "     |      The `TypeSpec` of the flat_values of RaggedTensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        - The TypeSpec of flat_values.\n",
      "     |        - None when the flat_values is a Tensor.\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Defaults to `shape.ndims - 1`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> tf.type_spec_from_value(values).ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> tf.type_spec_from_value(rt1).ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits_dtype\n",
      "     |      The `tf.dtypes.DType` of the RaggedTensor's `row_splits`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4]], row_splits_dtype=tf.int64)\n",
      "     |      >>> tf.type_spec_from_value(rt).row_splits_dtype\n",
      "     |      tf.int64\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |        of `tf.int32` or `tf.int64`.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[0], [1, 2]])\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1)\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` containing the statically known shape of the\n",
      "     |        RaggedTensor. Ragged dimensions have a size of `None`.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RegisterGradient(builtins.object)\n",
      "     |  RegisterGradient(op_type)\n",
      "     |  \n",
      "     |  A decorator for registering the gradient function for an op type.\n",
      "     |  \n",
      "     |  This decorator is only used when defining a new op type. For an op\n",
      "     |  with `m` inputs and `n` outputs, the gradient function is a function\n",
      "     |  that takes the original `Operation` and `n` `Tensor` objects\n",
      "     |  (representing the gradients with respect to each output of the op),\n",
      "     |  and returns `m` `Tensor` objects (representing the partial gradients\n",
      "     |  with respect to each input of the op).\n",
      "     |  \n",
      "     |  For example, assuming that operations of type `\"Sub\"` take two\n",
      "     |  inputs `x` and `y`, and return a single output `x - y`, the\n",
      "     |  following gradient function would be registered:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  @tf.RegisterGradient(\"Sub\")\n",
      "     |  def _sub_grad(unused_op, grad):\n",
      "     |    return grad, tf.negative(grad)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The decorator argument `op_type` is the string type of an\n",
      "     |  operation. This corresponds to the `OpDef.name` field for the proto\n",
      "     |  that defines the operation.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, f)\n",
      "     |      Registers the function `f` as gradient function for `op_type`.\n",
      "     |  \n",
      "     |  __init__(self, op_type)\n",
      "     |      Creates a new decorator with `op_type` as the Operation type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The string type of an operation. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type` is not string.\n",
      "    \n",
      "    class SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  SparseTensor(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Represents a sparse tensor.\n",
      "     |  \n",
      "     |  TensorFlow represents a sparse tensor as three separate dense tensors:\n",
      "     |  `indices`, `values`, and `dense_shape`.  In Python, the three tensors are\n",
      "     |  collected into a `SparseTensor` class for ease of use.  If you have separate\n",
      "     |  `indices`, `values`, and `dense_shape` tensors, wrap them in a `SparseTensor`\n",
      "     |  object before passing to the ops below.\n",
      "     |  \n",
      "     |  Concretely, the sparse tensor `SparseTensor(indices, values, dense_shape)`\n",
      "     |  comprises the following components, where `N` and `ndims` are the number\n",
      "     |  of values and number of dimensions in the `SparseTensor`, respectively:\n",
      "     |  \n",
      "     |  * `indices`: A 2-D int64 tensor of shape `[N, ndims]`, which specifies the\n",
      "     |    indices of the elements in the sparse tensor that contain nonzero values\n",
      "     |    (elements are zero-indexed). For example, `indices=[[1,3], [2,4]]` specifies\n",
      "     |    that the elements with indexes of [1,3] and [2,4] have nonzero values.\n",
      "     |  \n",
      "     |  * `values`: A 1-D tensor of any type and shape `[N]`, which supplies the\n",
      "     |    values for each element in `indices`. For example, given `indices=[[1,3],\n",
      "     |    [2,4]]`, the parameter `values=[18, 3.6]` specifies that element [1,3] of\n",
      "     |    the sparse tensor has a value of 18, and element [2,4] of the tensor has a\n",
      "     |    value of 3.6.\n",
      "     |  \n",
      "     |  * `dense_shape`: A 1-D int64 tensor of shape `[ndims]`, which specifies the\n",
      "     |    dense_shape of the sparse tensor. Takes a list indicating the number of\n",
      "     |    elements in each dimension. For example, `dense_shape=[3,6]` specifies a\n",
      "     |    two-dimensional 3x6 tensor, `dense_shape=[2,3,4]` specifies a\n",
      "     |    three-dimensional 2x3x4 tensor, and `dense_shape=[9]` specifies a\n",
      "     |    one-dimensional tensor with 9 elements.\n",
      "     |  \n",
      "     |  The corresponding dense tensor satisfies:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense.shape = dense_shape\n",
      "     |  dense[tuple(indices[i])] = values[i]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By convention, `indices` should be sorted in row-major order (or equivalently\n",
      "     |  lexicographic order on the tuples `indices[i]`). This is not enforced when\n",
      "     |  `SparseTensor` objects are constructed, but most ops assume correct ordering.\n",
      "     |  If the ordering of sparse tensor `st` is wrong, a fixed version can be\n",
      "     |  obtained by calling `tf.sparse.reorder(st)`.\n",
      "     |  \n",
      "     |  Example: The sparse tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  represents the dense tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  [[1, 0, 0, 0]\n",
      "     |   [0, 0, 2, 0]\n",
      "     |   [0, 0, 0, 0]]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise divides a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      \n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |      \n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __init__(self, indices, values, dense_shape)\n",
      "     |      Creates a `SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A 2-D int64 tensor of shape `[N, ndims]`.\n",
      "     |        values: A 1-D tensor of any type and shape `[N]`.\n",
      "     |        dense_shape: A 1-D int64 tensor of shape `[ndims]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: When building an eager SparseTensor if `dense_shape` is\n",
      "     |          unknown or contains unknown elements (None or -1).\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise multiplies a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      The output locations corresponding to the implicitly zero elements in the sparse\n",
      "     |      \n",
      "     |      tensor will be zero (i.e., will not take up storage space), regardless of the\n",
      "     |      \n",
      "     |      contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      \n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |      \n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Internal helper function for 'sp_t / dense_t'.\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this sparse tensor in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this sparse\n",
      "     |          tensor. If none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensorValue` object.\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> st = tf.SparseTensor(\n",
      "     |      ...   indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |      >>> st.set_shape([3, 4])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> st.set_shape([3, None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> st.set_shape([1, 4])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (3, 4) is not compatible with supplied\n",
      "     |      shape [1, 4]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `SparseTensor.set_shape` will *merge* the given `shape`\n",
      "     |      with the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> st = tf.keras.Input(shape=[None, None, 3], sparse=True)\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> st.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_values`.\n",
      "     |      \n",
      "     |      This method produces a new `SparseTensor` that has the same nonzero\n",
      "     |      `indices` and same `dense_shape`, but updated values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: The values of the new `SparseTensor`. Needs to have the same\n",
      "     |          shape as the current `.values` `Tensor`. May have a different type than\n",
      "     |          the current `values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensor` with identical indices and shape but updated values.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      >>> st = tf.sparse.from_dense([[1, 0, 2, 0], [3, 0, 0, 4]])\n",
      "     |      >>> tf.sparse.to_dense(st.with_values([10, 20, 30, 40]))  # 4 nonzero values\n",
      "     |      <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "     |      array([[10,  0, 20,  0],\n",
      "     |             [30,  0,  0, 40]], dtype=int32)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(sparse_tensor_value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D Tensor of int64 representing the shape of the dense tensor.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the index, value, and dense_shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      The indices of non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 2-D Tensor of int64 with dense_shape `[N, ndims]`, where `N` is the\n",
      "     |          number of non-zero values in the tensor, and `ndims` is the rank.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      The non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D Tensor of any data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class SparseTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  SparseTensorSpec(shape=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Type specification for a `tf.sparse.SparseTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32)\n",
      "     |      Constructs a type specification for a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `SparseTensor`, or `None` to allow any dense\n",
      "     |          shape.\n",
      "     |        dtype: `tf.DType` of values in the `SparseTensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `tf.TensorShape` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Tensor(tensorflow.python.client._pywrap_tf_session.PyTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "     |  A `tf.Tensor` represents a multidimensional array of elements.\n",
      "     |  \n",
      "     |  All elements are of a single known data type.\n",
      "     |  \n",
      "     |  When writing a TensorFlow program, the main object that is\n",
      "     |  manipulated and passed around is the `tf.Tensor`.\n",
      "     |  \n",
      "     |  A `tf.Tensor` has the following properties:\n",
      "     |  \n",
      "     |  * a single data type (float32, int32, or string, for example)\n",
      "     |  * a shape\n",
      "     |  \n",
      "     |  TensorFlow supports eager execution and graph execution.  In eager\n",
      "     |  execution, operations are evaluated immediately.  In graph\n",
      "     |  execution, a computational graph is constructed for later\n",
      "     |  evaluation.\n",
      "     |  \n",
      "     |  TensorFlow defaults to eager execution.  In the example below, the\n",
      "     |  matrix multiplication results are calculated immediately.\n",
      "     |  \n",
      "     |  >>> # Compute some values using a Tensor\n",
      "     |  >>> c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
      "     |  >>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
      "     |  >>> e = tf.matmul(c, d)\n",
      "     |  >>> print(e)\n",
      "     |  tf.Tensor(\n",
      "     |  [[1. 3.]\n",
      "     |   [3. 7.]], shape=(2, 2), dtype=float32)\n",
      "     |  \n",
      "     |  Note that during eager execution, you may discover your `Tensors` are actually\n",
      "     |  of type `EagerTensor`.  This is an internal detail, but it does give you\n",
      "     |  access to a useful function, `numpy`:\n",
      "     |  \n",
      "     |  >>> type(e)\n",
      "     |  <class '...ops.EagerTensor'>\n",
      "     |  >>> print(e.numpy())\n",
      "     |    [[1. 3.]\n",
      "     |     [3. 7.]]\n",
      "     |  \n",
      "     |  In TensorFlow, `tf.function`s are a common way to define graph execution.\n",
      "     |  \n",
      "     |  A Tensor's shape (that is, the rank of the Tensor and the size of\n",
      "     |  each dimension) may not always be fully known.  In `tf.function`\n",
      "     |  definitions, the shape may only be partially known.\n",
      "     |  \n",
      "     |  Most operations produce tensors of fully-known shapes if the shapes of their\n",
      "     |  inputs are also fully known, but in some cases it's only possible to find the\n",
      "     |  shape of a tensor at execution time.\n",
      "     |  \n",
      "     |  A number of specialized tensors are available: see `tf.Variable`,\n",
      "     |  `tf.constant`, `tf.placeholder`, `tf.sparse.SparseTensor`, and\n",
      "     |  `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Caution: when constructing a tensor from a numpy array or pandas dataframe\n",
      "     |  the underlying buffer may be re-used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = np.array([1, 2, 3])\n",
      "     |  b = tf.constant(a)\n",
      "     |  a[0] = 4\n",
      "     |  print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note: this is an implementation detail that is subject to change and users\n",
      "     |  should not rely on this behaviour.\n",
      "     |  \n",
      "     |  For more on Tensors, see the [guide](https://tensorflow.org/guide/tensor).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.types.core.Symbol\n",
      "     |      tensorflow.python.types.core.Tensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(x, name=None)\n",
      "     |      Computes the absolute value of a tensor.\n",
      "     |      \n",
      "     |      Given a tensor of integer or floating-point values, this operation returns a\n",
      "     |      tensor of the same type, where each element contains the absolute value of the\n",
      "     |      corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "     |      `float32` or `float64` that is the absolute value of each element in `x`. For\n",
      "     |      a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "     |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # real number\n",
      "     |      >>> x = tf.constant([-2.25, 3.25])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=float32,\n",
      "     |      numpy=array([2.25, 3.25], dtype=float32)>\n",
      "     |      \n",
      "     |      >>> # complex number\n",
      "     |      >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "     |      array([[5.25594901],\n",
      "     |             [6.60492241]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "     |          `int32`, `int64`, `complex64` or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
      "     |          with absolute values. Note, for `complex64` or `complex128` input, the\n",
      "     |          returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |      The operation invoked by the `Tensor.__add__` operator.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: The left-hand side of the `+` operator.\n",
      "     |        y: The right-hand side of the `+` operator.\n",
      "     |        name: an optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `+` operation.\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This overload raises a `TypeError` when the user inadvertently\n",
      "     |      treats a `Tensor` as a boolean (most commonly in an `if` or `while`\n",
      "     |      statement), in code that was not converted by AutoGraph. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      if tf.constant(True):  # Will raise.\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      if tf.constant(5) < tf.constant(7):  # Will raise.\n",
      "     |        # ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__ = tensor_equals(self, other)\n",
      "     |      The operation invoked by the `Tensor.__eq__` operator.\n",
      "     |      \n",
      "     |      Compares two tensors element-wise for equality if they are\n",
      "     |      broadcast-compatible; or returns False if they are not broadcast-compatible.\n",
      "     |      (Note that this behavior differs from `tf.math.equal`, which raises an\n",
      "     |      exception if the two tensors are not broadcast-compatible.)\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__eq__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The left-hand side of the `==` operator.\n",
      "     |        other: The right-hand side of the `==` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `==` operation, or `False` if the arguments\n",
      "     |        are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      \n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper(tensor, slice_spec, var=None)\n",
      "     |      Overload for Tensor.__getitem__.\n",
      "     |      \n",
      "     |      This operation extracts the specified region from the tensor.\n",
      "     |      The notation is similar to NumPy with the restriction that\n",
      "     |      currently only support basic indexing. That means that\n",
      "     |      using a non-scalar tensor as input is not currently allowed.\n",
      "     |      \n",
      "     |      Some useful examples:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Strip leading and trailing 2 elements\n",
      "     |      foo = tf.constant([1,2,3,4,5,6])\n",
      "     |      print(foo[2:-2])  # => [3,4]\n",
      "     |      \n",
      "     |      # Skip every other row and reverse the order of the columns\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[::2,::-1])  # => [[3,2,1], [9,8,7]]\n",
      "     |      \n",
      "     |      # Use scalar tensors as indices on both dimensions\n",
      "     |      print(foo[tf.constant(0), tf.constant(2)])  # => 3\n",
      "     |      \n",
      "     |      # Insert another dimension\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :]) # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[:, tf.newaxis, :]) # => [[[1,2,3]], [[4,5,6]], [[7,8,9]]]\n",
      "     |      print(foo[:, :, tf.newaxis]) # => [[[1],[2],[3]], [[4],[5],[6]],\n",
      "     |      [[7],[8],[9]]]\n",
      "     |      \n",
      "     |      # Ellipses (3 equivalent operations)\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis, ...])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      \n",
      "     |      # Masks\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[foo > 2])  # => [3, 4, 5, 6, 7, 8, 9]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |        - `tf.newaxis` is `None` as in NumPy.\n",
      "     |        - An implicit ellipsis is placed at the end of the `slice_spec`\n",
      "     |        - NumPy advanced indexing is currently not supported.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__getitem__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: An ops.Tensor object.\n",
      "     |        slice_spec: The arguments to Tensor.__getitem__.\n",
      "     |        var: In the case of variable slice assignment, the Variable object to slice\n",
      "     |          (i.e. tensor is the read-only view of this variable).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: If the slice indices aren't int, slice, ellipsis,\n",
      "     |          tf.newaxis or scalar int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = invert_(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "     |      and any further outer dimensions specify matching batch size.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |      `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      A simple 2-D tensor matrix multiplication:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      >>> a  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]], dtype=int32)>\n",
      "     |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      >>> b  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[ 7,  8],\n",
      "     |             [ 9, 10],\n",
      "     |             [11, 12]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "     |      array([[ 58,  64],\n",
      "     |             [139, 154]], dtype=int32)>\n",
      "     |      \n",
      "     |      A batch matrix multiplication with batch shape [2]:\n",
      "     |      \n",
      "     |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "     |      >>> a  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "     |      array([[[ 1,  2,  3],\n",
      "     |              [ 4,  5,  6]],\n",
      "     |             [[ 7,  8,  9],\n",
      "     |              [10, 11, 12]]], dtype=int32)>\n",
      "     |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "     |      >>> b  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "     |      array([[[13, 14],\n",
      "     |              [15, 16],\n",
      "     |              [17, 18]],\n",
      "     |             [[19, 20],\n",
      "     |              [21, 22],\n",
      "     |              [23, 24]]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "     |      array([[[ 94, 100],\n",
      "     |              [229, 244]],\n",
      "     |             [[508, 532],\n",
      "     |              [697, 730]]], dtype=int32)>\n",
      "     |      \n",
      "     |      Since python >= 3.5 the @ operator is supported\n",
      "     |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "     |      it simply calls the `tf.matmul()` function, so the following lines are\n",
      "     |      equivalent:\n",
      "     |      \n",
      "     |      >>> d = a @ b @ [[10], [11]]\n",
      "     |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "     |          `complex64`, `complex128` and rank > 1.\n",
      "     |        b: `tf.Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `a` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `b` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        output_type: The output datatype if needed. Defaults to None in which case\n",
      "     |          the output_type is the same as input type. Currently only works when input\n",
      "     |          tensors are type (u)int8 and output_type can be int32.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "     |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "     |        for all indices `i`, `j`.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "     |          `adjoint_b` are both set to `True`.\n",
      "     |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "     |          `output_type` is not (u)int8, (u)int8 and int32.\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ne__ = tensor_not_equals(self, other)\n",
      "     |      The operation invoked by the `Tensor.__ne__` operator.\n",
      "     |      \n",
      "     |      Compares two tensors element-wise for inequality if they are\n",
      "     |      broadcast-compatible; or returns True if they are not broadcast-compatible.\n",
      "     |      (Note that this behavior differs from `tf.math.not_equal`, which raises an\n",
      "     |      exception if the two tensors are not broadcast-compatible.)\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__ne__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The left-hand side of the `!=` operator.\n",
      "     |        other: The right-hand side of the `!=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `!=` operation, or `True` if the arguments\n",
      "     |        are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This is the Python 2.x counterpart to `__bool__()` above.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |      The operation invoked by the `Tensor.__add__` operator.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: The left-hand side of the `+` operator.\n",
      "     |        y: The right-hand side of the `+` operator.\n",
      "     |        name: an optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `+` operation.\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "     |      and any further outer dimensions specify matching batch size.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |      `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      A simple 2-D tensor matrix multiplication:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      >>> a  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]], dtype=int32)>\n",
      "     |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      >>> b  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[ 7,  8],\n",
      "     |             [ 9, 10],\n",
      "     |             [11, 12]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "     |      array([[ 58,  64],\n",
      "     |             [139, 154]], dtype=int32)>\n",
      "     |      \n",
      "     |      A batch matrix multiplication with batch shape [2]:\n",
      "     |      \n",
      "     |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "     |      >>> a  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "     |      array([[[ 1,  2,  3],\n",
      "     |              [ 4,  5,  6]],\n",
      "     |             [[ 7,  8,  9],\n",
      "     |              [10, 11, 12]]], dtype=int32)>\n",
      "     |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "     |      >>> b  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "     |      array([[[13, 14],\n",
      "     |              [15, 16],\n",
      "     |              [17, 18]],\n",
      "     |             [[19, 20],\n",
      "     |              [21, 22],\n",
      "     |              [23, 24]]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "     |      array([[[ 94, 100],\n",
      "     |              [229, 244]],\n",
      "     |             [[508, 532],\n",
      "     |              [697, 730]]], dtype=int32)>\n",
      "     |      \n",
      "     |      Since python >= 3.5 the @ operator is supported\n",
      "     |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "     |      it simply calls the `tf.matmul()` function, so the following lines are\n",
      "     |      equivalent:\n",
      "     |      \n",
      "     |      >>> d = a @ b @ [[10], [11]]\n",
      "     |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "     |          `complex64`, `complex128` and rank > 1.\n",
      "     |        b: `tf.Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `a` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `b` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        output_type: The output datatype if needed. Defaults to None in which case\n",
      "     |          the output_type is the same as input type. Currently only works when input\n",
      "     |          tensors are type (u)int8 and output_type can be int32.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "     |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "     |        for all indices `i`, `j`.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "     |          `adjoint_b` are both set to `True`.\n",
      "     |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "     |          `output_type` is not (u)int8, (u)int8 and int32.\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __round__ = around(a, decimals=0)\n",
      "     |      TensorFlow variant of NumPy's `around`.\n",
      "     |      \n",
      "     |      Unsupported arguments: `out`.\n",
      "     |      \n",
      "     |      See the NumPy documentation for [`numpy.around`](https://numpy.org/doc/1.16/reference/generated/numpy.around.html).\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype: Union[tensorflow.python.framework.dtypes.DType, NoneType] = None, name: Union[str, NoneType] = None) -> 'Tensor'\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, signature_context)\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this tensor in a `Session`.\n",
      "     |      \n",
      "     |      Note: If you are not using `compat.v1` libraries, you should not need this,\n",
      "     |      (or `feed_dict` or `Session`).  In eager execution (or within `tf.function`)\n",
      "     |      you do not need to call `eval`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Tensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this tensor. If\n",
      "     |          none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy array corresponding to the value of this tensor.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      In eager execution the shape is always fully-known.\n",
      "     |      \n",
      "     |      >>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
      "     |      >>> print(a.shape)\n",
      "     |      (2, 3)\n",
      "     |      \n",
      "     |      `tf.Tensor.get_shape()` is equivalent to `tf.Tensor.shape`.\n",
      "     |      \n",
      "     |      \n",
      "     |      When executing in a `tf.function` or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.shape` may return a partial shape (including\n",
      "     |      `None` for unknown dimensions). See `tf.TensorShape` for more details.\n",
      "     |      \n",
      "     |      >>> inputs = tf.keras.Input(shape = [10])\n",
      "     |      >>> # Unknown batch size\n",
      "     |      >>> print(inputs.shape)\n",
      "     |      (None, 10)\n",
      "     |      \n",
      "     |      The shape is computed using shape inference functions that are\n",
      "     |      registered for each `tf.Operation`.\n",
      "     |      \n",
      "     |      The returned `tf.TensorShape` is determined at *build* time, without\n",
      "     |      executing the underlying kernel. It is not a `tf.Tensor`. If you need a\n",
      "     |      shape *tensor*, either convert the `tf.TensorShape` to a `tf.constant`, or\n",
      "     |      use the `tf.shape(tensor)` function, which returns the tensor's shape at\n",
      "     |      *execution* time.\n",
      "     |      \n",
      "     |      This is useful for debugging and providing early errors. For\n",
      "     |      example, when tracing a `tf.function`, no ops are being executed, shapes\n",
      "     |      may be unknown (See the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details).\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_matmul(a, b):\n",
      "     |      ...   result = a@b\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      The shape inference functions propagate shapes to the extent possible:\n",
      "     |      \n",
      "     |      >>> f = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([3,5]))\n",
      "     |      Result shape: (None, 5)\n",
      "     |      \n",
      "     |      Tracing may fail if a shape missmatch can be detected:\n",
      "     |      \n",
      "     |      >>> cf = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([4,5]))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Dimensions must be equal, but are 3 and 4 for 'matmul' (op:\n",
      "     |      'MatMul') with input shapes: [?,3], [4,5].\n",
      "     |      \n",
      "     |      In some cases, the inferred shape may have unknown dimensions. If\n",
      "     |      the caller has additional information about the values of these\n",
      "     |      dimensions, `tf.ensure_shape` or `Tensor.set_shape()` can be used to augment\n",
      "     |      the inferred shape.\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_fun(a):\n",
      "     |      ...   a = tf.ensure_shape(a, [5, 5])\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", a.shape)\n",
      "     |      ...   return a\n",
      "     |      \n",
      "     |      >>> cf = my_fun.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None, None]))\n",
      "     |      Result shape: (5, 5)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` representing the shape of this tensor.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Tensor.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put tensors in a set/dictionary.\n",
      "     |      We can't put tensors in a set/dictionary as `tensor.__hash__()` is no longer\n",
      "     |      available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> y = tf.constant(10)\n",
      "     |      >>> z = tf.constant(10)\n",
      "     |      >>> tensor_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> tensor_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `tensor.ref()`.\n",
      "     |      \n",
      "     |      >>> tensor_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in tensor_set\n",
      "     |      True\n",
      "     |      >>> tensor_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> tensor_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Tensor.\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the shape of this tensor.\n",
      "     |      \n",
      "     |      Note: It is recommended to use `tf.ensure_shape` instead of\n",
      "     |      `Tensor.set_shape`, because `tf.ensure_shape` provides better checking for\n",
      "     |      programming errors and can create guarantees for compiler\n",
      "     |      optimization.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> t = tf.constant([[1,2,3]])\n",
      "     |      >>> t.set_shape([1, 3])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,5])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (1, 3) is not compatible with supplied\n",
      "     |      shape [1, 5]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.set_shape` will *merge* the given `shape` with\n",
      "     |      the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> t = tf.keras.Input(shape=[None, None, 3])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> t.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      For example if you know all the images in a dataset have shape [28,28,3] you\n",
      "     |      can set it with `tf.set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def load_image(filename):\n",
      "     |      ...   raw = tf.io.read_file(filename)\n",
      "     |      ...   image = tf.image.decode_png(raw, channels=3)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", image.shape)\n",
      "     |      ...   image.set_shape([28, 28, 3])\n",
      "     |      ...   print(\"Final shape: \", image.shape)\n",
      "     |      ...   return image\n",
      "     |      \n",
      "     |      Trace the function, see the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details.\n",
      "     |      \n",
      "     |      >>> cf = load_image.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  (None, None, 3)\n",
      "     |      Final shape: (28, 28, 3)\n",
      "     |      \n",
      "     |      Similarly the `tf.io.parse_tensor` function could return a tensor with\n",
      "     |      any shape, even the `tf.rank` is unknown. If you know that all your\n",
      "     |      serialized tensors will be 2d, set it with `set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_parse(string_tensor):\n",
      "     |      ...   result = tf.io.parse_tensor(string_tensor, out_type=tf.float32)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", result.shape)\n",
      "     |      ...   result.set_shape([None, None])\n",
      "     |      ...   print(\"Final shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      Trace the function\n",
      "     |      \n",
      "     |      >>> concrete_parse = my_parse.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  <unknown>\n",
      "     |      Final shape:  (None, None)\n",
      "     |      \n",
      "     |      Make sure it works:\n",
      "     |      \n",
      "     |      >>> t = tf.ones([5,3], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> print(serialized.dtype)\n",
      "     |      <dtype: 'string'>\n",
      "     |      >>> print(serialized.shape)\n",
      "     |      ()\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 3)\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors. For runtime\n",
      "     |      validation of the shape, use `tf.ensure_shape` instead. It also modifies\n",
      "     |      the `shape` of the tensor.\n",
      "     |      \n",
      "     |      >>> # Serialize a rank-3 tensor\n",
      "     |      >>> t = tf.ones([5,5,5], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> # The function still runs, even though it `set_shape([None,None])`\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 5, 5)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The string name of this tensor.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      >>> t = tf.constant([1,2,3,4,5])\n",
      "     |      >>> t.shape\n",
      "     |      TensorShape([5])\n",
      "     |      \n",
      "     |      `tf.Tensor.shape` is equivalent to `tf.Tensor.get_shape()`.\n",
      "     |      \n",
      "     |      In a `tf.function` or when building a model using\n",
      "     |      `tf.keras.Input`, they return the build-time shape of the\n",
      "     |      tensor, which may be partially unknown.\n",
      "     |      \n",
      "     |      A `tf.TensorShape` is not a tensor. Use `tf.shape(t)` to get a tensor\n",
      "     |      containing the shape, calculated at runtime.\n",
      "     |      \n",
      "     |      See `tf.Tensor.get_shape()`, and `tf.TensorShape` for details and examples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  OVERLOADABLE_OPERATORS = {'__abs__', '__add__', '__and__', '__div__', ...\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.client._pywrap_tf_session.PyTensor:\n",
      "     |  \n",
      "     |  consumers = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> list\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyTensor:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyTensor:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  op\n",
      "     |  \n",
      "     |  value_index\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TensorArray(builtins.object)\n",
      "     |  TensorArray(dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |  \n",
      "     |  Class wrapping dynamic-sized, per-time-step, Tensor arrays.\n",
      "     |  \n",
      "     |  This class is meant to be used with dynamic iteration primitives such as\n",
      "     |  `while_loop` and `map_fn`.  It supports gradient back-propagation via special\n",
      "     |  \"flow\" control flow dependencies.\n",
      "     |  \n",
      "     |  Note that although the array can be read multiple times and positions can be\n",
      "     |  overwritten, behavior may be undefined when storing multiple references to\n",
      "     |  the same array and clear_after_read is False. In particular, avoid using\n",
      "     |  methods like concat() to convert an intermediate TensorArray to a Tensor,\n",
      "     |  then further modifying the TensorArray, particularly if you need to backprop\n",
      "     |  through it later.\n",
      "     |  \n",
      "     |  Example 1: Plain reading and writing.\n",
      "     |  \n",
      "     |  >>> ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
      "     |  >>> ta = ta.write(0, 10)\n",
      "     |  >>> ta = ta.write(1, 20)\n",
      "     |  >>> ta = ta.write(2, 30)\n",
      "     |  >>>\n",
      "     |  >>> ta.read(0)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=10.0>\n",
      "     |  >>> ta.read(1)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=20.0>\n",
      "     |  >>> ta.read(2)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=30.0>\n",
      "     |  >>> ta.stack()\n",
      "     |  <tf.Tensor: shape=(3,), dtype=float32, numpy=array([10., 20., 30.],\n",
      "     |  dtype=float32)>\n",
      "     |  \n",
      "     |  Example 2: Fibonacci sequence algorithm that writes in a loop then returns.\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def fibonacci(n):\n",
      "     |  ...   ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
      "     |  ...   ta = ta.unstack([0., 1.])\n",
      "     |  ...\n",
      "     |  ...   for i in range(2, n):\n",
      "     |  ...     ta = ta.write(i, ta.read(i - 1) + ta.read(i - 2))\n",
      "     |  ...\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>>\n",
      "     |  >>> fibonacci(7)\n",
      "     |  <tf.Tensor: shape=(7,), dtype=float32,\n",
      "     |  numpy=array([0., 1., 1., 2., 3., 5., 8.], dtype=float32)>\n",
      "     |  \n",
      "     |  Example 3: A simple loop interacting with a `tf.Variable`.\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(1)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def f(x):\n",
      "     |  ...   ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
      "     |  ...   for i in tf.range(x):\n",
      "     |  ...     v.assign_add(i)\n",
      "     |  ...     ta = ta.write(i, v)\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>> f(5)\n",
      "     |  <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 1,  2,  4,  7, 11],\n",
      "     |  dtype=int32)>\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |      Construct a new TensorArray or wrap an existing TensorArray handle.\n",
      "     |      \n",
      "     |      A note about the parameter `name`:\n",
      "     |      \n",
      "     |      The name of the `TensorArray` (even if passed in) is uniquified: each time\n",
      "     |      a new `TensorArray` is created at runtime it is assigned its own name for\n",
      "     |      the duration of the run.  This avoids name collisions if a `TensorArray`\n",
      "     |      is created within a `while_loop`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: (required) data type of the TensorArray.\n",
      "     |        size: (optional) int32 scalar `Tensor`: the size of the TensorArray.\n",
      "     |          Required if handle is not provided.\n",
      "     |        dynamic_size: (optional) Python bool: If true, writes to the TensorArray\n",
      "     |          can grow the TensorArray past its initial size.  Default: False.\n",
      "     |        clear_after_read: Boolean (optional, default: True).  If True, clear\n",
      "     |          TensorArray values after reading them.  This disables read-many\n",
      "     |          semantics, but allows early release of memory.\n",
      "     |        tensor_array_name: (optional) Python string: the name of the TensorArray.\n",
      "     |          This is used when creating the TensorArray handle.  If this value is\n",
      "     |          set, handle should be None.\n",
      "     |        handle: (optional) A `Tensor` handle to an existing TensorArray.  If this\n",
      "     |          is set, tensor_array_name should be None. Only supported in graph mode.\n",
      "     |        flow: (optional) A float `Tensor` scalar coming from an existing\n",
      "     |          `TensorArray.flow`. Only supported in graph mode.\n",
      "     |        infer_shape: (optional, default: True) If True, shape inference is\n",
      "     |          enabled.  In this case, all elements must have the same shape.\n",
      "     |        element_shape: (optional, default: None) A `TensorShape` object specifying\n",
      "     |          the shape constraints of each of the elements of the TensorArray. Need\n",
      "     |          not be fully defined.\n",
      "     |        colocate_with_first_write_call: If `True`, the TensorArray will be\n",
      "     |          colocated on the same device as the Tensor used on its first write\n",
      "     |          (write operations include `write`, `unstack`, and `split`).  If `False`,\n",
      "     |          the TensorArray will be placed on the device determined by the device\n",
      "     |          context available during its initialization.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if both handle and tensor_array_name are provided.\n",
      "     |        TypeError: if handle is provided but is not a Tensor.\n",
      "     |  \n",
      "     |  close(self, name=None)\n",
      "     |      Close the current TensorArray.\n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  concat(self, name=None)\n",
      "     |      Return the values in the TensorArray as a concatenated `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written, their ranks must match, and\n",
      "     |      and their shapes must all match for all dimensions except the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray concatenated into one tensor.\n",
      "     |  \n",
      "     |  gather(self, indices, name=None)\n",
      "     |      Return selected values in the TensorArray as a packed `Tensor`.\n",
      "     |      \n",
      "     |      All of selected values must have been written and their shapes\n",
      "     |      must all match.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors in the `TensorArray` selected by `indices`, packed into one\n",
      "     |        tensor.\n",
      "     |  \n",
      "     |  grad(self, source, flow=None, name=None)\n",
      "     |  \n",
      "     |  identity(self)\n",
      "     |      Returns a TensorArray with the same content and properties.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the control dependencies\n",
      "     |        from the contexts will become control dependencies for writes, reads, etc.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |  \n",
      "     |  read(self, index, name=None)\n",
      "     |      Read the value at location `index` in the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 tensor with the index to read from.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensor at index `index`.\n",
      "     |  \n",
      "     |  scatter(self, indices, value, name=None)\n",
      "     |      Scatter the values of a `Tensor` in specific indices of a `TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unpack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the scatter occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Return the size of the TensorArray.\n",
      "     |  \n",
      "     |  split(self, value, lengths, name=None)\n",
      "     |      Split the values of a `Tensor` into the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to split.\n",
      "     |        lengths: 1-D.  int32 vector with the lengths to use when splitting `value`\n",
      "     |          along its first dimension.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the split occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  stack(self, name=None)\n",
      "     |      Return the values in the TensorArray as a stacked `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written and their shapes must all match.\n",
      "     |      If input shapes have rank-`R`, then output shape will have rank-`(R+1)`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> ta = tf.TensorArray(tf.int32, size=3)\n",
      "     |      >>> ta = ta.write(0, tf.constant([1, 2]))\n",
      "     |      >>> ta = ta.write(1, tf.constant([3, 4]))\n",
      "     |      >>> ta = ta.write(2, tf.constant([5, 6]))\n",
      "     |      >>> ta.stack()\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4],\n",
      "     |             [5, 6]], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray stacked into one tensor.\n",
      "     |  \n",
      "     |  unstack(self, value, name=None)\n",
      "     |      Unstack the values of a `Tensor` in the TensorArray.\n",
      "     |      \n",
      "     |      If input value shapes have rank-`R`, then the output TensorArray will\n",
      "     |      contain elements whose shapes are rank-`(R-1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unstack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the unstack occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  write(self, index, value, name=None)\n",
      "     |      Write `value` into index `index` of the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 scalar with the index to write to.\n",
      "     |        value: N-D.  Tensor of type `dtype`.  The Tensor to write to this index.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the write occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if there are more writers than specified.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The data type of this TensorArray.\n",
      "     |  \n",
      "     |  dynamic_size\n",
      "     |      Python bool; if `True` the TensorArray can grow dynamically.\n",
      "     |  \n",
      "     |  element_shape\n",
      "     |      The `tf.TensorShape` of elements in this TensorArray.\n",
      "     |  \n",
      "     |  flow\n",
      "     |      The flow `Tensor` forcing ops leading to this TensorArray state.\n",
      "     |  \n",
      "     |  handle\n",
      "     |      The reference to the TensorArray.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TensorArraySpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  TensorArraySpec(element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |  \n",
      "     |  Type specification for a `tf.TensorArray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorArraySpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |      Constructs a type specification for a `tf.TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element_shape: The shape of each element in the `TensorArray`.\n",
      "     |        dtype: Data type of the `TensorArray`.\n",
      "     |        dynamic_size: Whether the `TensorArray` can grow past its initial size.\n",
      "     |        infer_shape: Whether shape inference is enabled.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others)\n",
      "     |      Returns the most specific supertype of `self` and `others`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A Sequence of `TypeSpec`.\n",
      "     |      \n",
      "     |      Returns `None` if a supertype does not exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  TensorShape(dims)\n",
      "     |  \n",
      "     |  Represents the shape of a `Tensor`.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> t.shape\n",
      "     |  TensorShape([2, 3])\n",
      "     |  \n",
      "     |  `TensorShape` is the *static* shape representation of a Tensor.\n",
      "     |  During eager execution a Tensor always has a fully specified shape but\n",
      "     |  when tracing a `tf.function` it may be one of the following:\n",
      "     |  \n",
      "     |  * *Fully-known shape:* has a known number of dimensions and a known size\n",
      "     |    for each dimension. e.g. `TensorShape([16, 256])`\n",
      "     |  * *Partially-known shape:* has a known number of dimensions, and an unknown\n",
      "     |    size for one or more dimension. e.g. `TensorShape([None, 256])`\n",
      "     |  * *Unknown shape:* has an unknown number of dimensions, and an unknown\n",
      "     |    size in all dimensions. e.g. `TensorShape(None)`\n",
      "     |  \n",
      "     |  During function tracing `t.shape` will return a `TensorShape` object\n",
      "     |  representing the shape of Tensor as it is known during tracing.\n",
      "     |  This static representation will be partially defined in cases where the\n",
      "     |  exact shape depends on the values within the tensors. To get the\n",
      "     |  *dynamic* representation, please use `tf.shape(t)`\n",
      "     |  which will return Tensor representing the fully defined shape of `t`.\n",
      "     |  This way, you can express logic that manipulates the shapes of tensors by\n",
      "     |  building other tensors that depend on the dynamic shape of `t`.\n",
      "     |  \n",
      "     |  Note: `tf.RaggedTensor.shape` also returns a `tf.TensorShape`,\n",
      "     |  the lengths of any ragged dimensions are unknown (`None`).\n",
      "     |  \n",
      "     |  For example, this function prints the `TensorShape' (`t.shape`), when you\n",
      "     |  trace the function, and returns a tensor `tf.shape(t)` for given input `t`:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def get_dynamic_shape(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   print(f\"static shape is {t.shape}\")\n",
      "     |  ...   return tf.shape(t)\n",
      "     |  \n",
      "     |  Just calling the function traces it with a fully-specified static shape:\n",
      "     |  \n",
      "     |  >>> result = get_dynamic_shape(tf.constant([[1, 1, 1], [0, 0, 0]]))\n",
      "     |  tracing...\n",
      "     |  static shape is (2, 3)\n",
      "     |  >>> result.numpy()\n",
      "     |  array([2, 3], dtype=int32)\n",
      "     |  \n",
      "     |  But `tf.function` can also trace the function with a partially specified\n",
      "     |  (or even unspecified) shape:\n",
      "     |  \n",
      "     |  >>> cf1 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(\n",
      "     |  ...                                               shape=[None, 2]))\n",
      "     |  tracing...\n",
      "     |  static shape is (None, 2)\n",
      "     |  >>> cf1(tf.constant([[1., 0],[1, 0],[1, 0]])).numpy()\n",
      "     |  array([3, 2], dtype=int32)\n",
      "     |  \n",
      "     |  >>> cf2 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(shape=None))\n",
      "     |  tracing...\n",
      "     |  static shape is <unknown>\n",
      "     |  >>> cf2(tf.constant([[[[[1., 0]]]]])).numpy()\n",
      "     |  array([1, 1, 1, 1, 2], dtype=int32)\n",
      "     |  \n",
      "     |  If a tensor is produced by an operation of type `\"Foo\"`, its shape\n",
      "     |  may be inferred if there is a registered shape function for\n",
      "     |  `\"Foo\"`. See [Shape\n",
      "     |  functions](https://www.tensorflow.org/guide/create_op#shape_functions_in_c)\n",
      "     |  for details of shape functions and how to register them. Alternatively,\n",
      "     |  you may set the shape explicitly using `tf.Tensor.ensure_shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorShape\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Returns True if this shape contains non-zero information.\n",
      "     |  \n",
      "     |  __concat__(self, other)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True if `self` is equivalent to `other`.\n",
      "     |      \n",
      "     |      It first tries to convert `other` to `TensorShape`. `TypeError` is thrown\n",
      "     |      when the conversion fails. Otherwise, it compares each element in the\n",
      "     |      TensorShape dimensions.\n",
      "     |      \n",
      "     |      * Two *Fully known* shapes, return True iff each element is equal.\n",
      "     |      >>> t_a = tf.TensorShape([1,2])\n",
      "     |      >>> a = [1, 2]\n",
      "     |      >>> t_b = tf.TensorShape([1,2])\n",
      "     |      >>> t_c = tf.TensorShape([1,2,3])\n",
      "     |      >>> t_a.__eq__(a)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Partially-known* shapes, return True iff each element is equal.\n",
      "     |      >>> p_a = tf.TensorShape([1,None])\n",
      "     |      >>> p_b = tf.TensorShape([1,None])\n",
      "     |      >>> p_c = tf.TensorShape([2,None])\n",
      "     |      >>> p_a.__eq__(p_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(p_a)\n",
      "     |      False\n",
      "     |      >>> p_a.__eq__(p_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Unknown shape*, return True.\n",
      "     |      >>> unk_a = tf.TensorShape(None)\n",
      "     |      >>> unk_b = tf.TensorShape(None)\n",
      "     |      >>> unk_a.__eq__(unk_b)\n",
      "     |      True\n",
      "     |      >>> unk_a.__eq__(t_a)\n",
      "     |      False\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TensorShape` or type that can be converted to `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the dimensions are all equal.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError if `other` can not be converted to `TensorShape`.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Returns the value of a dimension or a shape, depending on the key.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        key: If `key` is an integer, returns the dimension at that index;\n",
      "     |          otherwise if `key` is a slice, returns a TensorShape whose dimensions\n",
      "     |          are those selected by the slice from `self`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n",
      "     |        slice.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is a slice and `self` is completely unknown and\n",
      "     |          the step is set.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, dims)\n",
      "     |      Creates a new TensorShape with the given dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dims: A list of Dimensions, or None if the shape is unspecified.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If dims cannot be converted to a list of dimensions.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Returns `self.dims` if the rank is known, otherwise raises ValueError.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the rank of this shape, or raises ValueError if unspecified.\n",
      "     |  \n",
      "     |  __nonzero__ = __bool__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  as_list(self)\n",
      "     |      Returns a list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` is an unknown shape with an unknown rank.\n",
      "     |  \n",
      "     |  as_proto(self)\n",
      "     |      Returns this shape as a `TensorShapeProto`.\n",
      "     |  \n",
      "     |  assert_has_rank(self, rank)\n",
      "     |      Raises an exception if `self` is not compatible with the given `rank`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises exception if `self` and `other` do not represent the same shape.\n",
      "     |      \n",
      "     |      This method can be used to assert that there exists a shape that both\n",
      "     |      `self` and `other` represent.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent the same shape.\n",
      "     |  \n",
      "     |  assert_is_fully_defined(self)\n",
      "     |      Raises an exception if `self` is not fully defined in every dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not have a known value for every dimension.\n",
      "     |  \n",
      "     |  assert_same_rank(self, other)\n",
      "     |      Raises an exception if `self` and `other` do not have compatible ranks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent shapes with the\n",
      "     |          same rank.\n",
      "     |  \n",
      "     |  concatenate(self, other)\n",
      "     |      Returns the concatenation of the dimension in `self` and `other`.\n",
      "     |      \n",
      "     |      *N.B.* If either `self` or `other` is completely unknown,\n",
      "     |      concatenation will discard information about the other shape. In\n",
      "     |      future, we might support concatenation that preserves this\n",
      "     |      information for use with slicing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` whose dimensions are the concatenation of the\n",
      "     |        dimensions in `self` and `other`.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto\n",
      "     |      Returns a proto representation of the TensorShape instance.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True iff `self` is compatible with `other`.\n",
      "     |      \n",
      "     |      Two possibly-partially-defined shapes are compatible if there\n",
      "     |      exists a fully-defined shape that both shapes can represent. Thus,\n",
      "     |      compatibility allows the shape inference code to reason about\n",
      "     |      partially-defined shapes. For example:\n",
      "     |      \n",
      "     |      * TensorShape(None) is compatible with all shapes.\n",
      "     |      \n",
      "     |      * TensorShape([None, None]) is compatible with all two-dimensional\n",
      "     |        shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is\n",
      "     |        not compatible with, for example, TensorShape([None]) or\n",
      "     |        TensorShape([None, None, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, None]) is compatible with all two-dimensional shapes\n",
      "     |        with size 32 in the 0th dimension, and also TensorShape([None, None])\n",
      "     |        and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, 784]) is compatible with itself, and also\n",
      "     |        TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None,\n",
      "     |        None]) and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32, 1, 784]) or TensorShape([None]).\n",
      "     |      \n",
      "     |      The compatibility relation is reflexive and symmetric, but not\n",
      "     |      transitive. For example, TensorShape([32, 784]) is compatible with\n",
      "     |      TensorShape(None), and TensorShape(None) is compatible with\n",
      "     |      TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with\n",
      "     |      TensorShape([4, 4]).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is compatible with `other`.\n",
      "     |  \n",
      "     |  is_fully_defined(self)\n",
      "     |      Returns True iff `self` is fully defined in every dimension.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True iff `self` is subtype of `other`.\n",
      "     |      \n",
      "     |      Shape A is a subtype of shape B if shape B can successfully represent it:\n",
      "     |      \n",
      "     |      * A `TensorShape` of any rank is a subtype of `TensorShape(None)`.\n",
      "     |      \n",
      "     |      *  TensorShapes of equal ranks are covariant, i.e.\n",
      "     |        `TensorShape([A1, A2, ..])` is a subtype of\n",
      "     |        `TensorShape([B1, B2, ..])` iff An is a subtype of Bn.\n",
      "     |      \n",
      "     |        An is subtype of Bn iff An == Bn or Bn is None.\n",
      "     |      \n",
      "     |      * TensorShapes of different defined ranks have no subtyping relation.\n",
      "     |      \n",
      "     |      The subtyping relation is reflexive and transitive, but not symmetric.\n",
      "     |      \n",
      "     |      Some examples:\n",
      "     |      * `TensorShape([32, 784])` is a subtype of `TensorShape(None)`, and\n",
      "     |        `TensorShape([4, 4])` is also a subtype of `TensorShape(None)` but\n",
      "     |        `TensorShape([32, 784])` and `TensorShape([4, 4])` are not subtypes of\n",
      "     |        each other.\n",
      "     |      \n",
      "     |      * All two-dimensional shapes are subtypes of `TensorShape([None, None])`,\n",
      "     |        such as `TensorShape([32, 784])`. There is no subtype relationship with,\n",
      "     |        for example, `TensorShape([None])` or `TensorShape([None, None, None])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, None])` is also a subtype of `TensorShape([None, None])`\n",
      "     |        and `TensorShape(None)`. It is not a subtype of, for example,\n",
      "     |        `TensorShape([32])`, `TensorShape([32, None, 1])`,\n",
      "     |        `TensorShape([64, None])` or `TensorShape([None, 32])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, 784])` is a subtype of itself, and also\n",
      "     |        `TensorShape([32, None])`, `TensorShape([None, 784])`,\n",
      "     |        `TensorShape([None, None])` and `TensorShape(None)`.\n",
      "     |        It has no subtype relation with, for example, `TensorShape([32, 1, 784])`\n",
      "     |        or `TensorShape([None])`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is subtype of `other`.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a `TensorShape` combining the information in `self` and `other`.\n",
      "     |      \n",
      "     |      The dimensions in `self` and `other` are merged element-wise,\n",
      "     |      according to the rules below:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      Dimension(n).merge_with(Dimension(None)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(n)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(None)) == Dimension(None)\n",
      "     |      # raises ValueError for n != m\n",
      "     |      Dimension(n).merge_with(Dimension(m))\n",
      "     |      ```\n",
      "     |      >> ts = tf.TensorShape([1,2])\n",
      "     |      >> ot1 = tf.TensorShape([1,2])\n",
      "     |      >> ts.merge_with(ot).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot2 = tf.TensorShape([1,None])\n",
      "     |      >> ts.merge_with(ot2).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot3 = tf.TensorShape([None, None])\n",
      "     |      >> ot3.merge_with(ot2).as_list()\n",
      "     |      [1, None]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TensorShape'), NoneType]\n",
      "     |      Returns the most specific supertype `TensorShape` of self and others.\n",
      "     |      \n",
      "     |      * `TensorShape([None, 1])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([2, 1])` and `TensorShape([5, 1])`. Note that\n",
      "     |        `TensorShape(None)` is also a supertype but it is not \"most specific\".\n",
      "     |      \n",
      "     |      * `TensorShape([1, 2, 3])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([1, 2, 3])` and `TensorShape([1, 2, 3]`). There are\n",
      "     |        other less specific TensorShapes that supertype above mentioned\n",
      "     |        TensorShapes, e.g. `TensorShape([1, 2, None])`, `TensorShape(None)`.\n",
      "     |      \n",
      "     |       * `TensorShape([None, None])` is the most specific `TensorShape`\n",
      "     |         supertyping both `TensorShape([2, None])` and `TensorShape([None, 3])`.\n",
      "     |         As always, `TensorShape(None)` is also a supertype but not the most\n",
      "     |         specific one.\n",
      "     |      \n",
      "     |       * `TensorShape(None`) is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape([1, 2])`. In general, any two\n",
      "     |         shapes that have different ranks will only have `TensorShape(None)`\n",
      "     |         as a common supertype.\n",
      "     |      \n",
      "     |       * `TensorShape(None)` is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape(None)`. In general, the common\n",
      "     |         supertype of any shape with `TensorShape(None)` is `TensorShape(None)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: Sequence of `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific supertype shape of `self`\n",
      "     |        and `others`. None if it does not exist.\n",
      "     |  \n",
      "     |  most_specific_compatible_shape(self, other)\n",
      "     |      Returns the most specific TensorShape compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      * TensorShape([None, 1]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([2, 1]) and TensorShape([5, 1]). Note that\n",
      "     |        TensorShape(None) is also compatible with above mentioned TensorShapes.\n",
      "     |      \n",
      "     |      * TensorShape([1, 2, 3]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more\n",
      "     |        less specific TensorShapes compatible with above mentioned TensorShapes,\n",
      "     |        e.g. TensorShape([1, 2, None]), TensorShape(None).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific compatible shape of `self`\n",
      "     |        and `other`.\n",
      "     |  \n",
      "     |  num_elements(self)\n",
      "     |      Returns the total number of elements, or none for incomplete shapes.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Creates a placeholder for tracing.\n",
      "     |      \n",
      "     |      tf.funcion traces with the placeholder value rather than the actual value.\n",
      "     |      For example, a placeholder value can represent multiple different\n",
      "     |      actual values. This means that the trace generated with that placeholder\n",
      "     |      value is more general and reusable which saves expensive retracing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A `PlaceholderContext` container for context\n",
      "     |                             information when creating a placeholder value.\n",
      "     |      \n",
      "     |      For the `Fruit` example shared above, implementing:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      class FruitTraceType:\n",
      "     |        def placeholder_value(self, placeholder_context):\n",
      "     |          return Fruit()\n",
      "     |      ```\n",
      "     |      instructs tf.function to trace with the `Fruit()` objects\n",
      "     |      instead of the actual `Apple()` and `Mango()` objects when it receives a\n",
      "     |      call to `get_mixed_flavor(Apple(), Mango())`. For example, Tensor arguments\n",
      "     |      are replaced with Tensors of similar shape and dtype, output from\n",
      "     |      a tf.Placeholder op.\n",
      "     |      \n",
      "     |      More generally, placeholder values are the arguments of a tf.function,\n",
      "     |      as seen from the function's body:\n",
      "     |      ```python\n",
      "     |      @tf.function\n",
      "     |      def foo(x):\n",
      "     |        # Here `x` is be the placeholder value\n",
      "     |        ...\n",
      "     |      \n",
      "     |      foo(x) # Here `x` is the actual value\n",
      "     |      ```\n",
      "     |  \n",
      "     |  with_rank(self, rank)\n",
      "     |      Returns a shape based on `self` with the given rank.\n",
      "     |      \n",
      "     |      This method promotes a completely unknown shape to one with a\n",
      "     |      known rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with the given rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_least(self, rank)\n",
      "     |      Returns a shape based on `self` with at least the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at least the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at least the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_most(self, rank)\n",
      "     |      Returns a shape based on `self` with at most the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at most the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at most the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto) -> 'TensorShape' from abc.ABCMeta\n",
      "     |      Returns a TensorShape instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorShape serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dims\n",
      "     |      Deprecated.  Returns list of dimensions for this shape.\n",
      "     |      \n",
      "     |      Suggest `TensorShape.as_list` instead.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list containing `tf.compat.v1.Dimension`s, or None if the shape is\n",
      "     |        unspecified.\n",
      "     |  \n",
      "     |  ndims\n",
      "     |      Deprecated accessor for `rank`.\n",
      "     |  \n",
      "     |  rank\n",
      "     |      Returns the rank of this shape, or None if it is unspecified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TensorSpec(DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "     |  TensorSpec(shape, dtype=tf.float32, name=None)\n",
      "     |  \n",
      "     |  Describes the type of a tf.Tensor.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> tf.TensorSpec.from_tensor(t)\n",
      "     |  TensorSpec(shape=(2, 3), dtype=tf.int32, name=None)\n",
      "     |  \n",
      "     |  Contains metadata for describing the the nature of `tf.Tensor` objects\n",
      "     |  accepted or returned by some TensorFlow APIs.\n",
      "     |  \n",
      "     |  For example, it can be used to constrain the type of inputs accepted by\n",
      "     |  a tf.function:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.TensorSpec([1, None])])\n",
      "     |  ... def constrained_foo(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   return t\n",
      "     |  \n",
      "     |  Now the `tf.function` is able to assume that `t` is always of the type\n",
      "     |  `tf.TensorSpec([1, None])` which will avoid retracing as well as enforce the\n",
      "     |  type restriction on inputs.\n",
      "     |  \n",
      "     |  As a result, the following call with tensor of type `tf.TensorSpec([1, 2])`\n",
      "     |  triggers a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2]])).numpy()\n",
      "     |  tracing...\n",
      "     |  array([[1., 2.]], dtype=float32)\n",
      "     |  \n",
      "     |  The following subsequent call with tensor of type `tf.TensorSpec([1, 4])`\n",
      "     |  does not trigger a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2, 3, 4]])).numpy()\n",
      "     |  array([[1., 2., 3., 4.], dtype=float32)\n",
      "     |  \n",
      "     |  But the following call with tensor of type `tf.TensorSpec([2, 2])` fails:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2], [3, 4]])).numpy()\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Binding inputs to tf.function `constrained_foo` failed ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorSpec\n",
      "     |      DenseSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      tensorflow.python.types.internal.TensorSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TensorSpecProto\n",
      "     |      Returns a proto representation of the TensorSpec instance.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_tensor)\n",
      "     |      Returns True if spec_or_tensor is compatible with this TensorSpec.\n",
      "     |      \n",
      "     |      Two tensors are considered compatible if they have the same dtype\n",
      "     |      and their shapes are compatible (see `tf.TensorShape.is_compatible_with`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_tensor: A tf.TensorSpec or a tf.Tensor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if spec_or_tensor is compatible with self.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Generates a graph_placholder with the given TensorSpec information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TensorSpecProto) -> 'TensorSpec' from abc.ABCMeta\n",
      "     |      Returns a TensorSpec instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TensorSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorSpec serialization.\n",
      "     |  \n",
      "     |  from_spec(spec, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` with the same shape and dtype as `spec`.\n",
      "     |      \n",
      "     |      >>> spec = tf.TensorSpec(shape=[8, 3], dtype=tf.int32, name=\"OriginalName\")\n",
      "     |      >>> tf.TensorSpec.from_spec(spec, \"NewName\")\n",
      "     |      TensorSpec(shape=(8, 3), dtype=tf.int32, name='NewName')\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: The `TypeSpec` used to create the new `TensorSpec`.\n",
      "     |        name: The name for the new `TensorSpec`.  Defaults to `spec.name`.\n",
      "     |  \n",
      "     |  from_tensor(tensor, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` that describes `tensor`.\n",
      "     |      \n",
      "     |      >>> tf.TensorSpec.from_tensor(tf.constant([1, 2, 3]))\n",
      "     |      TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `tf.Tensor` that should be described.\n",
      "     |        name: A name for the `TensorSpec`.  Defaults to `tensor.op.name`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorSpec` that describes `tensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, shape, dtype=tf.float32, name=None)\n",
      "     |      Creates a TensorSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Value convertible to `tf.TensorShape`. The shape of the tensor.\n",
      "     |        dtype: Value convertible to `tf.DType`. The type of the tensor values.\n",
      "     |        name: Optional name for the Tensor.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If shape is not convertible to a `tf.TensorShape`, or dtype is\n",
      "     |          not convertible to a `tf.DType`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from DenseSpec:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Returns the `dtype` of elements in the tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the (optionally provided) name of the described tensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns the `TensorShape` that represents the shape of the tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  Specifies a TensorFlow value type.\n",
      "     |  \n",
      "     |  A `tf.TypeSpec` provides metadata describing an object accepted or returned\n",
      "     |  by TensorFlow APIs.  Concrete subclasses, such as `tf.TensorSpec` and\n",
      "     |  `tf.RaggedTensorSpec`, are used to describe different value types.\n",
      "     |  \n",
      "     |  For example, `tf.function`'s `input_signature` argument accepts a list\n",
      "     |  (or nested structure) of `TypeSpec`s.\n",
      "     |  \n",
      "     |  Creating new subclasses of `TypeSpec` (outside of TensorFlow core) is not\n",
      "     |  currently supported.  In particular, we may make breaking changes to the\n",
      "     |  private methods and properties defined by this base class.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> spec = tf.TensorSpec(shape=[None, None], dtype=tf.int32)\n",
      "     |  >>> @tf.function(input_signature=[spec])\n",
      "     |  ... def double(x):\n",
      "     |  ...   return x * 2\n",
      "     |  >>> double(tf.constant([[1, 2], [3, 4]]))\n",
      "     |  <tf.Tensor: shape=(2, 2), dtype=int32,\n",
      "     |      numpy=array([[2, 4], [6, 8]], dtype=int32)>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Union[ForwardRef('TypeSpec'), NoneType]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_component_specs', '_from_components...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class UnconnectedGradients(enum.Enum)\n",
      "     |  UnconnectedGradients(value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      "     |  \n",
      "     |  Controls how gradient computation behaves when y does not depend on x.\n",
      "     |  \n",
      "     |  The gradient of y with respect to x can be zero in two different ways: there\n",
      "     |  could be no differentiable path in the graph connecting x to y (and so we can\n",
      "     |  statically prove that the gradient is zero) or it could be that runtime values\n",
      "     |  of tensors in a particular execution lead to a gradient of zero (say, if a\n",
      "     |  relu unit happens to not be activated). To allow you to distinguish between\n",
      "     |  these two cases you can choose what value gets returned for the gradient when\n",
      "     |  there is no path in the graph from x to y:\n",
      "     |  \n",
      "     |  * `NONE`: Indicates that [None] will be returned if there is no path from x\n",
      "     |    to y\n",
      "     |  * `ZERO`: Indicates that a zero tensor will be returned in the shape of x.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnconnectedGradients\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NONE = <UnconnectedGradients.NONE: 'none'>\n",
      "     |  \n",
      "     |  ZERO = <UnconnectedGradients.ZERO: 'zero'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class Variable(tensorflow.python.trackable.base.Trackable)\n",
      "     |  Variable(*args, **kwargs)\n",
      "     |  \n",
      "     |  See the [variable guide](https://tensorflow.org/guide/variable).\n",
      "     |  \n",
      "     |  A variable maintains shared, persistent state manipulated by a program.\n",
      "     |  \n",
      "     |  The `Variable()` constructor requires an initial value for the variable, which\n",
      "     |  can be a `Tensor` of any type and shape. This initial value defines the type\n",
      "     |  and shape of the variable. After construction, the type and shape of the\n",
      "     |  variable are fixed. The value can be changed using one of the assign methods.\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(1.)\n",
      "     |  >>> v.assign(2.)\n",
      "     |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
      "     |  >>> v.assign_add(0.5)\n",
      "     |  <tf.Variable ... shape=() dtype=float32, numpy=2.5>\n",
      "     |  \n",
      "     |  The `shape` argument to `Variable`'s constructor allows you to construct a\n",
      "     |  variable with a less defined shape than its `initial_value`:\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(1., shape=tf.TensorShape(None))\n",
      "     |  >>> v.assign([[1.]])\n",
      "     |  <tf.Variable ... shape=<unknown> dtype=float32, numpy=array([[1.]], ...)>\n",
      "     |  \n",
      "     |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
      "     |  inputs to operations. Additionally, all the operators overloaded for the\n",
      "     |  `Tensor` class are carried over to variables.\n",
      "     |  \n",
      "     |  >>> w = tf.Variable([[1.], [2.]])\n",
      "     |  >>> x = tf.constant([[3., 4.]])\n",
      "     |  >>> tf.matmul(w, x)\n",
      "     |  <tf.Tensor:... shape=(2, 2), ... numpy=\n",
      "     |    array([[3., 4.],\n",
      "     |           [6., 8.]], dtype=float32)>\n",
      "     |  >>> tf.sigmoid(w + x)\n",
      "     |  <tf.Tensor:... shape=(2, 2), ...>\n",
      "     |  \n",
      "     |  When building a machine learning model it is often convenient to distinguish\n",
      "     |  between variables holding trainable model parameters and other variables such\n",
      "     |  as a `step` variable used to count training steps. To make this easier, the\n",
      "     |  variable constructor supports a `trainable=<bool>`\n",
      "     |  parameter. `tf.GradientTape` watches trainable variables by default:\n",
      "     |  \n",
      "     |  >>> with tf.GradientTape(persistent=True) as tape:\n",
      "     |  ...   trainable = tf.Variable(1.)\n",
      "     |  ...   non_trainable = tf.Variable(2., trainable=False)\n",
      "     |  ...   x1 = trainable * 2.\n",
      "     |  ...   x2 = non_trainable * 3.\n",
      "     |  >>> tape.gradient(x1, trainable)\n",
      "     |  <tf.Tensor:... shape=(), dtype=float32, numpy=2.0>\n",
      "     |  >>> assert tape.gradient(x2, non_trainable) is None  # Unwatched\n",
      "     |  \n",
      "     |  Variables are automatically tracked when assigned to attributes of types\n",
      "     |  inheriting from `tf.Module`.\n",
      "     |  \n",
      "     |  >>> m = tf.Module()\n",
      "     |  >>> m.v = tf.Variable([1.])\n",
      "     |  >>> m.trainable_variables\n",
      "     |  (<tf.Variable ... shape=(1,) ... numpy=array([1.], dtype=float32)>,)\n",
      "     |  \n",
      "     |  This tracking then allows saving variable values to\n",
      "     |  [training checkpoints](https://www.tensorflow.org/guide/checkpoint), or to\n",
      "     |  [SavedModels](https://www.tensorflow.org/guide/saved_model) which include\n",
      "     |  serialized TensorFlow graphs.\n",
      "     |  \n",
      "     |  Variables are often captured and manipulated by `tf.function`s. This works the\n",
      "     |  same way the un-decorated function would have:\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(0.)\n",
      "     |  >>> read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
      "     |  >>> read_and_decrement()\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.1>\n",
      "     |  >>> read_and_decrement()\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.2>\n",
      "     |  \n",
      "     |  Variables created inside a `tf.function` must be owned outside the function\n",
      "     |  and be created only once:\n",
      "     |  \n",
      "     |  >>> class M(tf.Module):\n",
      "     |  ...   @tf.function\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
      "     |  ...       self.v = tf.Variable(x)\n",
      "     |  ...     return self.v * x\n",
      "     |  >>> m = M()\n",
      "     |  >>> m(2.)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n",
      "     |  >>> m(3.)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "     |  >>> m.v\n",
      "     |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
      "     |  \n",
      "     |  See the `tf.function` documentation for details.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Variable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(x, name=None)\n",
      "     |      Computes the absolute value of a tensor.\n",
      "     |      \n",
      "     |      Given a tensor of integer or floating-point values, this operation returns a\n",
      "     |      tensor of the same type, where each element contains the absolute value of the\n",
      "     |      corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "     |      `float32` or `float64` that is the absolute value of each element in `x`. For\n",
      "     |      a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "     |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # real number\n",
      "     |      >>> x = tf.constant([-2.25, 3.25])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=float32,\n",
      "     |      numpy=array([2.25, 3.25], dtype=float32)>\n",
      "     |      \n",
      "     |      >>> # complex number\n",
      "     |      >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "     |      array([[5.25594901],\n",
      "     |             [6.60492241]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "     |          `int32`, `int64`, `complex64` or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
      "     |          with absolute values. Note, for `complex64` or `complex128` input, the\n",
      "     |          returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |      The operation invoked by the `Tensor.__add__` operator.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: The left-hand side of the `+` operator.\n",
      "     |        y: The right-hand side of the `+` operator.\n",
      "     |        name: an optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `+` operation.\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      \n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = _SliceHelperVar(var, slice_spec)\n",
      "     |      Creates a slice helper object given a variable.\n",
      "     |      \n",
      "     |      This allows creating a sub-tensor from part of the current contents\n",
      "     |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
      "     |      of slicing.\n",
      "     |      \n",
      "     |      This function in addition also allows assignment to a sliced range.\n",
      "     |      This is similar to `__setitem__` functionality in Python. However,\n",
      "     |      the syntax is different so that the user can capture the assignment\n",
      "     |      operation for grouping or passing to `sess.run()` in TF1.\n",
      "     |      For example,\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
      "     |      print(A[:2, :2])  # => [[1,2], [4,5]]\n",
      "     |      \n",
      "     |      A[:2,:2].assign(22. * tf.ones((2, 2))))\n",
      "     |      print(A) # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Note that assignments currently do not support NumPy broadcasting\n",
      "     |      semantics.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        var: An `ops.Variable` object.\n",
      "     |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |        As an operator. The operator also has a `assign()` method\n",
      "     |        that can be used to generate an assignment operator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
      "     |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, initial_value=None, trainable=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, import_scope=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None, experimental_enable_variable_lifting=True)\n",
      "     |      Creates a new variable with value `initial_value`. (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(caching_device)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      A variable's value can be manually cached by calling tf.Variable.read_value() under a tf.device scope. The caching_device argument does not work properly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "     |          which is the initial value for the Variable. The initial value must have\n",
      "     |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "     |          callable with no argument that returns the initial value when called. In\n",
      "     |          that case, `dtype` must be specified. (Note that initializer functions\n",
      "     |          from init_ops.py must first be bound to a shape before being used here.)\n",
      "     |        trainable: If `True`, GradientTapes automatically watch uses of this\n",
      "     |          variable. Defaults to `True`, unless `synchronization` is set to\n",
      "     |          `ON_READ`, in which case it defaults to `False`.\n",
      "     |        validate_shape: If `False`, allows the variable to be initialized with a\n",
      "     |          value of unknown shape. If `True`, the default, the shape of\n",
      "     |          `initial_value` must be known.\n",
      "     |        caching_device: Note: This argument is only valid when using a v1-style\n",
      "     |          `Session`. Optional device string describing where the Variable should\n",
      "     |          be cached for reading. Defaults to the Variable's device. If not `None`,\n",
      "     |          caches on another device. Typical use is to cache on the device where\n",
      "     |          the Ops using the Variable reside, to deduplicate copying through\n",
      "     |          `Switch` and other conditional statements.\n",
      "     |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "     |          uniquified automatically.\n",
      "     |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
      "     |          Variable object with its contents, referencing the variable's nodes in\n",
      "     |          the graph, which must already exist. The graph is not changed.\n",
      "     |          `variable_def` and the other arguments are mutually exclusive.\n",
      "     |        dtype: If set, initial_value will be converted to the given type. If\n",
      "     |          `None`, either the datatype will be kept (if `initial_value` is a\n",
      "     |          Tensor), or `convert_to_tensor` will decide.\n",
      "     |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
      "     |          used when initializing from protocol buffer.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
      "     |          synchronize.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        shape: (optional) The shape of this variable. If None, the shape of\n",
      "     |          `initial_value` will be used. When setting this argument to\n",
      "     |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
      "     |          can be assigned with values of different shapes.\n",
      "     |        experimental_enable_variable_lifting: Whether to lift the variable out if\n",
      "     |          it's in a `tf.function`. Default is `True`. When this argument\n",
      "     |          is `True`, variable creation will follow the behavior and\n",
      "     |          restrictions described\n",
      "     |          [here](https://www.tensorflow.org/guide/function#creating_tfvariables).\n",
      "     |          If this argument is `False`, that description doesn't apply,\n",
      "     |          and you can freely create and use the variable in the\n",
      "     |          `tf.function`, as if it's a \"mutable `tf.Tensor`\". You can't\n",
      "     |          return the variable though.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `variable_def` and initial_value are specified.\n",
      "     |        ValueError: If the initial value is not specified, or does not have a\n",
      "     |          shape and `validate_shape` is `True`.\n",
      "     |  \n",
      "     |  __invert__ = invert_(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      When executing eagerly, iterates over the value of the variable.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      \n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      ```python\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      \n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      \n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "     |      and any further outer dimensions specify matching batch size.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |      `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      A simple 2-D tensor matrix multiplication:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      >>> a  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]], dtype=int32)>\n",
      "     |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      >>> b  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[ 7,  8],\n",
      "     |             [ 9, 10],\n",
      "     |             [11, 12]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "     |      array([[ 58,  64],\n",
      "     |             [139, 154]], dtype=int32)>\n",
      "     |      \n",
      "     |      A batch matrix multiplication with batch shape [2]:\n",
      "     |      \n",
      "     |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "     |      >>> a  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "     |      array([[[ 1,  2,  3],\n",
      "     |              [ 4,  5,  6]],\n",
      "     |             [[ 7,  8,  9],\n",
      "     |              [10, 11, 12]]], dtype=int32)>\n",
      "     |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "     |      >>> b  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "     |      array([[[13, 14],\n",
      "     |              [15, 16],\n",
      "     |              [17, 18]],\n",
      "     |             [[19, 20],\n",
      "     |              [21, 22],\n",
      "     |              [23, 24]]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "     |      array([[[ 94, 100],\n",
      "     |              [229, 244]],\n",
      "     |             [[508, 532],\n",
      "     |              [697, 730]]], dtype=int32)>\n",
      "     |      \n",
      "     |      Since python >= 3.5 the @ operator is supported\n",
      "     |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "     |      it simply calls the `tf.matmul()` function, so the following lines are\n",
      "     |      equivalent:\n",
      "     |      \n",
      "     |      >>> d = a @ b @ [[10], [11]]\n",
      "     |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "     |          `complex64`, `complex128` and rank > 1.\n",
      "     |        b: `tf.Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `a` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `b` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        output_type: The output datatype if needed. Defaults to None in which case\n",
      "     |          the output_type is the same as input type. Currently only works when input\n",
      "     |          tensors are type (u)int8 and output_type can be int32.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "     |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "     |        for all indices `i`, `j`.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "     |          `adjoint_b` are both set to `True`.\n",
      "     |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "     |          `output_type` is not (u)int8, (u)int8 and int32.\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |      The operation invoked by the `Tensor.__add__` operator.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: The left-hand side of the `+` operator.\n",
      "     |        y: The right-hand side of the `+` operator.\n",
      "     |        name: an optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `+` operation.\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "     |      and any further outer dimensions specify matching batch size.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |      `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      A simple 2-D tensor matrix multiplication:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      >>> a  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]], dtype=int32)>\n",
      "     |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      >>> b  # 2-D tensor\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[ 7,  8],\n",
      "     |             [ 9, 10],\n",
      "     |             [11, 12]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "     |      array([[ 58,  64],\n",
      "     |             [139, 154]], dtype=int32)>\n",
      "     |      \n",
      "     |      A batch matrix multiplication with batch shape [2]:\n",
      "     |      \n",
      "     |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "     |      >>> a  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "     |      array([[[ 1,  2,  3],\n",
      "     |              [ 4,  5,  6]],\n",
      "     |             [[ 7,  8,  9],\n",
      "     |              [10, 11, 12]]], dtype=int32)>\n",
      "     |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "     |      >>> b  # 3-D tensor\n",
      "     |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "     |      array([[[13, 14],\n",
      "     |              [15, 16],\n",
      "     |              [17, 18]],\n",
      "     |             [[19, 20],\n",
      "     |              [21, 22],\n",
      "     |              [23, 24]]], dtype=int32)>\n",
      "     |      >>> c = tf.matmul(a, b)\n",
      "     |      >>> c  # `a` * `b`\n",
      "     |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "     |      array([[[ 94, 100],\n",
      "     |              [229, 244]],\n",
      "     |             [[508, 532],\n",
      "     |              [697, 730]]], dtype=int32)>\n",
      "     |      \n",
      "     |      Since python >= 3.5 the @ operator is supported\n",
      "     |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "     |      it simply calls the `tf.matmul()` function, so the following lines are\n",
      "     |      equivalent:\n",
      "     |      \n",
      "     |      >>> d = a @ b @ [[10], [11]]\n",
      "     |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "     |          `complex64`, `complex128` and rank > 1.\n",
      "     |        b: `tf.Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `a` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "     |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "     |          that assume most values in `b` are zero.\n",
      "     |          See `tf.sparse.sparse_dense_matmul`\n",
      "     |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "     |        output_type: The output datatype if needed. Defaults to None in which case\n",
      "     |          the output_type is the same as input type. Currently only works when input\n",
      "     |          tensors are type (u)int8 and output_type can be int32.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "     |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "     |        for all indices `i`, `j`.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "     |          `adjoint_b` are both set to `True`.\n",
      "     |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "     |          `output_type` is not (u)int8, (u)int8 and int32.\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      \n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      \n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      \n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = 1\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      \n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      \n",
      "     |      >>> x - y\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      \n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      \n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      \n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      \n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      \n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      \n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      \n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      \n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      \n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      \n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      \n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      \n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      \n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      \n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      \n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |      \n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |      \n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
      "     |      Assigns a new value to the variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign(self, value)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: A `Tensor`. The new value for this variable.\n",
      "     |        use_locking: If `True`, use locking during the assignment.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Adds a value to this variable.\n",
      "     |      \n",
      "     |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to add to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Subtracts a value from this variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to subtract from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
      "     |      \n",
      "     |      Analogous to `batch_gather`. This assumes that this variable and the\n",
      "     |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
      "     |      same for all of them, and the updates are performed on the last dimension of\n",
      "     |      indices. In other words, the dimensions should be the following:\n",
      "     |      \n",
      "     |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
      "     |      `batch_dim = num_prefix_dims + 1`\n",
      "     |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
      "     |           batch_dim:]`\n",
      "     |      \n",
      "     |      where\n",
      "     |      \n",
      "     |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
      "     |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
      "     |      `== var.shape[:num_prefix_dims]`\n",
      "     |      \n",
      "     |      And the operation performed can be expressed as:\n",
      "     |      \n",
      "     |      `var[i_1, ..., i_n,\n",
      "     |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
      "     |              i_1, ..., i_n, j]`\n",
      "     |      \n",
      "     |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
      "     |      `scatter_update`.\n",
      "     |      \n",
      "     |      To avoid this operation one can looping over the first `ndims` of the\n",
      "     |      variable and using `scatter_update` on the subtensors that result of slicing\n",
      "     |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
      "     |      efficient than this implementation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  count_up_to(self, limit)\n",
      "     |      Increments this variable until it reaches `limit`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Dataset.range instead.\n",
      "     |      \n",
      "     |      When that Op is run it tries to increment the variable by `1`. If\n",
      "     |      incrementing the variable would bring it above `limit` then the Op raises\n",
      "     |      the exception `OutOfRangeError`.\n",
      "     |      \n",
      "     |      If no error is raised, the Op outputs the value of the variable before\n",
      "     |      the increment.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        limit: value at which incrementing the variable raises an error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the variable value before the increment. If no\n",
      "     |        other Op modifies this variable, the values produced will all be\n",
      "     |        distinct.\n",
      "     |  \n",
      "     |  eval(self, session=None)\n",
      "     |      In a session, computes and returns the value of this variable.\n",
      "     |      \n",
      "     |      This is not a graph construction method, it does not add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          print(v.eval(sess))\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          print(v.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        session: The session to use to evaluate this variable. If none, the\n",
      "     |          default session is used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `ndarray` with a copy of the value of this variable.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  gather_nd(self, indices, name=None)\n",
      "     |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "     |      \n",
      "     |      See tf.gather_nd for details.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "     |          Index tensor.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Alias of `Variable.shape`.\n",
      "     |  \n",
      "     |  initialized_value(self)\n",
      "     |      Returns the value of the initialized variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "     |      \n",
      "     |      You should use this instead of the variable itself to initialize another\n",
      "     |      variable with a value that depends on the value of this variable.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Initialize 'v' with a random tensor.\n",
      "     |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
      "     |      # Use `initialized_value` to guarantee that `v` has been\n",
      "     |      # initialized before its value is used to initialize `w`.\n",
      "     |      # The random values are picked only once.\n",
      "     |      w = tf.Variable(v.initialized_value() * 2.0)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` holding the value of this variable after its initializer\n",
      "     |        has run.\n",
      "     |  \n",
      "     |  load(self, value, session=None)\n",
      "     |      Load new value into this variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "     |      \n",
      "     |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          v.load([2, 3], sess)\n",
      "     |          print(v.eval(sess)) # prints [2 3]\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          v.load([3, 4], sess)\n",
      "     |          print(v.eval()) # prints [3 4]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          value: New variable value\n",
      "     |          session: The session to use to evaluate this variable. If none, the\n",
      "     |            default session is used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: Session is not passed and no default session\n",
      "     |  \n",
      "     |  read_value(self)\n",
      "     |      Returns the value of this variable, read in the current context.\n",
      "     |      \n",
      "     |      Can be different from value() if it's on another device, with control\n",
      "     |      dependencies, etc.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Variable.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put variables in a set/dictionary.\n",
      "     |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
      "     |      longer available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> y = tf.Variable(10)\n",
      "     |      >>> z = tf.Variable(10)\n",
      "     |      >>> variable_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> variable_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `variable.ref()`.\n",
      "     |      \n",
      "     |      >>> variable_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in variable_set\n",
      "     |      True\n",
      "     |      >>> variable_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> variable_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Variable.\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Adds `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Divide this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Multiply this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_nd_add(self, indices, updates, name=None)\n",
      "     |      Applies sparse addition to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_add(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_sub(self, indices, updates, name=None)\n",
      "     |      Applies sparse subtraction to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_sub(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      After the update `v` would look like this:\n",
      "     |      \n",
      "     |          [1, -9, 3, -6, -4, 6, 7, -4]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_update(self, indices, updates, name=None)\n",
      "     |      Applies sparse assignment to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_update(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Subtracts `tf.IndexedSlices` from this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Overrides the shape for this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: the `TensorShape` representing the overridden shape.\n",
      "     |  \n",
      "     |  sparse_read(self, indices, name=None)\n",
      "     |      Gather slices from params axis axis according to indices.\n",
      "     |      \n",
      "     |      This function supports a subset of tf.gather, see tf.gather for details on\n",
      "     |      usage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "     |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  to_proto(self, export_scope=None)\n",
      "     |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        export_scope: Optional `string`. Name scope to remove.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
      "     |        in the specified name scope.\n",
      "     |  \n",
      "     |  value(self)\n",
      "     |      Returns the last snapshot of this variable.\n",
      "     |      \n",
      "     |      You usually do not need to call this method as all ops that need the value\n",
      "     |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
      "     |      \n",
      "     |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
      "     |      assign a new value to this tensor as it is not a reference to the variable.\n",
      "     |      \n",
      "     |      To avoid copies, if the consumer of the returned value is on the same device\n",
      "     |      as the variable, this actually returns the live value of the variable, not\n",
      "     |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
      "     |      is on a different device it will get a copy of the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_proto(variable_def, import_scope=None)\n",
      "     |      Returns a `Variable` object created from `variable_def`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  aggregation\n",
      "     |  \n",
      "     |  constraint\n",
      "     |      Returns the constraint function associated with this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The constraint function that was passed to the variable constructor.\n",
      "     |        Can be `None` if no constraint was passed.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The device of this variable.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of this variable.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` of this variable.\n",
      "     |  \n",
      "     |  initial_value\n",
      "     |      Returns the Tensor used as the initial value for the variable.\n",
      "     |      \n",
      "     |      Note that this is different from `initialized_value()` which runs\n",
      "     |      the op that initializes the variable before returning its value.\n",
      "     |      This method returns the tensor that is used by the op that initializes\n",
      "     |      the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  initializer\n",
      "     |      The initializer operation for this variable.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this variable.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` of this variable.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `TensorShape` of this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape`.\n",
      "     |  \n",
      "     |  synchronization\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
      "     |      Information on how to save this Variable as a slice.\n",
      "     |      \n",
      "     |      Provides internal support for saving variables as slices of a larger\n",
      "     |      variable.  This API is not public and is subject to change.\n",
      "     |      \n",
      "     |      Available properties:\n",
      "     |      \n",
      "     |      * full_name\n",
      "     |      * full_shape\n",
      "     |      * var_offset\n",
      "     |      * var_shape\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    VariableAggregation = class VariableAggregationV2(enum.Enum)\n",
      "     |  VariableAggregation(value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      "     |  \n",
      "     |  Indicates how a distributed variable will be aggregated.\n",
      "     |  \n",
      "     |  `tf.distribute.Strategy` distributes a model by making multiple copies\n",
      "     |  (called \"replicas\") acting on different elements of the input batch in a\n",
      "     |  data parallel model. When performing some variable-update operation,\n",
      "     |  for example `var.assign_add(x)`, in a model, we need to resolve how to combine\n",
      "     |  the different values for `x` computed in the different replicas.\n",
      "     |  \n",
      "     |  * `NONE`: This is the default, giving an error if you use a\n",
      "     |    variable-update operation with multiple replicas.\n",
      "     |  * `SUM`: Add the updates across replicas.\n",
      "     |  * `MEAN`: Take the arithmetic mean (\"average\") of the updates across replicas.\n",
      "     |  * `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same\n",
      "     |    update, but we only want to perform the update once. Used, e.g., for the\n",
      "     |    global step counter.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  >>> strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
      "     |  >>> with strategy.scope():\n",
      "     |  ...   v = tf.Variable(5.0, aggregation=tf.VariableAggregation.MEAN)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def update_fn():\n",
      "     |  ...   return v.assign_add(1.0)\n",
      "     |  >>> strategy.run(update_fn)\n",
      "     |  PerReplica:{\n",
      "     |    0: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
      "     |    1: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "     |  }\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableAggregationV2\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEAN = <VariableAggregationV2.MEAN: 2>\n",
      "     |  \n",
      "     |  NONE = <VariableAggregationV2.NONE: 0>\n",
      "     |  \n",
      "     |  ONLY_FIRST_REPLICA = <VariableAggregationV2.ONLY_FIRST_REPLICA: 3>\n",
      "     |  \n",
      "     |  SUM = <VariableAggregationV2.SUM: 1>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VariableSynchronization(enum.Enum)\n",
      "     |  VariableSynchronization(value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      "     |  \n",
      "     |  Indicates when a distributed variable will be synced.\n",
      "     |  \n",
      "     |  * `AUTO`: Indicates that the synchronization will be determined by the current\n",
      "     |    `DistributionStrategy` (eg. With `MirroredStrategy` this would be\n",
      "     |    `ON_WRITE`).\n",
      "     |  * `NONE`: Indicates that there will only be one copy of the variable, so\n",
      "     |    there is no need to sync.\n",
      "     |  * `ON_WRITE`: Indicates that the variable will be updated across devices\n",
      "     |    every time it is written.\n",
      "     |  * `ON_READ`: Indicates that the variable will be aggregated across devices\n",
      "     |    when it is read (eg. when checkpointing or when evaluating an op that uses\n",
      "     |    the variable).\n",
      "     |  \n",
      "     |    Example:\n",
      "     |  >>> temp_grad=[tf.Variable([0.], trainable=False,\n",
      "     |  ...                      synchronization=tf.VariableSynchronization.ON_READ,\n",
      "     |  ...                      aggregation=tf.VariableAggregation.MEAN\n",
      "     |  ...                      )]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableSynchronization\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AUTO = <VariableSynchronization.AUTO: 0>\n",
      "     |  \n",
      "     |  NONE = <VariableSynchronization.NONE: 1>\n",
      "     |  \n",
      "     |  ON_READ = <VariableSynchronization.ON_READ: 3>\n",
      "     |  \n",
      "     |  ON_WRITE = <VariableSynchronization.ON_WRITE: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    constant_initializer = class Constant(Initializer)\n",
      "     |  constant_initializer(value=0)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with constant values.\n",
      "     |  \n",
      "     |  Initializers allow you to pre-specify an initialization strategy, encoded in\n",
      "     |  the Initializer object, without knowing the shape and dtype of the variable\n",
      "     |  being initialized.\n",
      "     |  \n",
      "     |  `tf.constant_initializer` returns an object which when called returns a tensor\n",
      "     |  populated with the `value` specified in the constructor. This `value` must be\n",
      "     |  convertible to the requested `dtype`.\n",
      "     |  \n",
      "     |  The argument `value` can be a scalar constant value, or a list of\n",
      "     |  values. Scalars broadcast to whichever shape is requested from the\n",
      "     |  initializer.\n",
      "     |  \n",
      "     |  If `value` is a list, then the length of the list must be equal to the number\n",
      "     |  of elements implied by the desired shape of the tensor. If the total number of\n",
      "     |  elements in `value` is not equal to the number of elements required by the\n",
      "     |  tensor shape, the initializer will raise a `TypeError`.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> def make_variables(k, initializer):\n",
      "     |  ...   return (tf.Variable(initializer(shape=[k], dtype=tf.float32)),\n",
      "     |  ...           tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
      "     |  >>> v1, v2 = make_variables(3, tf.constant_initializer(2.))\n",
      "     |  >>> v1\n",
      "     |  <tf.Variable ... shape=(3,) ... numpy=array([2., 2., 2.], dtype=float32)>\n",
      "     |  >>> v2\n",
      "     |  <tf.Variable ... shape=(3, 3) ... numpy=\n",
      "     |  array([[2., 2., 2.],\n",
      "     |         [2., 2., 2.],\n",
      "     |         [2., 2., 2.]], dtype=float32)>\n",
      "     |  >>> make_variables(4, tf.random_uniform_initializer(minval=-1., maxval=1.))\n",
      "     |  (<tf.Variable...shape=(4,) dtype=float32...>, <tf.Variable...shape=(4, 4) ...\n",
      "     |  \n",
      "     |  >>> value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  >>> init = tf.constant_initializer(value)\n",
      "     |  >>> # Fitting shape\n",
      "     |  >>> tf.Variable(init(shape=[2, 4], dtype=tf.float32))\n",
      "     |  <tf.Variable ...\n",
      "     |  array([[0., 1., 2., 3.],\n",
      "     |         [4., 5., 6., 7.]], dtype=float32)>\n",
      "     |  >>> # Larger shape\n",
      "     |  >>> tf.Variable(init(shape=[3, 4], dtype=tf.float32))\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: ...value has 8 elements, shape is (3, 4) with 12 elements...\n",
      "     |  >>> # Smaller shape\n",
      "     |  >>> tf.Variable(init(shape=[2, 3], dtype=tf.float32))\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: ...value has 8 elements, shape is (2, 3) with 6 elements...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    value: A Python scalar, list or tuple of values, or a N-dimensional numpy\n",
      "     |      array. All elements of the initialized variable will be set to the\n",
      "     |      corresponding value in the `value` argument.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    TypeError: If the input `value` is not one of the expected types.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Constant\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, **kwargs)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided the dtype of the\n",
      "     |          tensor created will be the type of the inital value.\n",
      "     |        **kwargs: Additional keyword arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the initializer cannot create a tensor of the requested\n",
      "     |         dtype.\n",
      "     |  \n",
      "     |  __init__(self, value=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary.\n",
      "     |          It will typically be the output of `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    name_scope = class name_scope_v2(builtins.object)\n",
      "     |  name_scope(name)\n",
      "     |  \n",
      "     |  A context manager for use when defining a Python op.\n",
      "     |  \n",
      "     |  This context manager pushes a name scope, which will make the name of all\n",
      "     |  operations added within it have a prefix.\n",
      "     |  \n",
      "     |  For example, to define a new Python op called `my_op`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def my_op(a, b, c, name=None):\n",
      "     |    with tf.name_scope(\"MyOp\") as scope:\n",
      "     |      a = tf.convert_to_tensor(a, name=\"a\")\n",
      "     |      b = tf.convert_to_tensor(b, name=\"b\")\n",
      "     |      c = tf.convert_to_tensor(c, name=\"c\")\n",
      "     |      # Define some computation that uses `a`, `b`, and `c`.\n",
      "     |      return foo_op(..., name=scope)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  When executed, the Tensors `a`, `b`, `c`, will have names `MyOp/a`, `MyOp/b`,\n",
      "     |  and `MyOp/c`.\n",
      "     |  \n",
      "     |  Inside a `tf.function`, if the scope name already exists, the name will be\n",
      "     |  made unique by appending `_n`. For example, calling `my_op` the second time\n",
      "     |  will generate `MyOp_1/a`, etc.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Start the scope block.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The scope name.\n",
      "     |  \n",
      "     |  __exit__(self, type_arg, value_arg, traceback_arg)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, name)\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The prefix to use on all names created within the name scope.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If name is not a string.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "    \n",
      "    ones_initializer = class Ones(Initializer)\n",
      "     |  Initializer that generates tensors initialized to 1.\n",
      "     |  \n",
      "     |  Initializers allow you to pre-specify an initialization strategy, encoded in\n",
      "     |  the Initializer object, without knowing the shape and dtype of the variable\n",
      "     |  being initialized.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> def make_variables(k, initializer):\n",
      "     |  ...   return (tf.Variable(initializer(shape=[k], dtype=tf.float32)),\n",
      "     |  ...           tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
      "     |  >>> v1, v2 = make_variables(3, tf.ones_initializer())\n",
      "     |  >>> v1\n",
      "     |  <tf.Variable ... shape=(3,) ... numpy=array([1., 1., 1.], dtype=float32)>\n",
      "     |  >>> v2\n",
      "     |  <tf.Variable ... shape=(3, 3) ... numpy=\n",
      "     |  array([[1., 1., 1.],\n",
      "     |         [1., 1., 1.],\n",
      "     |         [1., 1., 1.]], dtype=float32)>\n",
      "     |  >>> make_variables(4, tf.random_uniform_initializer(minval=-1., maxval=1.))\n",
      "     |  (<tf.Variable...shape=(4,) dtype=float32...>, <tf.Variable...shape=(4, 4) ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Ones\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=tf.float32, **kwargs)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. Only numeric or boolean dtypes are\n",
      "     |          supported.\n",
      "     |        **kwargs: Additional keyword arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValuesError: If the dtype is not numeric or boolean.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary.\n",
      "     |          It will typically be the output of `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    random_normal_initializer = class RandomNormal(Initializer)\n",
      "     |  random_normal_initializer(mean=0.0, stddev=0.05, seed=None)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a normal distribution.\n",
      "     |  \n",
      "     |  Initializers allow you to pre-specify an initialization strategy, encoded in\n",
      "     |  the Initializer object, without knowing the shape and dtype of the variable\n",
      "     |  being initialized.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> def make_variables(k, initializer):\n",
      "     |  ...   return (tf.Variable(initializer(shape=[k], dtype=tf.float32)),\n",
      "     |  ...           tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
      "     |  >>> v1, v2 = make_variables(3,\n",
      "     |  ...                         tf.random_normal_initializer(mean=1., stddev=2.))\n",
      "     |  >>> v1\n",
      "     |  <tf.Variable ... shape=(3,) ... numpy=array([...], dtype=float32)>\n",
      "     |  >>> v2\n",
      "     |  <tf.Variable ... shape=(3, 3) ... numpy=\n",
      "     |  ...\n",
      "     |  >>> make_variables(4, tf.random_uniform_initializer(minval=-1., maxval=1.))\n",
      "     |  (<tf.Variable...shape=(4,) dtype=float32...>, <tf.Variable...shape=(4, 4) ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.random.set_seed` for behavior.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=tf.float32, **kwargs)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. Only floating point types are\n",
      "     |          supported.\n",
      "     |        **kwargs: Additional keyword arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the dtype is not floating point\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=0.05, seed=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary.\n",
      "     |          It will typically be the output of `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    random_uniform_initializer = class RandomUniform(Initializer)\n",
      "     |  random_uniform_initializer(minval=-0.05, maxval=0.05, seed=None)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a uniform distribution.\n",
      "     |  \n",
      "     |  Initializers allow you to pre-specify an initialization strategy, encoded in\n",
      "     |  the Initializer object, without knowing the shape and dtype of the variable\n",
      "     |  being initialized.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> def make_variables(k, initializer):\n",
      "     |  ...   return (tf.Variable(initializer(shape=[k], dtype=tf.float32)),\n",
      "     |  ...           tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
      "     |  >>> v1, v2 = make_variables(3, tf.ones_initializer())\n",
      "     |  >>> v1\n",
      "     |  <tf.Variable ... shape=(3,) ... numpy=array([1., 1., 1.], dtype=float32)>\n",
      "     |  >>> v2\n",
      "     |  <tf.Variable ... shape=(3, 3) ... numpy=\n",
      "     |  array([[1., 1., 1.],\n",
      "     |         [1., 1., 1.],\n",
      "     |         [1., 1., 1.]], dtype=float32)>\n",
      "     |  >>> make_variables(4, tf.random_uniform_initializer(minval=-1., maxval=1.))\n",
      "     |  (<tf.Variable...shape=(4,) dtype=float32...>, <tf.Variable...shape=(4, 4) ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    minval: A python scalar or a scalar tensor. Lower bound of the range of\n",
      "     |      random values to generate (inclusive).\n",
      "     |    maxval: A python scalar or a scalar tensor. Upper bound of the range of\n",
      "     |      random values to generate (exclusive).\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.random.set_seed` for behavior.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomUniform\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=tf.float32, **kwargs)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. Only floating point and integer\n",
      "     |          types are supported.\n",
      "     |        **kwargs: Additional keyword arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the dtype is not numeric.\n",
      "     |  \n",
      "     |  __init__(self, minval=-0.05, maxval=0.05, seed=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary.\n",
      "     |          It will typically be the output of `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    zeros_initializer = class Zeros(Initializer)\n",
      "     |  Initializer that generates tensors initialized to 0.\n",
      "     |  \n",
      "     |  Initializers allow you to pre-specify an initialization strategy, encoded in\n",
      "     |  the Initializer object, without knowing the shape and dtype of the variable\n",
      "     |  being initialized.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> def make_variables(k, initializer):\n",
      "     |  ...   return (tf.Variable(initializer(shape=[k], dtype=tf.float32)),\n",
      "     |  ...           tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
      "     |  >>> v1, v2 = make_variables(3, tf.zeros_initializer())\n",
      "     |  >>> v1\n",
      "     |  <tf.Variable ... shape=(3,) ... numpy=array([0., 0., 0.], dtype=float32)>\n",
      "     |  >>> v2\n",
      "     |  <tf.Variable ... shape=(3, 3) ... numpy=\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)>\n",
      "     |  >>> make_variables(4, tf.random_uniform_initializer(minval=-1., maxval=1.))\n",
      "     |  (<tf.Variable...shape=(4,) dtype=float32...>, <tf.Variable...shape=(4, 4) ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Zeros\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=tf.float32, **kwargs)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. Only numeric or boolean dtypes are\n",
      "     |         supported.\n",
      "     |        **kwargs: Additional keyword arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValuesError: If the dtype is not numeric or boolean.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary.\n",
      "     |          It will typically be the output of `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    Assert(condition, data, summarize=None, name=None)\n",
      "        Asserts that the given condition is true.\n",
      "        \n",
      "        If `condition` evaluates to false, print the list of tensors in `data`.\n",
      "        `summarize` determines how many entries of the tensors to print.\n",
      "        \n",
      "        Args:\n",
      "          condition: The condition to evaluate.\n",
      "          data: The tensors to print out when condition is false.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          assert_op: An `Operation` that, when executed, raises a\n",
      "          `tf.errors.InvalidArgumentError` if `condition` is not true.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          @compatibility(TF1)\n",
      "          When in TF V1 mode (that is, outside `tf.function`) Assert needs a control\n",
      "          dependency on the output to ensure the assertion executes:\n",
      "        \n",
      "        ```python\n",
      "        # Ensure maximum element of x is smaller or equal to 1\n",
      "        assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\n",
      "        with tf.control_dependencies([assert_op]):\n",
      "          ... code using x ...\n",
      "        ```\n",
      "        \n",
      "          @end_compatibility\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    abs(x, name=None)\n",
      "        Computes the absolute value of a tensor.\n",
      "        \n",
      "        Given a tensor of integer or floating-point values, this operation returns a\n",
      "        tensor of the same type, where each element contains the absolute value of the\n",
      "        corresponding element in the input.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "        `float32` or `float64` that is the absolute value of each element in `x`. For\n",
      "        a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "        \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> x = tf.constant([-2.25, 3.25])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([2.25, 3.25], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "        array([[5.25594901],\n",
      "               [6.60492241]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "            `int32`, `int64`, `complex64` or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
      "            with absolute values. Note, for `complex64` or `complex128` input, the\n",
      "            returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    acos(x, name=None)\n",
      "        Computes acos of x element-wise.\n",
      "        \n",
      "        Provided an input tensor, the `tf.math.acos` operation\n",
      "        returns the inverse cosine of each element of the tensor.\n",
      "        If `y = tf.math.cos(x)` then, `x = tf.math.acos(y)`.\n",
      "        \n",
      "        Input range is `[-1, 1]` and the output has a range of `[0, pi]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.0, -0.5, 3.4, 0.2, 0.0, -2], dtype = tf.float32)\n",
      "        >>> tf.math.acos(x)\n",
      "        <tf.Tensor: shape=(6,), dtype=float32,\n",
      "        numpy= array([0. , 2.0943952, nan, 1.3694383, 1.5707964, nan],\n",
      "        dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    acosh(x, name=None)\n",
      "        Computes inverse hyperbolic cosine of x element-wise.\n",
      "        \n",
      "        Given an input tensor, the function computes inverse hyperbolic cosine of every element.\n",
      "        \n",
      "        Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        \n",
      "        tf.math.acosh(x) ==> [nan nan 0. 0.62236255 5.9914584 9.903487 inf]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    add(x, y, name=None)\n",
      "        Returns x + y element-wise.\n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        Add a scalar and a list:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = 1\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Note that binary `+` operator can be used instead:\n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        >>> x + y\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Add a tensor and a list of same shape:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        conversion.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        >>> y = [2**7 + 1, 2**7 + 2]\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "        \n",
      "        When adding two input values of different shapes, `Add` follows NumPy\n",
      "        broadcasting rules. The two input array shapes are compared element-wise.\n",
      "        Starting with the trailing dimensions, the two dimensions either have to be\n",
      "        equal or one of them needs to be `1`.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "        >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [2, 2, 3, 3]\n",
      "        \n",
      "        Another example with two arrays of different dimension.\n",
      "        \n",
      "        >>> x = np.ones([1, 2, 1, 4])\n",
      "        >>> y = np.ones([3, 4])\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [1, 2, 3, 4]\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "            float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "            int32, int64, complex64, complex128, string.\n",
      "          y: A `tf.Tensor`. Must have the same type as x.\n",
      "          name: A name for the operation (optional)\n",
      "    \n",
      "    add_n(inputs, name=None)\n",
      "        Returns the element-wise sum of a list of tensors.\n",
      "        \n",
      "        All inputs in the list must have the same shape. This op does not\n",
      "        [broadcast](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        its inputs. If you need broadcasting, use `tf.math.add` (or the `+` operator)\n",
      "        instead.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([[3, 5], [4, 8]])\n",
      "        >>> b = tf.constant([[1, 6], [2, 9]])\n",
      "        >>> tf.math.add_n([a, b, a]).numpy()\n",
      "        array([[ 7, 16],\n",
      "               [10, 25]], dtype=int32)\n",
      "        \n",
      "        See Also:\n",
      "        \n",
      "        * `tf.reduce_sum(inputs, axis=0)` - This performs the same mathematical\n",
      "          operation, but `tf.add_n` may be more efficient because it sums the\n",
      "          tensors directly. `reduce_sum` on the other hand calls\n",
      "          `tf.convert_to_tensor` on the list of tensors, unnecessarily stacking them\n",
      "          into a single tensor before summing.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` or `tf.IndexedSlices` objects, each with the\n",
      "            same shape and type. `tf.IndexedSlices` objects will be converted into\n",
      "            dense tensors prior to adding.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    approx_top_k(input, k, reduction_dimension=-1, recall_target=0.95, is_max_k=True, reduction_input_size_override=-1, aggregate_to_topk=True, name=None)\n",
      "        Returns min/max k values and their indices of the input operand in an approximate manner.\n",
      "        \n",
      "        See https://arxiv.org/abs/2206.14286 for the algorithm details.\n",
      "        \n",
      "        This op is only optimized on TPU currently.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.\n",
      "            Array to search. Must be at least 1-D of the floating type\n",
      "          k: An `int` that is `>= 0`. Specifies the number of min/max-k.\n",
      "          reduction_dimension: An optional `int`. Defaults to `-1`.\n",
      "            Integer dimension along which to search. Default: -1.\n",
      "          recall_target: An optional `float`. Defaults to `0.95`.\n",
      "            Recall target for the approximation. Range in (0,1]\n",
      "          is_max_k: An optional `bool`. Defaults to `True`.\n",
      "            When true, computes max-k; otherwise computes min-k.\n",
      "          reduction_input_size_override: An optional `int`. Defaults to `-1`.\n",
      "            When set to a positive value, it overrides the size determined by\n",
      "        \n",
      "            `input[reduction_dim]` for evaluating the recall. This option is useful when\n",
      "        \n",
      "            the given `input` is only a subset of the overall computation in SPMD or\n",
      "        \n",
      "            distributed pipelines, where the true input size cannot be deferred by the\n",
      "        \n",
      "            `input` shape.\n",
      "          aggregate_to_topk: An optional `bool`. Defaults to `True`.\n",
      "            When true, aggregates approximate results to top-k. When false, returns the\n",
      "        \n",
      "            approximate results. The number of the approximate results is implementation\n",
      "        \n",
      "            defined and is greater equals to the specified `k`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (values, indices).\n",
      "        \n",
      "          values: A `Tensor`. Has the same type as `input`.\n",
      "          indices: A `Tensor` of type `int32`.\n",
      "    \n",
      "    argmax = argmax_v2(input, axis=None, output_type=tf.int64, name=None)\n",
      "        Returns the index with the largest value across axes of a tensor.\n",
      "        \n",
      "        In case of identity returns the smallest index.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> A = tf.constant([2, 20, 30, 3, 6])\n",
      "        >>> tf.math.argmax(A)  # A[2] is maximum in tensor A\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=2>\n",
      "        >>> B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
      "        ...                  [14, 45, 23, 5, 27]])\n",
      "        >>> tf.math.argmax(B, 0)\n",
      "        <tf.Tensor: shape=(5,), dtype=int64, numpy=array([2, 2, 0, 2, 2])>\n",
      "        >>> tf.math.argmax(B, 1)\n",
      "        <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 1])>\n",
      "        >>> C = tf.constant([0, 0, 0, 0])\n",
      "        >>> tf.math.argmax(C) # Returns smallest index in case of ties\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=0>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          axis: An integer, the axis to reduce across. Default to 0.\n",
      "          output_type: An optional output dtype (`tf.int32` or `tf.int64`). Defaults\n",
      "            to `tf.int64`.\n",
      "          name: An optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmin = argmin_v2(input, axis=None, output_type=tf.int64, name=None)\n",
      "        Returns the index with the smallest value across axes of a tensor.\n",
      "        \n",
      "        Returns the smallest index in case of ties.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`,\n",
      "            `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`,\n",
      "            `uint64`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to\n",
      "            `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "        \n",
      "        Usage:\n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        b = tf.math.argmin(input = a)\n",
      "        c = tf.keras.backend.eval(b)\n",
      "        # c = 0\n",
      "        # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "        ```\n",
      "    \n",
      "    argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)\n",
      "        Returns the indices of a tensor that give its sorted order along an axis.\n",
      "        \n",
      "        >>> values = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> sort_order = tf.argsort(values)\n",
      "        >>> sort_order.numpy()\n",
      "        array([0, 3, 1, 2, 5, 4], dtype=int32)\n",
      "        \n",
      "        For a 1D tensor:\n",
      "        \n",
      "        >>> sorted = tf.gather(values, sort_order)\n",
      "        >>> assert tf.reduce_all(sorted == tf.sort(values))\n",
      "        \n",
      "        For higher dimensions, the output has the same shape as\n",
      "        `values`, but along the given axis, values represent the index of the sorted\n",
      "        element in that slice of the tensor at the given position.\n",
      "        \n",
      "        >>> mat = [[30,20,10],\n",
      "        ...        [20,10,30],\n",
      "        ...        [10,30,20]]\n",
      "        >>> indices = tf.argsort(mat)\n",
      "        >>> indices.numpy()\n",
      "        array([[2, 1, 0],\n",
      "               [1, 0, 2],\n",
      "               [0, 2, 1]], dtype=int32)\n",
      "        \n",
      "        If `axis=-1` these indices can be used to apply a sort using `tf.gather`:\n",
      "        \n",
      "        >>> tf.gather(mat, indices, batch_dims=-1).numpy()\n",
      "        array([[10, 20, 30],\n",
      "               [10, 20, 30],\n",
      "               [10, 20, 30]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.sort`: Sort along an axis.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          stable: If True, equal elements in the original tensor will not be\n",
      "            re-ordered in the returned order. Unstable sort is not yet implemented,\n",
      "            but will eventually be the default for performance reasons. If you require\n",
      "            a stable order, pass `stable=True` for forwards compatibility.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An int32 `Tensor` with the same shape as `values`. The indices that would\n",
      "              sort each slice of the given `values` along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "    \n",
      "    as_dtype(type_value)\n",
      "        Converts the given `type_value` to a `tf.DType`.\n",
      "        \n",
      "        Inputs can be existing `tf.DType` objects, a [`DataType`\n",
      "        enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),\n",
      "        a string type name, or a\n",
      "        [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).\n",
      "        \n",
      "        Examples:\n",
      "        >>> tf.as_dtype(2)  # Enum value for float64.\n",
      "        tf.float64\n",
      "        \n",
      "        >>> tf.as_dtype('float')\n",
      "        tf.float32\n",
      "        \n",
      "        >>> tf.as_dtype(np.int32)\n",
      "        tf.int32\n",
      "        \n",
      "        Note: `DType` values are interned (i.e. a single instance of each dtype is\n",
      "        stored in a map). When passed a new `DType` object, `as_dtype` always returns\n",
      "        the interned value.\n",
      "        \n",
      "        Args:\n",
      "          type_value: A value that can be converted to a `tf.DType` object.\n",
      "        \n",
      "        Returns:\n",
      "          A `DType` corresponding to `type_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `type_value` cannot be converted to a `DType`.\n",
      "    \n",
      "    as_string(input, precision=-1, scientific=False, shortest=False, width=-1, fill='', name=None)\n",
      "        Converts each entry in the given tensor to strings.\n",
      "        \n",
      "        Supports many numeric types and boolean.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For Unicode, see the\n",
      "        \n",
      "        [https://www.tensorflow.org/tutorials/representation/unicode](Working with Unicode text)\n",
      "        \n",
      "        tutorial.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.strings.as_string([3, 2])\n",
      "        \n",
      "        <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'3', b'2'], dtype=object)>\n",
      "        \n",
      "        >>> tf.strings.as_string([3.1415926, 2.71828], precision=2).numpy()\n",
      "        \n",
      "        array([b'3.14', b'2.72'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`, `variant`, `string`.\n",
      "          precision: An optional `int`. Defaults to `-1`.\n",
      "            The post-decimal precision to use for floating point numbers.\n",
      "        \n",
      "            Only used if precision > -1.\n",
      "          scientific: An optional `bool`. Defaults to `False`.\n",
      "            Use scientific notation for floating point numbers.\n",
      "          shortest: An optional `bool`. Defaults to `False`.\n",
      "            Use shortest representation (either scientific or standard) for\n",
      "        \n",
      "            floating point numbers.\n",
      "          width: An optional `int`. Defaults to `-1`.\n",
      "            Pad pre-decimal numbers to this width.\n",
      "        \n",
      "            Applies to both floating point and integer numbers.\n",
      "        \n",
      "            Only used if width > -1.\n",
      "          fill: An optional `string`. Defaults to `\"\"`.\n",
      "            The value to pad if width > -1.  If empty, pads with spaces.\n",
      "        \n",
      "            Another typical value is '0'.  String cannot be longer than 1 character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    asin(x, name=None)\n",
      "        Computes the trignometric inverse sine of x element-wise.\n",
      "        \n",
      "        The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that\n",
      "        \n",
      "        if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        **Note**: The output of `tf.math.asin` will lie within the invertible range\n",
      "        \n",
      "        of sine, i.e [-pi/2, pi/2].\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        \n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        \n",
      "        y = tf.math.sin(x) # [0.8659266, 0.7068252]\n",
      "        \n",
      "        \n",
      "        \n",
      "        tf.math.asin(y) # [1.047, 0.785] = x\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    asinh(x, name=None)\n",
      "        Computes inverse hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic sine\n",
      "        \n",
      "          for every element in the tensor. Both input and output has a range of\n",
      "        \n",
      "          `[-inf, inf]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        \n",
      "          tf.math.asinh(x) ==> [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    assert_equal = assert_equal_v2(x, y, message=None, summarize=None, name=None)\n",
      "        Assert the condition `x == y` holds element-wise.\n",
      "        \n",
      "        This Op checks that `x[i] == y[i]` holds for every pair of (possibly\n",
      "        broadcast) elements of `x` and `y`. If both `x` and `y` are empty, this is\n",
      "        trivially satisfied.\n",
      "        \n",
      "        If `x` == `y` does not hold, `message`, as well as the first `summarize`\n",
      "        entries of `x` and `y` are printed, and `InvalidArgumentError` is raised.\n",
      "        \n",
      "        When using inside `tf.function`, this API takes effects during execution.\n",
      "        It's recommended to use this API with `tf.control_dependencies` to\n",
      "        ensure the correct execution order.\n",
      "        \n",
      "        In the following example, without `tf.control_dependencies`, errors may\n",
      "        not be raised at all.\n",
      "        Check `tf.control_dependencies` for more details.\n",
      "        \n",
      "        >>> def check_size(x):\n",
      "        ...   with tf.control_dependencies([\n",
      "        ...       tf.debugging.assert_equal(tf.size(x), 3,\n",
      "        ...                       message='Bad tensor size')]):\n",
      "        ...     return x\n",
      "        \n",
      "        >>> check_size(tf.ones([2, 3], tf.float32))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          message: A string to prefix to the default message. (optional)\n",
      "          summarize: Print this many entries of each tensor. (optional)\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x == y` is False. This can\n",
      "            be used with `tf.control_dependencies` inside of `tf.function`s to\n",
      "            block followup computation until the check has executed.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during eager\n",
      "            execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_greater = assert_greater_v2(x, y, message=None, summarize=None, name=None)\n",
      "        Assert the condition `x > y` holds element-wise.\n",
      "        \n",
      "        This Op checks that `x[i] > y[i]` holds for every pair of (possibly\n",
      "        broadcast) elements of `x` and `y`. If both `x` and `y` are empty, this is\n",
      "        trivially satisfied.\n",
      "        \n",
      "        If `x` > `y` does not hold, `message`, as well as the first `summarize`\n",
      "        entries of `x` and `y` are printed, and `InvalidArgumentError` is raised.\n",
      "        \n",
      "        When using inside `tf.function`, this API takes effects during execution.\n",
      "        It's recommended to use this API with `tf.control_dependencies` to\n",
      "        ensure the correct execution order.\n",
      "        \n",
      "        In the following example, without `tf.control_dependencies`, errors may\n",
      "        not be raised at all.\n",
      "        Check `tf.control_dependencies` for more details.\n",
      "        \n",
      "        >>> def check_size(x):\n",
      "        ...   with tf.control_dependencies([\n",
      "        ...       tf.debugging.assert_greater(tf.size(x), 9,\n",
      "        ...                       message='Bad tensor size')]):\n",
      "        ...     return x\n",
      "        \n",
      "        >>> check_size(tf.ones([2, 3], tf.float32))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          message: A string to prefix to the default message. (optional)\n",
      "          summarize: Print this many entries of each tensor. (optional)\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > y` is False. This can\n",
      "            be used with `tf.control_dependencies` inside of `tf.function`s to\n",
      "            block followup computation until the check has executed.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during eager\n",
      "            execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_less = assert_less_v2(x, y, message=None, summarize=None, name=None)\n",
      "        Assert the condition `x < y` holds element-wise.\n",
      "        \n",
      "        This Op checks that `x[i] < y[i]` holds for every pair of (possibly\n",
      "        broadcast) elements of `x` and `y`. If both `x` and `y` are empty, this is\n",
      "        trivially satisfied.\n",
      "        \n",
      "        If `x` < `y` does not hold, `message`, as well as the first `summarize`\n",
      "        entries of `x` and `y` are printed, and `InvalidArgumentError` is raised.\n",
      "        \n",
      "        When using inside `tf.function`, this API takes effects during execution.\n",
      "        It's recommended to use this API with `tf.control_dependencies` to\n",
      "        ensure the correct execution order.\n",
      "        \n",
      "        In the following example, without `tf.control_dependencies`, errors may\n",
      "        not be raised at all.\n",
      "        Check `tf.control_dependencies` for more details.\n",
      "        \n",
      "        >>> def check_size(x):\n",
      "        ...   with tf.control_dependencies([\n",
      "        ...       tf.debugging.assert_less(tf.size(x), 3,\n",
      "        ...                       message='Bad tensor size')]):\n",
      "        ...     return x\n",
      "        \n",
      "        >>> check_size(tf.ones([2, 3], tf.float32))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          message: A string to prefix to the default message. (optional)\n",
      "          summarize: Print this many entries of each tensor. (optional)\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < y` is False. This can\n",
      "            be used with `tf.control_dependencies` inside of `tf.function`s to\n",
      "            block followup computation until the check has executed.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during eager\n",
      "            execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_rank = assert_rank_v2(x, rank, message=None, name=None)\n",
      "        Assert that `x` has rank equal to `rank`.\n",
      "        \n",
      "        This Op checks that the rank of `x` is equal to `rank`.\n",
      "        \n",
      "        If `x` has a different rank, `message`, as well as the shape of `x` are\n",
      "        printed, and `InvalidArgumentError` is raised.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor`.\n",
      "          rank: Scalar integer `Tensor`.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional). Defaults to\n",
      "            \"assert_rank\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "          This can be used with `tf.control_dependencies` inside of `tf.function`s\n",
      "          to block followup computation until the check has executed.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x` does not have rank `rank`. The check can be performed immediately\n",
      "            during eager execution or if the shape of `x` is statically known.\n",
      "    \n",
      "    atan(x, name=None)\n",
      "        Computes the trignometric inverse tangent of x element-wise.\n",
      "        \n",
      "        The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that\n",
      "        \n",
      "        if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        **Note**: The output of `tf.math.atan` will lie within the invertible range\n",
      "        \n",
      "        of tan, i.e (-pi/2, pi/2).\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        \n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        \n",
      "        y = tf.math.tan(x) # [1.731261, 0.99920404]\n",
      "        \n",
      "        \n",
      "        \n",
      "        tf.math.atan(y) # [1.047, 0.785] = x\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    atan2(y, x, name=None)\n",
      "        Computes arctangent of `y/x` element-wise, respecting signs of the arguments.\n",
      "        \n",
      "        This is the angle \\\\( \\theta \\in [-\\pi, \\pi] \\\\) such that\n",
      "        \n",
      "        \\\\[ x = r \\cos(\\theta) \\\\]\n",
      "        \n",
      "        and\n",
      "        \n",
      "        \\\\[ y = r \\sin(\\theta) \\\\]\n",
      "        \n",
      "        where \\\\(r = \\sqrt{x^2 + y^2} \\\\).\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = [1., 1.]\n",
      "        \n",
      "        >>> y = [1., -1.]\n",
      "        \n",
      "        >>> print((tf.math.atan2(y,x) * (180 / np.pi)).numpy())\n",
      "        \n",
      "        [ 45. -45.]\n",
      "        \n",
      "        Args:\n",
      "          y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `y`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `y`.\n",
      "    \n",
      "    atanh(x, name=None)\n",
      "        Computes inverse hyperbolic tangent of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic tangent\n",
      "        \n",
      "          for every element in the tensor. Input range is `[-1,1]` and output range is\n",
      "        \n",
      "          `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the\n",
      "        \n",
      "          input is `1`, output will be `inf`. Values outside the range will have\n",
      "        \n",
      "          `nan` as output.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -1, -0.5, 1, 0, 0.5, 10, float(\"inf\")])\n",
      "        \n",
      "          tf.math.atanh(x) ==> [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    batch_to_space = batch_to_space_v2(input, block_shape, crops, name=None)\n",
      "        BatchToSpace for N-D tensors of type T.\n",
      "        \n",
      "        This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n",
      "        shape `block_shape + [batch]`, interleaves these blocks back into the grid\n",
      "        defined by the spatial dimensions `[1, ..., M]`, to obtain a result with the\n",
      "        same rank as the input.  The spatial dimensions of this intermediate result\n",
      "        are then optionally cropped according to `crops` to produce the output.  This\n",
      "        is the reverse of SpaceToBatch (see `tf.space_to_batch`).\n",
      "        \n",
      "        Args:\n",
      "          input: A N-D `Tensor` with shape `input_shape = [batch] + spatial_shape +\n",
      "            remaining_shape`, where `spatial_shape` has M dimensions.\n",
      "          block_shape: A 1-D `Tensor` with shape [M]. Must be one of the following\n",
      "            types: `int32`, `int64`. All values must be >= 1. For backwards\n",
      "            compatibility with TF 1.0, this parameter may be an int, in which case it\n",
      "            is converted to\n",
      "            `numpy.array([block_shape, block_shape],\n",
      "            dtype=numpy.int64)`.\n",
      "          crops: A  2-D `Tensor` with shape `[M, 2]`. Must be one of the\n",
      "            following types: `int32`, `int64`. All values must be >= 0.\n",
      "            `crops[i] = [crop_start, crop_end]` specifies the amount to crop from\n",
      "            input dimension `i + 1`, which corresponds to spatial dimension `i`.\n",
      "            It is required that\n",
      "            `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.\n",
      "            This operation is equivalent to the following steps:\n",
      "            1. Reshape `input` to `reshaped` of shape: [block_shape[0], ...,\n",
      "              block_shape[M-1], batch / prod(block_shape), input_shape[1], ...,\n",
      "              input_shape[N-1]]\n",
      "            2. Permute dimensions of `reshaped` to produce `permuted` of shape\n",
      "               [batch / prod(block_shape),  input_shape[1], block_shape[0], ...,\n",
      "               input_shape[M], block_shape[M-1], input_shape[M+1],\n",
      "              ..., input_shape[N-1]]\n",
      "            3. Reshape `permuted` to produce `reshaped_permuted` of shape\n",
      "               [batch / prod(block_shape), input_shape[1] * block_shape[0], ...,\n",
      "               input_shape[M] * block_shape[M-1], input_shape[M+1], ...,\n",
      "               input_shape[N-1]]\n",
      "            4. Crop the start and end of dimensions `[1, ..., M]` of\n",
      "               `reshaped_permuted` according to `crops` to produce the output\n",
      "               of shape:\n",
      "               [batch / prod(block_shape),  input_shape[1] *\n",
      "                 block_shape[0] - crops[0,0] - crops[0,1], ..., input_shape[M] *\n",
      "                 block_shape[M-1] - crops[M-1,0] - crops[M-1,1],  input_shape[M+1],\n",
      "                 ..., input_shape[N-1]]\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        1. For the following input of shape `[4, 1, 1, 1]`,\n",
      "           `block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "           ```python\n",
      "           [[[[1]]],\n",
      "            [[[2]]],\n",
      "            [[[3]]],\n",
      "            [[[4]]]]\n",
      "           ```\n",
      "        \n",
      "          The output tensor has shape `[1, 2, 2, 1]` and value:\n",
      "        \n",
      "           ```\n",
      "           x = [[[[1], [2]],\n",
      "               [[3], [4]]]]\n",
      "           ```\n",
      "        \n",
      "        2. For the following input of shape `[4, 1, 1, 3]`,\n",
      "           `block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "           ```python\n",
      "           [[[1,  2,   3]],\n",
      "            [[4,  5,   6]],\n",
      "            [[7,  8,   9]],\n",
      "            [[10, 11, 12]]]\n",
      "           ```\n",
      "        \n",
      "          The output tensor has shape `[1, 2, 2, 3]` and value:\n",
      "        \n",
      "          ```python\n",
      "           x = [[[[1, 2, 3], [4,  5,  6 ]],\n",
      "                 [[7, 8, 9], [10, 11, 12]]]]\n",
      "           ```\n",
      "        \n",
      "        3. For the following\n",
      "           input of shape `[4, 2, 2, 1]`,\n",
      "           `block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "           ```python\n",
      "           x = [[[[1], [3]], [[ 9], [11]]],\n",
      "                [[[2], [4]], [[10], [12]]],\n",
      "                [[[5], [7]], [[13], [15]]],\n",
      "                [[[6], [8]], [[14], [16]]]]\n",
      "           ```\n",
      "        \n",
      "          The output tensor has shape `[1, 4, 4, 1]` and value:\n",
      "        \n",
      "          ```python\n",
      "           x = [[[1],  [2],  [ 3], [ 4]],\n",
      "                [[5],  [6],  [ 7], [ 8]],\n",
      "                [[9],  [10], [11], [12]],\n",
      "                [[13], [14], [15], [16]]]\n",
      "           ```\n",
      "        \n",
      "        4. For the following input of shape\n",
      "            `[8, 1, 3, 1]`,\n",
      "            `block_shape = [2, 2]`, and `crops = [[0, 0], [2, 0]]`:\n",
      "        \n",
      "            ```python\n",
      "            x = [[[[0], [ 1], [ 3]]],\n",
      "                 [[[0], [ 9], [11]]],\n",
      "                 [[[0], [ 2], [ 4]]],\n",
      "                 [[[0], [10], [12]]],\n",
      "                 [[[0], [ 5], [ 7]]],\n",
      "                 [[[0], [13], [15]]],\n",
      "                 [[[0], [ 6], [ 8]]],\n",
      "                 [[[0], [14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[2, 2, 4, 1]` and value:\n",
      "        \n",
      "            ```python\n",
      "            x = [[[[ 1], [ 2], [ 3], [ 4]],\n",
      "                  [[ 5], [ 6], [ 7], [ 8]]],\n",
      "                 [[[ 9], [10], [11], [12]],\n",
      "                  [[13], [14], [15], [16]]]]\n",
      "            ```\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    bitcast(input, type, name=None)\n",
      "        Bitcasts a tensor from one type to another without copying data.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor that has the same buffer\n",
      "        \n",
      "        data as `input` with datatype `type`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        If the input datatype `T` is larger than the output datatype `type` then the\n",
      "        \n",
      "        shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].\n",
      "        \n",
      "        \n",
      "        \n",
      "        If `T` is smaller than `type`, the operator requires that the rightmost\n",
      "        \n",
      "        dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from\n",
      "        \n",
      "        [..., sizeof(`type`)/sizeof(`T`)] to [...].\n",
      "        \n",
      "        \n",
      "        \n",
      "        tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype\n",
      "        \n",
      "        (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()\n",
      "        \n",
      "        gives module error.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example 1:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> a = [1., 2., 3.]\n",
      "        \n",
      "        >>> equality_bitcast = tf.bitcast(a, tf.complex128)\n",
      "        \n",
      "        Traceback (most recent call last):\n",
      "        \n",
      "        ...\n",
      "        \n",
      "        InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]\n",
      "        \n",
      "        >>> equality_cast = tf.cast(a, tf.complex128)\n",
      "        \n",
      "        >>> print(equality_cast)\n",
      "        \n",
      "        tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example 2:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)\n",
      "        \n",
      "        <tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example 3:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = [1., 2., 3.]\n",
      "        \n",
      "        >>> y = [0., 2., 3.]\n",
      "        \n",
      "        >>> equality= tf.equal(x,y)\n",
      "        \n",
      "        >>> equality_cast = tf.cast(equality,tf.float32)\n",
      "        \n",
      "        >>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)\n",
      "        \n",
      "        >>> print(equality)\n",
      "        \n",
      "        tf.Tensor([False True True], shape=(3,), dtype=bool)\n",
      "        \n",
      "        >>> print(equality_cast)\n",
      "        \n",
      "        tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)\n",
      "        \n",
      "        >>> print(equality_bitcast)\n",
      "        \n",
      "        tf.Tensor(\n",
      "        \n",
      "            [[  0   0   0   0]\n",
      "        \n",
      "             [  0   0 128  63]\n",
      "        \n",
      "             [  0   0 128  63]], shape=(3, 4), dtype=uint8)\n",
      "        \n",
      "        \n",
      "        \n",
      "        *NOTE*: Bitcast is implemented as a low-level cast, so machines with different\n",
      "        \n",
      "        endian orderings will give different results. A copy from input buffer to output\n",
      "        \n",
      "        buffer is made on BE machines when types are of different sizes in order to get\n",
      "        \n",
      "        the same casting results as on LE machines.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.\n",
      "          type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `type`.\n",
      "    \n",
      "    boolean_mask = boolean_mask_v2(tensor, mask, axis=None, name='boolean_mask')\n",
      "        Apply boolean mask to tensor.\n",
      "        \n",
      "        Numpy equivalent is `tensor[mask]`.\n",
      "        \n",
      "        In general, `0 < dim(mask) = K <= dim(tensor)`, and `mask`'s shape must match\n",
      "        the first K dimensions of `tensor`'s shape.  We then have:\n",
      "          `boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]`\n",
      "        where `(i1,...,iK)` is the ith `True` entry of `mask` (row-major order).\n",
      "        The `axis` could be used with `mask` to indicate the axis to mask from.\n",
      "        In that case, `axis + dim(mask) <= dim(tensor)` and `mask`'s shape must match\n",
      "        the first `axis + dim(mask)` dimensions of `tensor`'s shape.\n",
      "        \n",
      "        See also: `tf.ragged.boolean_mask`, which can be applied to both dense and\n",
      "        ragged tensors, and can be used if you need to preserve the masked dimensions\n",
      "        of `tensor` (rather than flattening them, as `tf.boolean_mask` does).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tensor = [0, 1, 2, 3]  # 1-D example\n",
      "        >>> mask = np.array([True, False, True, False])\n",
      "        >>> tf.boolean_mask(tensor, mask)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 2], dtype=int32)>\n",
      "        \n",
      "        >>> tensor = [[1, 2], [3, 4], [5, 6]] # 2-D example\n",
      "        >>> mask = np.array([True, False, True])\n",
      "        >>> tf.boolean_mask(tensor, mask)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [5, 6]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor:  N-D Tensor.\n",
      "          mask:  K-D boolean Tensor, K <= N and K must be known statically.\n",
      "          axis:  A 0-D int Tensor representing the axis in `tensor` to mask from. By\n",
      "            default, axis is 0 which will mask from the first dimension. Otherwise K +\n",
      "            axis <= N.\n",
      "          name:  A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          (N-K+1)-dimensional tensor populated by entries in `tensor` corresponding\n",
      "          to `True` values in `mask`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If shapes do not conform.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # 2-D example\n",
      "        tensor = [[1, 2], [3, 4], [5, 6]]\n",
      "        mask = np.array([True, False, True])\n",
      "        boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]\n",
      "        ```\n",
      "    \n",
      "    broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given symbolic shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are Tensors representing shapes (i.e. the result\n",
      "        of calling tf.shape on another Tensor) this computes a Tensor which is the\n",
      "        shape of the result of a broadcasting op applied in tensors of shapes\n",
      "        `shape_x` and `shape_y`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors do not have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = (1, 2, 3)\n",
      "        >>> shape_y = (5, 1, 3)\n",
      "        >>> tf.broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 2, 3], ...>\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A rank 1 integer `Tensor`, representing the shape of x.\n",
      "          shape_y: A rank 1 integer `Tensor`, representing the shape of y.\n",
      "        \n",
      "        Returns:\n",
      "          A rank 1 integer `Tensor` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: If the two shapes are incompatible for\n",
      "          broadcasting.\n",
      "    \n",
      "    broadcast_static_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given known shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are fully known `TensorShape`s this computes a\n",
      "        `TensorShape` which is the shape of the result of a broadcasting op applied in\n",
      "        tensors of shapes `shape_x` and `shape_y`.\n",
      "        \n",
      "        For example, if shape_x is `TensorShape([1, 2, 3])` and shape_y is\n",
      "        `TensorShape([5, 1, 3])`, the result is a TensorShape whose value is\n",
      "        `TensorShape([5, 2, 3])`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = tf.TensorShape([1, 2, 3])\n",
      "        >>> shape_y = tf.TensorShape([5, 1 ,3])\n",
      "        >>> tf.broadcast_static_shape(shape_x, shape_y)\n",
      "        TensorShape([5, 2, 3])\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A `TensorShape`\n",
      "          shape_y: A `TensorShape`\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorShape` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the two shapes can not be broadcasted.\n",
      "    \n",
      "    broadcast_to(input, shape, name=None)\n",
      "        Broadcast an array for a compatible shape.\n",
      "        \n",
      "        Broadcasting is the process of making arrays to have compatible shapes\n",
      "        \n",
      "        for arithmetic operations. Two shapes are compatible if for each\n",
      "        \n",
      "        dimension pair they are either equal or one of them is one.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3]])   # Shape (1, 3,)\n",
      "        \n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        \n",
      "        >>> print(y)\n",
      "        \n",
      "        tf.Tensor(\n",
      "        \n",
      "            [[1 2 3]\n",
      "        \n",
      "             [1 2 3]], shape=(2, 3), dtype=int32)\n",
      "        \n",
      "        \n",
      "        \n",
      "        In the above example, the input Tensor with the shape of `[1, 3]`\n",
      "        \n",
      "        is broadcasted to output Tensor with shape of `[2, 3]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        When broadcasting, if a tensor has fewer axes than necessary its shape is\n",
      "        \n",
      "        padded on the left with ones. So this gives the same result as the previous\n",
      "        \n",
      "        example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([1, 2, 3])   # Shape (3,)\n",
      "        \n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        When doing broadcasted operations such as multiplying a tensor\n",
      "        \n",
      "        by a scalar, broadcasting (usually) confers some time or space\n",
      "        \n",
      "        benefit, as the broadcasted tensor is never materialized.\n",
      "        \n",
      "        \n",
      "        \n",
      "        However, `broadcast_to` does not carry with it any such benefits.\n",
      "        \n",
      "        The newly-created tensor takes the full memory of the broadcasted\n",
      "        \n",
      "        shape. (In a graph context, `broadcast_to` might be fused to\n",
      "        \n",
      "        subsequent operation and then be optimized away, however.)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. A Tensor to broadcast.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 1-D `int` Tensor. The shape of the desired output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    case = case_v2(pred_fn_pairs, default=None, exclusive=False, strict=False, name='case')\n",
      "        Create a case operation.\n",
      "        \n",
      "        See also `tf.switch_case`.\n",
      "        \n",
      "        The `pred_fn_pairs` parameter is a list of pairs of size N.\n",
      "        Each pair contains a boolean scalar tensor and a python callable that\n",
      "        creates the tensors to be returned if the boolean evaluates to True.\n",
      "        `default` is a callable generating a list of tensors. All the callables\n",
      "        in `pred_fn_pairs` as well as `default` (if provided) should return the same\n",
      "        number and types of tensors.\n",
      "        \n",
      "        If `exclusive==True`, all predicates are evaluated, and an exception is\n",
      "        thrown if more than one of the predicates evaluates to `True`.\n",
      "        If `exclusive==False`, execution stops at the first predicate which\n",
      "        evaluates to True, and the tensors generated by the corresponding function\n",
      "        are returned immediately. If none of the predicates evaluate to True, this\n",
      "        operation returns the tensors generated by `default`.\n",
      "        \n",
      "        `tf.case` supports nested structures as implemented in\n",
      "        `tf.nest`. All of the callables must return the same (possibly nested) value\n",
      "        structure of lists, tuples, and/or named tuples. Singleton lists and tuples\n",
      "        form the only exceptions to this: when returned by a callable, they are\n",
      "        implicitly unpacked to single values. This behavior is disabled by passing\n",
      "        `strict=True`.\n",
      "        \n",
      "        @compatibility(v2)\n",
      "        `pred_fn_pairs` could be a dictionary in v1. However, tf.Tensor and\n",
      "        tf.Variable are no longer hashable in v2, so cannot be used as a key for a\n",
      "        dictionary.  Please use a list or a tuple instead.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        **Example 1:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y) return 17;\n",
      "        else return 23;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        f1 = lambda: tf.constant(17)\n",
      "        f2 = lambda: tf.constant(23)\n",
      "        r = tf.case([(tf.less(x, y), f1)], default=f2)\n",
      "        ```\n",
      "        \n",
      "        **Example 2:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y && x > z) raise OpError(\"Only one predicate may evaluate to True\");\n",
      "        if (x < y) return 17;\n",
      "        else if (x > z) return 23;\n",
      "        else return -1;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(23)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.case([(tf.less(x, y), f1), (tf.greater(x, z), f2)],\n",
      "                 default=f3, exclusive=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          pred_fn_pairs: List of pairs of a boolean scalar tensor and a callable which\n",
      "            returns a list of tensors.\n",
      "          default: Optional callable that returns a list of tensors.\n",
      "          exclusive: True iff at most one predicate is allowed to evaluate to `True`.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the first pair whose predicate evaluated to True, or\n",
      "          those returned by `default` if none does.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `pred_fn_pairs` is not a list/tuple.\n",
      "          TypeError: If `pred_fn_pairs` is a list but does not contain 2-tuples.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    cast(x, dtype, name=None)\n",
      "        Casts a tensor to a new type.\n",
      "        \n",
      "        The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "        (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.dtypes.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        The operation supports data types (for `x` and `dtype`) of\n",
      "        `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
      "        `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
      "        In case of casting from complex types (`complex64`, `complex128`) to real\n",
      "        types, only the real part of `x` is returned. In case of casting from real\n",
      "        types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
      "        returned value is set to `0`. The handling of complex types here matches the\n",
      "        behavior of numpy.\n",
      "        \n",
      "        Note casting nan and inf values to integral types has undefined behavior.\n",
      "        \n",
      "        Note this operation can lead to a loss of precision when converting native\n",
      "        Python `float` and `complex` variables to `tf.float64` or `tf.complex128`\n",
      "        tensors, since the input is first converted to the `float32` data type and\n",
      "        then widened. It is recommended to use `tf.convert_to_tensor` instead of\n",
      "        `tf.cast` for any non-tensor inputs.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
      "            be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
      "            `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
      "            `bfloat16`.\n",
      "          dtype: The destination type. The list of supported dtypes is the same as\n",
      "            `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
      "            same type as `dtype`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `dtype`.\n",
      "    \n",
      "    clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)\n",
      "        Clips values of multiple tensors by the ratio of the sum of their norms.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, and a clipping ratio `clip_norm`,\n",
      "        this operation returns a list of clipped tensors `list_clipped`\n",
      "        and the global norm (`global_norm`) of all tensors in `t_list`. Optionally,\n",
      "        if you've already computed the global norm for `t_list`, you can specify\n",
      "        the global norm with `use_norm`.\n",
      "        \n",
      "        To perform the clipping, the values `t_list[i]` are set to:\n",
      "        \n",
      "            t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
      "        \n",
      "        where:\n",
      "        \n",
      "            global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n",
      "        \n",
      "        If `clip_norm > global_norm` then the entries in `t_list` remain as they are,\n",
      "        otherwise they're all shrunk by the global ratio.\n",
      "        \n",
      "        If `global_norm == infinity` then the entries in `t_list` are all set to `NaN`\n",
      "        to signal that an error occurred.\n",
      "        \n",
      "        Any of the entries of `t_list` that are of type `None` are ignored.\n",
      "        \n",
      "        This is the correct way to perform gradient clipping (Pascanu et al., 2012).\n",
      "        \n",
      "        However, it is slower than `clip_by_norm()` because all the parameters must be\n",
      "        ready before the clipping operation can be performed.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. The clipping ratio.\n",
      "          use_norm: A 0-D (scalar) `Tensor` of type `float` (optional). The global\n",
      "            norm to use. If not provided, `global_norm()` is used to compute the norm.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          list_clipped: A list of `Tensors` of the same type as `list_t`.\n",
      "          global_norm: A 0-D (scalar) `Tensor` representing the global norm.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "        \n",
      "        References:\n",
      "          On the difficulty of training Recurrent Neural Networks:\n",
      "            [Pascanu et al., 2012](http://proceedings.mlr.press/v28/pascanu13.html)\n",
      "            ([pdf](http://proceedings.mlr.press/v28/pascanu13.pdf))\n",
      "    \n",
      "    clip_by_norm(t, clip_norm, axes=None, name=None)\n",
      "        Clips tensor values to a maximum L2-norm.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its L2-norm is less than or equal to `clip_norm`,\n",
      "        along the dimensions given in `axes`. Specifically, in the default case\n",
      "        where all dimensions are used for calculation, if the L2-norm of `t` is\n",
      "        already less than or equal to `clip_norm`, then `t` is not modified. If\n",
      "        the L2-norm is greater than `clip_norm`, then this operation returns a\n",
      "        tensor of the same type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm(t)`\n",
      "        \n",
      "        In this case, the L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        As another example, if `t` is a matrix and `axes == [1]`, then each row\n",
      "        of the output will have L2-norm less than or equal to `clip_norm`. If\n",
      "        `axes == [0]` instead, each column of the output will be clipped.\n",
      "        \n",
      "        Code example:\n",
      "        \n",
      "        >>> some_nums = tf.constant([[1, 2, 3, 4, 5]], dtype=tf.float32)\n",
      "        >>> tf.clip_by_norm(some_nums, 2.0).numpy()\n",
      "        array([[0.26967996, 0.5393599 , 0.80903983, 1.0787199 , 1.3483998 ]],\n",
      "              dtype=float32)\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.  Most gradient data is a collection of different shaped tensors\n",
      "        for different parts of the model.  Thus, this is a common usage:\n",
      "        \n",
      "        ```\n",
      "        # Get your gradients after training\n",
      "        loss_value, grads = grad(model, features, labels)\n",
      "        \n",
      "        # Apply some clipping\n",
      "        grads = [tf.clip_by_norm(g, norm)\n",
      "                     for g in grads]\n",
      "        \n",
      "        # Continue on with training\n",
      "        optimizer.apply_gradients(grads)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.  This must be a floating point type.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value, also\n",
      "            floating point\n",
      "          axes: A 1-D (vector) `Tensor` of type int32 containing the dimensions\n",
      "            to use for computing the L2-norm. If `None` (the default), uses all\n",
      "            dimensions.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the clip_norm tensor is not a 0-D scalar tensor.\n",
      "          TypeError: If dtype of the input is not a floating point or\n",
      "            complex type.\n",
      "    \n",
      "    clip_by_value(t, clip_value_min, clip_value_max, name=None)\n",
      "        Clips tensor values to a specified min and max.\n",
      "        \n",
      "        Given a tensor `t`, this operation returns a tensor of the same type and\n",
      "        shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.\n",
      "        Any values less than `clip_value_min` are set to `clip_value_min`. Any values\n",
      "        greater than `clip_value_max` are set to `clip_value_max`.\n",
      "        \n",
      "        Note: `clip_value_min` needs to be smaller or equal to `clip_value_max` for\n",
      "        correct results.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Basic usage passes a scalar as the min and max value.\n",
      "        \n",
      "        >>> t = tf.constant([[-10., -1., 0.], [0., 2., 10.]])\n",
      "        >>> t2 = tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1)\n",
      "        >>> t2.numpy()\n",
      "        array([[-1., -1.,  0.],\n",
      "               [ 0.,  1.,  1.]], dtype=float32)\n",
      "        \n",
      "        The min and max can be the same size as `t`, or broadcastable to that size.\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[2],[1]]\n",
      "        >>> t3 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        >>> t3.numpy()\n",
      "        array([[ 2.,  2., 10.],\n",
      "               [ 1.,  1., 10.]], dtype=float32)\n",
      "        \n",
      "        Broadcasting fails, intentionally, if you would expand the dimensions of `t`\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[[2, 1]]] # Has a third axis\n",
      "        >>> t4 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Incompatible shapes: [2,3] vs. [1,1,2]\n",
      "        \n",
      "        It throws a `TypeError` if you try to clip an `int` to a `float` value\n",
      "        (`tf.cast` the input to `float` first).\n",
      "        \n",
      "        >>> t = tf.constant([[1, 2], [3, 4]], dtype=tf.int32)\n",
      "        >>> t5 = tf.clip_by_value(t, clip_value_min=-3.1, clip_value_max=3.1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        TypeError: Cannot convert ...\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.\n",
      "          clip_value_min: The minimum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          clip_value_max: The maximum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If the clip tensors would trigger array\n",
      "            broadcasting that would make the returned tensor larger than the input.\n",
      "          TypeError: If dtype of the input is `int32` and dtype of\n",
      "            the `clip_value_min` or `clip_value_max` is `float32`\n",
      "    \n",
      "    complex(real, imag, name=None)\n",
      "        Converts two real numbers to a complex number.\n",
      "        \n",
      "        Given a tensor `real` representing the real part of a complex number, and a\n",
      "        tensor `imag` representing the imaginary part of a complex number, this\n",
      "        operation returns complex numbers elementwise of the form \\\\(a + bj\\\\), where\n",
      "        *a* represents the `real` part and *b* represents the `imag` part.\n",
      "        \n",
      "        The input tensors `real` and `imag` must have the same shape.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        real = tf.constant([2.25, 3.25])\n",
      "        imag = tf.constant([4.75, 5.75])\n",
      "        tf.complex(real, imag)  # [[2.25 + 4.75j], [3.25 + 5.75j]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          real: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          imag: A `Tensor`. Must have the same type as `real`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `complex64` or `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: Real and imag must be correct types\n",
      "    \n",
      "    concat(values, axis, name='concat')\n",
      "        Concatenates tensors along one dimension.\n",
      "        \n",
      "        See also `tf.tile`, `tf.stack`, `tf.repeat`.\n",
      "        \n",
      "        Concatenates the list of tensors `values` along dimension `axis`.  If\n",
      "        `values[i].shape = [D0, D1, ... Daxis(i), ...Dn]`, the concatenated\n",
      "        result has shape\n",
      "        \n",
      "            [D0, D1, ... Raxis, ...Dn]\n",
      "        \n",
      "        where\n",
      "        \n",
      "            Raxis = sum(Daxis(i))\n",
      "        \n",
      "        That is, the data from the input tensors is joined along the `axis`\n",
      "        dimension.\n",
      "        \n",
      "        The number of dimensions of the input tensors must match, and all dimensions\n",
      "        except `axis` must be equal.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3], [4, 5, 6]]\n",
      "        >>> t2 = [[7, 8, 9], [10, 11, 12]]\n",
      "        >>> tf.concat([t1, t2], 0)\n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3],\n",
      "               [ 4,  5,  6],\n",
      "               [ 7,  8,  9],\n",
      "               [10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        >>> tf.concat([t1, t2], 1)\n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3,  7,  8,  9],\n",
      "               [ 4,  5,  6, 10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        As in Python, the `axis` could also be negative numbers. Negative `axis`\n",
      "        are interpreted as counting from the end of the rank, i.e.,\n",
      "         `axis + rank(values)`-th dimension.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\n",
      "        >>> t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\n",
      "        >>> tf.concat([t1, t2], -1)\n",
      "        <tf.Tensor: shape=(2, 2, 4), dtype=int32, numpy=\n",
      "          array([[[ 1,  2,  7,  4],\n",
      "                  [ 2,  3,  8,  4]],\n",
      "                 [[ 4,  4,  2, 10],\n",
      "                  [ 5,  3, 15, 11]]], dtype=int32)>\n",
      "        \n",
      "        Note: If you are concatenating along a new axis consider using stack.\n",
      "        E.g.\n",
      "        \n",
      "        ```python\n",
      "        tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)\n",
      "        ```\n",
      "        \n",
      "        can be rewritten as\n",
      "        \n",
      "        ```python\n",
      "        tf.stack(tensors, axis=axis)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects or a single `Tensor`.\n",
      "          axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n",
      "            in the range `[-rank(values), rank(values))`. As in Python, indexing for\n",
      "            axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n",
      "            to `axis`-th dimension. And negative axis refers to `axis +\n",
      "            rank(values)`-th dimension.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` resulting from concatenation of the input tensors.\n",
      "    \n",
      "    cond = cond_for_tf_v2(pred, true_fn=None, false_fn=None, name=None)\n",
      "        Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\n",
      "        \n",
      "        Note: This op is automatically used in a `tf.function` to convert Python\n",
      "        if-statements when the predicate is a `tf.Tensor`, unless `autograph=False` is\n",
      "        explicitly specified in `tf.function` args. For example, the following are\n",
      "        equivalent:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def fun1(x,y):\n",
      "        ...   if x > 0:  # AutoGraph converts if-statement to tf.cond().\n",
      "        ...     z = y+1\n",
      "        ...   else:\n",
      "        ...     z = y-1\n",
      "        ...   return z\n",
      "        >>> fun1(tf.constant(7), tf.constant(3)).numpy()\n",
      "        4\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def fun2(x,y):\n",
      "        ...   pred = x > 0\n",
      "        ...   true_fn =  lambda: y+1\n",
      "        ...   false_fn = lambda: y-1\n",
      "        ...   return tf.cond(pred, true_fn, false_fn)  # Use tf.cond() explicitly.\n",
      "        >>> fun1(tf.constant(7), tf.constant(3)).numpy()\n",
      "        4\n",
      "        \n",
      "        For more information, see [tf.function and AutoGraph guide](\n",
      "        https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "        \n",
      "        `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\n",
      "        `false_fn` must have the same non-zero number and type of outputs.\n",
      "        \n",
      "        **WARNING**: Any Tensors or Operations created outside of `true_fn` and\n",
      "        `false_fn` will be executed regardless of which branch is selected at runtime.\n",
      "        \n",
      "        Although this behavior is consistent with the dataflow model of TensorFlow,\n",
      "        it has frequently surprised users who expected a lazier semantics.\n",
      "        Consider the following simple program:\n",
      "        \n",
      "        >>> x, y = tf.constant(2, dtype=tf.int32), tf.constant(4, dtype=tf.int32)\n",
      "        >>> z = tf.multiply(x, y)\n",
      "        >>> r = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n",
      "        >>> r.numpy()\n",
      "        10\n",
      "        \n",
      "        If `x < y`, the `tf.add` operation will be executed and `tf.square`\n",
      "        operation will not be executed. Since `z` is needed for at least one\n",
      "        branch of the `cond`, the `tf.multiply` operation is always executed,\n",
      "        unconditionally.\n",
      "        \n",
      "        Note that `cond` calls `true_fn` and `false_fn` *exactly once* (inside the\n",
      "        call to `cond`, and not at all during `Session.run()`). `cond`\n",
      "        stitches together the graph fragments created during the `true_fn` and\n",
      "        `false_fn` calls with some additional graph nodes to ensure that the right\n",
      "        branch gets executed depending on the value of `pred`.\n",
      "        \n",
      "        `tf.cond` supports nested structures as implemented in\n",
      "        `tensorflow.python.util.nest`. Both `true_fn` and `false_fn` must return the\n",
      "        same (possibly nested) value structure of lists, tuples, and/or named tuples.\n",
      "        Singleton lists and tuples form the only exceptions to this: when returned by\n",
      "        `true_fn` and/or `false_fn`, they are implicitly unpacked to single values.\n",
      "        \n",
      "        Note: It is illegal to \"directly\" use tensors created inside a cond branch\n",
      "        outside it, e.g. by storing a reference to a branch tensor in the python\n",
      "        state. If you need to use a tensor created in a branch function you should\n",
      "        return it as an output of the branch function and use the output from\n",
      "        `tf.cond` instead.\n",
      "        \n",
      "        Args:\n",
      "          pred: A scalar determining whether to return the result of `true_fn` or\n",
      "            `false_fn`.\n",
      "          true_fn: The callable to be performed if pred is true.\n",
      "          false_fn: The callable to be performed if pred is false.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          Tensors returned by the call to either `true_fn` or `false_fn`. If the\n",
      "          callables return a singleton list, the element is extracted from the list.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `true_fn` or `false_fn` is not callable.\n",
      "          ValueError: if `true_fn` and `false_fn` do not return the same number of\n",
      "            tensors, or return tensors of different types.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> x = tf.constant(2)\n",
      "        >>> y = tf.constant(5)\n",
      "        >>> def f1(): return tf.multiply(x, 7)\n",
      "        >>> def f2(): return tf.add(y, 3)\n",
      "        >>> r = tf.cond(tf.less(x, y), f1, f2)\n",
      "        >>> # r is set to f1().\n",
      "        >>> # Operations in f2 (e.g., tf.add) are not executed.\n",
      "        >>> r.numpy()\n",
      "        14\n",
      "    \n",
      "    constant(value, dtype=None, shape=None, name='Const')\n",
      "        Creates a constant tensor from a tensor-like object.\n",
      "        \n",
      "        Note: All eager `tf.Tensor` values are immutable (in contrast to\n",
      "        `tf.Variable`). There is nothing especially _constant_ about the value\n",
      "        returned from `tf.constant`. This function is not fundamentally different from\n",
      "        `tf.convert_to_tensor`. The name `tf.constant` comes from the `value` being\n",
      "        embedded in a `Const` node in the `tf.Graph`. `tf.constant` is useful\n",
      "        for asserting that the value can be embedded that way.\n",
      "        \n",
      "        If the argument `dtype` is not specified, then the type is inferred from\n",
      "        the type of `value`.\n",
      "        \n",
      "        >>> # Constant 1-D Tensor from a python list.\n",
      "        >>> tf.constant([1, 2, 3, 4, 5, 6])\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "            numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> # Or a numpy array\n",
      "        >>> a = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "        >>> tf.constant(a)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
      "          array([[1, 2, 3],\n",
      "                 [4, 5, 6]])>\n",
      "        \n",
      "        If `dtype` is specified, the resulting tensor values are cast to the requested\n",
      "        `dtype`.\n",
      "        \n",
      "        >>> tf.constant([1, 2, 3, 4, 5, 6], dtype=tf.float64)\n",
      "        <tf.Tensor: shape=(6,), dtype=float64,\n",
      "            numpy=array([1., 2., 3., 4., 5., 6.])>\n",
      "        \n",
      "        If `shape` is set, the `value` is reshaped to match. Scalars are expanded to\n",
      "        fill the `shape`:\n",
      "        \n",
      "        >>> tf.constant(0, shape=(2, 3))\n",
      "          <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[0, 0, 0],\n",
      "                 [0, 0, 0]], dtype=int32)>\n",
      "        >>> tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[1, 2, 3],\n",
      "                 [4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        `tf.constant` has no effect if an eager Tensor is passed as the `value`, it\n",
      "        even transmits gradients:\n",
      "        \n",
      "        >>> v = tf.Variable([0.0])\n",
      "        >>> with tf.GradientTape() as g:\n",
      "        ...     loss = tf.constant(v + v)\n",
      "        >>> g.gradient(loss, v).numpy()\n",
      "        array([2.], dtype=float32)\n",
      "        \n",
      "        But, since `tf.constant` embeds the value in the `tf.Graph` this fails for\n",
      "        symbolic tensors:\n",
      "        \n",
      "        >>> with tf.compat.v1.Graph().as_default():\n",
      "        ...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
      "        ...   t = tf.constant(i)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        TypeError: ...\n",
      "        \n",
      "        `tf.constant` will create tensors on the current device. Inputs which are\n",
      "        already tensors maintain their placements unchanged.\n",
      "        \n",
      "        Related Ops:\n",
      "        \n",
      "        * `tf.convert_to_tensor` is similar but:\n",
      "          * It has no `shape` argument.\n",
      "          * Symbolic tensors are allowed to pass through.\n",
      "        \n",
      "          >>> with tf.compat.v1.Graph().as_default():\n",
      "          ...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
      "          ...   t = tf.convert_to_tensor(i)\n",
      "        \n",
      "        * `tf.fill`: differs in a few ways:\n",
      "          *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
      "              Tensors like `tf.fill`.\n",
      "          *   `tf.fill` creates an Op in the graph that is expanded at runtime, so it\n",
      "              can efficiently represent large tensors.\n",
      "          *   Since `tf.fill` does not embed the value, it can produce dynamically\n",
      "              sized outputs.\n",
      "        \n",
      "        Args:\n",
      "          value: A constant value (or list) of output type `dtype`.\n",
      "          dtype: The type of the elements of the resulting tensor.\n",
      "          shape: Optional dimensions of resulting tensor.\n",
      "          name: Optional name for the tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A Constant Tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if shape is incorrectly specified or unsupported.\n",
      "          ValueError: if called on a symbolic tensor.\n",
      "    \n",
      "    control_dependencies(control_inputs)\n",
      "        Wrapper for `Graph.control_dependencies()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.control_dependencies` for more details.\n",
      "        \n",
      "        In TensorFlow 2 with eager and/or Autograph, you should not need this method\n",
      "        most of the times, as ops execute in the expected order thanks to automatic\n",
      "        control dependencies. Only use it to manually control ordering, for example as\n",
      "        a workaround to known issues such as `tf.function` with `tf.debugging.assert*`\n",
      "        and `tf.py_function`.\n",
      "        For example:\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_1(x, bias):\n",
      "        ...   # `tf.function` attempts to execute `tf.math.add` in parallel to\n",
      "        ...   # `assert_equal`. As a result an error can get raised from `tf.math.add`\n",
      "        ...   # without triggering the assertion error.\n",
      "        ...   tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                   tf.shape(bias)[1],\n",
      "        ...                   message='bad shape')\n",
      "        ...   return x + bias\n",
      "        \n",
      "        >>> # Error raised in either `add` or `assert`\n",
      "        >>> my_assert_func_1(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_2(x, bias):\n",
      "        ...   with tf.control_dependencies(\n",
      "        ...       [tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                       tf.shape(bias)[1],\n",
      "        ...                       message='bad shape')]):\n",
      "        ...     return x + bias\n",
      "        \n",
      "        >>> # Error raised in `assert`\n",
      "        >>> my_assert_func_2(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        When eager execution is enabled, any callable object in the `control_inputs`\n",
      "        list will be called.\n",
      "        \n",
      "        Args:\n",
      "          control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "            executed or computed before running the operations defined in the context.\n",
      "            Can also be `None` to clear the control dependencies. If eager execution\n",
      "            is enabled, any callable object in the `control_inputs` list will be\n",
      "            called.\n",
      "        \n",
      "        Returns:\n",
      "         A context manager that specifies control dependencies for all\n",
      "         operations constructed within the context.\n",
      "    \n",
      "    conv2d_backprop_filter_v2(input, filter, out_backprop, strides, padding, use_cudnn_on_gpu=True, explicit_paddings=[], data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
      "        Computes the gradients of convolution with respect to the filter.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "          filter: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "        \n",
      "            Only shape of tensor is used.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "        \n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "        \n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "        \n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "        \n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "        \n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "        \n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "        \n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "        \n",
      "                [batch, in_height, in_width, in_channels].\n",
      "        \n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "        \n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "        \n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "        \n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "        \n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "        \n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    conv2d_backprop_input_v2(input, filter, out_backprop, strides, padding, use_cudnn_on_gpu=True, explicit_paddings=[], data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
      "        Computes the gradients of convolution with respect to the input.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "        \n",
      "            Only shape of tensor is used.\n",
      "          filter: A `Tensor`. Must have the same type as `input`. 4-D with shape\n",
      "        \n",
      "            `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "        \n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "        \n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "        \n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "        \n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "        \n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "        \n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "        \n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "        \n",
      "                [batch, in_height, in_width, in_channels].\n",
      "        \n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "        \n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "        \n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "        \n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "        \n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "        \n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    convert_to_tensor = convert_to_tensor_v2_with_dispatch(value, dtype=None, dtype_hint=None, name=None)\n",
      "        Converts the given `value` to a `Tensor`.\n",
      "        \n",
      "        This function converts Python objects of various types to `Tensor`\n",
      "        objects. It accepts `Tensor` objects, numpy arrays, Python lists,\n",
      "        and Python scalars.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> def my_func(arg):\n",
      "        ...   arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
      "        ...   return arg\n",
      "        \n",
      "        >>> # The following calls are equivalent.\n",
      "        ...\n",
      "        >>> value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
      "        >>> print(value_1)\n",
      "        tf.Tensor(\n",
      "          [[1. 2.]\n",
      "           [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "        >>> value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
      "        >>> print(value_2)\n",
      "        tf.Tensor(\n",
      "          [[1. 2.]\n",
      "           [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "        >>> value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
      "        >>> print(value_3)\n",
      "        tf.Tensor(\n",
      "          [[1. 2.]\n",
      "           [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "        \n",
      "        This function can be useful when composing a new operation in Python\n",
      "        (such as `my_func` in the example above). All standard Python op\n",
      "        constructors apply this function to each of their Tensor-valued\n",
      "        inputs, which allows those ops to accept numpy arrays, Python lists,\n",
      "        and scalars in addition to `Tensor` objects.\n",
      "        \n",
      "        Note: This function diverges from default Numpy behavior for `float` and\n",
      "          `string` types when `None` is present in a Python list or scalar. Rather\n",
      "          than silently converting `None` values, an error will be thrown.\n",
      "        \n",
      "        Args:\n",
      "          value: An object whose type has a registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          dtype_hint: Optional element type for the returned tensor, used when dtype\n",
      "            is None. In some cases, a caller may not have a dtype in mind when\n",
      "            converting to a tensor, so dtype_hint can be used as a soft preference. If\n",
      "            the conversion to `dtype_hint` is not possible, this argument has no\n",
      "            effect.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If no conversion function is registered for `value` to `dtype`.\n",
      "          RuntimeError: If a registered conversion function returns an invalid value.\n",
      "          ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\n",
      "    \n",
      "    cos(x, name=None)\n",
      "        Computes cos of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes cosine of every\n",
      "        \n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "        \n",
      "          output range is `[-1,1]`. If input lies outside the boundary, `nan`\n",
      "        \n",
      "          is returned.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        \n",
      "          tf.math.cos(x) ==> [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cosh(x, name=None)\n",
      "        Computes hyperbolic cosine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic cosine of every\n",
      "        \n",
      "          element in the tensor. Input range is `[-inf, inf]` and output range\n",
      "        \n",
      "          is `[1, inf]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "        \n",
      "          tf.math.cosh(x) ==> [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cumsum(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative sum of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumsum, which means that the first\n",
      "        element of the input is identical to the first element of the output:\n",
      "        For example:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c])   # [a, a + b, a + b + c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 2,  6, 12, 20], dtype=int32)>\n",
      "        \n",
      "        >>> # using varying `axis` values\n",
      "        >>> y = tf.constant([[2, 4, 6, 8], [1,3,5,7]])\n",
      "        >>> tf.cumsum(y, axis=0)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  4,  6,  8],\n",
      "               [ 3,  7, 11, 15]], dtype=int32)>\n",
      "        >>> tf.cumsum(y, axis=1)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  6, 12, 20],\n",
      "               [ 1,  4,  9, 16]], dtype=int32)>\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumsum is performed\n",
      "        instead:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True)  => [0, a, a + b]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 0,  2,  6, 12], dtype=int32)>\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumsum is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], reverse=True)  # [a + b + c, b + c, c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([20, 18, 14,  8], dtype=int32)>\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True, reverse=True)  # [b + c, c, 0]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([18, 14,  8,  0], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumsum.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    custom_gradient(f=None)\n",
      "        Decorator to define a function with a custom gradient.\n",
      "        \n",
      "        This decorator allows fine grained control over the gradients of a sequence\n",
      "        for operations.  This may be useful for multiple reasons, including providing\n",
      "        a more efficient or numerically stable gradient for a sequence of operations.\n",
      "        \n",
      "        For example, consider the following function that commonly occurs in the\n",
      "        computation of cross entropy and log likelihoods:\n",
      "        \n",
      "        ```python\n",
      "        def log1pexp(x):\n",
      "          return tf.math.log(1 + tf.exp(x))\n",
      "        ```\n",
      "        \n",
      "        Due to numerical instability, the gradient of this function evaluated at x=100\n",
      "        is NaN.  For example:\n",
      "        \n",
      "        ```python\n",
      "        with tf.GradientTape() as tape:\n",
      "          tape.watch(x)\n",
      "          y=log1pexp(x)\n",
      "        dy_dx = tape.gradient(y, x) # Will be NaN when evaluated.\n",
      "        ```\n",
      "        \n",
      "        The gradient expression can be analytically simplified to provide numerical\n",
      "        stability:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def log1pexp(x):\n",
      "          e = tf.exp(x)\n",
      "          def grad(upstream):\n",
      "            return upstream * (1 - 1 / (1 + e))\n",
      "          return tf.math.log(1 + e), grad\n",
      "        ```\n",
      "        \n",
      "        With this definition, the gradient `dy_dx` at `x = 100` will be correctly\n",
      "        evaluated as 1.0.\n",
      "        \n",
      "        The variable `upstream` is defined as the upstream gradient. i.e. the gradient\n",
      "        from all the layers or functions originating from this layer. The above\n",
      "        example has no upstream functions, therefore `upstream = dy/dy = 1.0`.\n",
      "        \n",
      "        Assume that `x_i` is `log1pexp` in the forward pass `x_1 = x_1(x_0)`,\n",
      "        `x_2 = x_2(x_1)`, ..., `x_i = x_i(x_i-1)`, ..., `x_n = x_n(x_n-1)`. By\n",
      "        chain rule we know that `dx_n/dx_0 = dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... *\n",
      "        dx_i/dx_i-1 * ... * dx_1/dx_0`.\n",
      "        \n",
      "        In this case the gradient of our current function defined as\n",
      "        `dx_i/dx_i-1 = (1 - 1 / (1 + e))`. The upstream gradient `upstream` would be\n",
      "        `dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... * dx_i+1/dx_i`. The upstream gradient\n",
      "        multiplied by the current gradient is then passed downstream.\n",
      "        \n",
      "        In case the function takes multiple variables as input, the `grad`\n",
      "        function must also return  the same number of variables.\n",
      "        We take the function `z = x * y` as an example.\n",
      "        \n",
      "        >>> @tf.custom_gradient\n",
      "        ... def bar(x, y):\n",
      "        ...   def grad(upstream):\n",
      "        ...     dz_dx = y\n",
      "        ...     dz_dy = x\n",
      "        ...     return upstream * dz_dx, upstream * dz_dy\n",
      "        ...   z = x * y\n",
      "        ...   return z, grad\n",
      "        >>> x = tf.constant(2.0, dtype=tf.float32)\n",
      "        >>> y = tf.constant(3.0, dtype=tf.float32)\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   tape.watch(y)\n",
      "        ...   z = bar(x, y)\n",
      "        >>> z\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "        >>> tape.gradient(z, x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.0>\n",
      "        >>> tape.gradient(z, y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=2.0>\n",
      "        \n",
      "        Nesting custom gradients can lead to unintuitive results. The default\n",
      "        behavior does not correspond to n-th order derivatives. For example\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op(x):\n",
      "          y = op1(x)\n",
      "          @tf.custom_gradient\n",
      "          def grad_fn(dy):\n",
      "            gdy = op2(x, y, dy)\n",
      "            def grad_grad_fn(ddy):  # Not the 2nd order gradient of op w.r.t. x.\n",
      "              return op3(x, y, dy, ddy)\n",
      "            return gdy, grad_grad_fn\n",
      "          return y, grad_fn\n",
      "        ```\n",
      "        \n",
      "        The function `grad_grad_fn` will be calculating the first order gradient\n",
      "        of `grad_fn` with respect to `dy`, which is used to generate forward-mode\n",
      "        gradient graphs from backward-mode gradient graphs, but is not the same as\n",
      "        the second order gradient of `op` with respect to `x`.\n",
      "        \n",
      "        Instead, wrap nested `@tf.custom_gradients` in another function:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op_with_fused_backprop(x):\n",
      "          y, x_grad = fused_op(x)\n",
      "          def first_order_gradient(dy):\n",
      "            @tf.custom_gradient\n",
      "            def first_order_custom(unused_x):\n",
      "              def second_order_and_transpose(ddy):\n",
      "                return second_order_for_x(...), gradient_wrt_dy(...)\n",
      "              return x_grad, second_order_and_transpose\n",
      "            return dy * first_order_custom(x)\n",
      "          return y, first_order_gradient\n",
      "        ```\n",
      "        \n",
      "        Additional arguments to the inner `@tf.custom_gradient`-decorated function\n",
      "        control the expected return values of the innermost function.\n",
      "        \n",
      "        The examples above illustrate how to specify custom gradients for functions\n",
      "        which do not read from variables. The following example uses variables, which\n",
      "        require special handling because they are effectively inputs of the forward\n",
      "        function.\n",
      "        \n",
      "        >>> weights = tf.Variable(tf.ones([2]))  # Trainable variable weights\n",
      "        >>> @tf.custom_gradient\n",
      "        ... def linear_poly(x):\n",
      "        ...   # Creating polynomial\n",
      "        ...   poly = weights[1] * x + weights[0]\n",
      "        ...\n",
      "        ...   def grad_fn(dpoly, variables):\n",
      "        ...     # dy/dx = weights[1] and we need to left multiply dpoly\n",
      "        ...     grad_xs = dpoly * weights[1]  # Scalar gradient\n",
      "        ...\n",
      "        ...     grad_vars = []  # To store gradients of passed variables\n",
      "        ...     assert variables is not None\n",
      "        ...     assert len(variables) == 1\n",
      "        ...     assert variables[0] is weights\n",
      "        ...     # Manually computing dy/dweights\n",
      "        ...     dy_dw = dpoly * tf.stack([x ** 1, x ** 0])\n",
      "        ...     grad_vars.append(\n",
      "        ...         tf.reduce_sum(tf.reshape(dy_dw, [2, -1]), axis=1)\n",
      "        ...     )\n",
      "        ...     return grad_xs, grad_vars\n",
      "        ...   return poly, grad_fn\n",
      "        >>> x = tf.constant([1., 2., 3.])\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   poly = linear_poly(x)\n",
      "        >>> poly # poly = x + 1\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([2., 3., 4.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, x)  # conventional scalar gradient dy/dx\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([1., 1., 1.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, weights)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([6., 3.], dtype=float32)>\n",
      "        \n",
      "        Above example illustrates usage of trainable variable `weights`.\n",
      "        In the example, the inner `grad_fn` accepts an extra `variables` input\n",
      "        parameter and also returns an extra `grad_vars` output. That extra argument\n",
      "        is passed if the forward function reads any variables. You need to\n",
      "        compute the gradient w.r.t. each of those `variables` and output it as a list\n",
      "        of `grad_vars`. Note here that default value of `variables` is set to `None`\n",
      "        when no variables are used in the forward function.\n",
      "        \n",
      "        It should be noted `tf.GradientTape` is still watching the forward pass of a\n",
      "        `tf.custom_gradient`, and will use the ops it watches. As a consequence,\n",
      "        calling `tf.function` while the tape is still watching leads\n",
      "        to a gradient graph being built. If an op is used in `tf.function` without\n",
      "        registered gradient, a `LookupError` will be raised.\n",
      "        \n",
      "        Users can insert `tf.stop_gradient` to customize this behavior. This\n",
      "        is demonstrated in the example below. `tf.random.shuffle` does not have a\n",
      "        registered gradient. As a result `tf.stop_gradient` is used to avoid the\n",
      "        `LookupError`.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.3, 0.5], dtype=tf.float32)\n",
      "        \n",
      "        @tf.custom_gradient\n",
      "        def test_func_with_stop_grad(x):\n",
      "          @tf.function\n",
      "          def _inner_func():\n",
      "            # Avoid exception during the forward pass\n",
      "            return tf.stop_gradient(tf.random.shuffle(x))\n",
      "            # return tf.random.shuffle(x)  # This will raise\n",
      "        \n",
      "          res = _inner_func()\n",
      "          def grad(upstream):\n",
      "            return upstream  # Arbitrarily defined custom gradient\n",
      "          return res, grad\n",
      "        \n",
      "        with tf.GradientTape() as g:\n",
      "          g.watch(x)\n",
      "          res = test_func_with_stop_grad(x)\n",
      "        \n",
      "        g.gradient(res, x)\n",
      "        ```\n",
      "        \n",
      "        See also `tf.RegisterGradient` which registers a gradient function for a\n",
      "        primitive TensorFlow operation. `tf.custom_gradient` on the other hand allows\n",
      "        for fine grained control over the gradient computation of a sequence of\n",
      "        operations.\n",
      "        \n",
      "        Note that if the decorated function uses `Variable`s, the enclosing variable\n",
      "        scope must be using\n",
      "        [ResourceVariables](https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables).\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a tuple `(y, grad_fn)` where:\n",
      "             - `x` is a sequence of (nested structures of) `Tensor` inputs to the\n",
      "               function.\n",
      "             - `y` is a (nested structure of) `Tensor` outputs of applying TensorFlow\n",
      "               operations in `f` to `x`.\n",
      "             - `grad_fn` is a function with the signature `g(*grad_ys)` which returns\n",
      "               a list of `Tensor`s the same size as (flattened) `x` - the derivatives\n",
      "               of `Tensor`s in `y` with respect to the `Tensor`s in `x`.  `grad_ys` is\n",
      "               a sequence of `Tensor`s the same size as (flattened) `y` holding the\n",
      "               initial value gradients for each `Tensor` in `y`.\n",
      "        \n",
      "               In a pure mathematical sense, a vector-argument vector-valued function\n",
      "               `f`'s derivatives should be its Jacobian matrix `J`. Here we are\n",
      "               expressing the Jacobian `J` as a function `grad_fn` which defines how\n",
      "               `J` will transform a vector `grad_ys` when left-multiplied with it\n",
      "               (`grad_ys * J`, the vector-Jacobian product, or VJP). This functional\n",
      "               representation of a matrix is convenient to use for chain-rule\n",
      "               calculation (in e.g. the back-propagation algorithm).\n",
      "        \n",
      "               If `f` uses `Variable`s (that are not part of the\n",
      "               inputs), i.e. through `get_variable`, then `grad_fn` should have\n",
      "               signature `g(*grad_ys, variables=None)`, where `variables` is a list of\n",
      "               the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where\n",
      "               `grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>`\n",
      "               with the derivatives of `Tensor`s in `y` with respect to the variables\n",
      "               (that is, grad_vars has one Tensor per variable in variables).\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same value as `f(x)[0]` and whose\n",
      "          gradient (as calculated by `tf.gradients`) is determined by `f(x)[1]`.\n",
      "    \n",
      "    device = device_v2(device_name)\n",
      "        Specifies the device for ops created/executed in this context.\n",
      "        \n",
      "        This function specifies the device to be used for ops created/executed in a\n",
      "        particular context. Nested contexts will inherit and also create/execute\n",
      "        their ops on the specified device. If a specific device is not required,\n",
      "        consider not using this function so that a device can be automatically\n",
      "        assigned.  In general the use of this function is optional. `device_name` can\n",
      "        be fully specified, as in \"/job:worker/task:1/device:cpu:0\", or partially\n",
      "        specified, containing only a subset of the \"/\"-separated fields. Any fields\n",
      "        which are specified will override device annotations from outer scopes.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        with tf.device('/job:foo'):\n",
      "          # ops created here have devices with /job:foo\n",
      "          with tf.device('/job:bar/task:0/device:gpu:2'):\n",
      "            # ops created here have the fully specified device above\n",
      "          with tf.device('/device:gpu:1'):\n",
      "            # ops created here have the device '/job:foo/device:gpu:1'\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          device_name: The device name to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default device to use for newly\n",
      "          created ops.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If a function is passed in.\n",
      "    \n",
      "    divide(x, y, name=None)\n",
      "        Computes Python style division of `x` by `y`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([16, 12, 11])\n",
      "        >>> y = tf.constant([4, 6, 2])\n",
      "        >>> tf.divide(x,y)\n",
      "        <tf.Tensor: shape=(3,), dtype=float64,\n",
      "        numpy=array([4. , 2. , 5.5])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`\n",
      "          y: A `Tensor`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with same shape as input\n",
      "    \n",
      "    dynamic_partition(data, partitions, num_partitions, name=None)\n",
      "        Partitions `data` into `num_partitions` tensors using indices from `partitions`.\n",
      "        \n",
      "        For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`\n",
      "        \n",
      "        becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`\n",
      "        \n",
      "        are placed in `outputs[i]` in lexicographic order of `js`, and the first\n",
      "        \n",
      "        dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.\n",
      "        \n",
      "        In detail,\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]\n",
      "        \n",
      "        \n",
      "        \n",
      "            outputs[i] = pack([data[js, ...] for js if partitions[js] == i])\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        `data.shape` must start with `partitions.shape`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            # Scalar partitions.\n",
      "        \n",
      "            partitions = 1\n",
      "        \n",
      "            num_partitions = 2\n",
      "        \n",
      "            data = [10, 20]\n",
      "        \n",
      "            outputs[0] = []  # Empty with shape [0, 2]\n",
      "        \n",
      "            outputs[1] = [[10, 20]]\n",
      "        \n",
      "        \n",
      "        \n",
      "            # Vector partitions.\n",
      "        \n",
      "            partitions = [0, 0, 1, 1, 0]\n",
      "        \n",
      "            num_partitions = 2\n",
      "        \n",
      "            data = [10, 20, 30, 40, 50]\n",
      "        \n",
      "            outputs[0] = [10, 20, 50]\n",
      "        \n",
      "            outputs[1] = [30, 40]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        See `dynamic_stitch` for an example on how to merge partitions back.\n",
      "        \n",
      "        \n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        \n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicPartition.png\" alt>\n",
      "        \n",
      "        </div>\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "          * `InvalidArgumentError` in following cases:\n",
      "        \n",
      "            - If partitions is not in range `[0, num_partiions)`\n",
      "        \n",
      "            - If `partitions.shape` does not match prefix of `data.shape` argument.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`.\n",
      "          partitions: A `Tensor` of type `int32`.\n",
      "            Any shape.  Indices in the range `[0, num_partitions)`.\n",
      "          num_partitions: An `int` that is `>= 1`.\n",
      "            The number of partitions to output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `num_partitions` `Tensor` objects with the same type as `data`.\n",
      "    \n",
      "    dynamic_stitch(indices, data, name=None)\n",
      "        Interleave the values from the `data` tensors into a single tensor.\n",
      "        \n",
      "        Builds a merged tensor such that\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example, if each `indices[m]` is scalar or vector, we have\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            # Scalar indices:\n",
      "        \n",
      "            merged[indices[m], ...] = data[m][...]\n",
      "        \n",
      "        \n",
      "        \n",
      "            # Vector indices:\n",
      "        \n",
      "            merged[indices[m][i], ...] = data[m][i, ...]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        Each `data[i].shape` must start with the corresponding `indices[i].shape`,\n",
      "        \n",
      "        and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we\n",
      "        \n",
      "        must have `data[i].shape = indices[i].shape + constant`.  In terms of this\n",
      "        \n",
      "        `constant`, the output shape is\n",
      "        \n",
      "        \n",
      "        \n",
      "            merged.shape = [max(indices)] + constant\n",
      "        \n",
      "        \n",
      "        \n",
      "        Values are merged in order, so if an index appears in both `indices[m][i]` and\n",
      "        \n",
      "        `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the\n",
      "        \n",
      "        merged result. If you do not need this guarantee, ParallelDynamicStitch might\n",
      "        \n",
      "        perform better on some devices.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            indices[0] = 6\n",
      "        \n",
      "            indices[1] = [4, 1]\n",
      "        \n",
      "            indices[2] = [[5, 2], [0, 3]]\n",
      "        \n",
      "            data[0] = [61, 62]\n",
      "        \n",
      "            data[1] = [[41, 42], [11, 12]]\n",
      "        \n",
      "            data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]\n",
      "        \n",
      "            merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],\n",
      "        \n",
      "                      [51, 52], [61, 62]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        This method can be used to merge partitions created by `dynamic_partition`\n",
      "        \n",
      "        as illustrated on the following example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            # Apply function (increments x_i) on elements for which a certain condition\n",
      "        \n",
      "            # apply (x_i != -1 in this example).\n",
      "        \n",
      "            x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])\n",
      "        \n",
      "            condition_mask=tf.not_equal(x,tf.constant(-1.))\n",
      "        \n",
      "            partitioned_data = tf.dynamic_partition(\n",
      "        \n",
      "                x, tf.cast(condition_mask, tf.int32) , 2)\n",
      "        \n",
      "            partitioned_data[1] = partitioned_data[1] + 1.0\n",
      "        \n",
      "            condition_indices = tf.dynamic_partition(\n",
      "        \n",
      "                tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)\n",
      "        \n",
      "            x = tf.dynamic_stitch(condition_indices, partitioned_data)\n",
      "        \n",
      "            # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain\n",
      "        \n",
      "            # unchanged.\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        \n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicStitch.png\" alt>\n",
      "        \n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          indices: A list of at least 1 `Tensor` objects with type `int32`.\n",
      "          data: A list with the same length as `indices` of `Tensor` objects with the same type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    edit_distance(hypothesis, truth, normalize=True, name='edit_distance')\n",
      "        Computes the Levenshtein distance between sequences.\n",
      "        \n",
      "        This operation takes variable-length sequences (`hypothesis` and `truth`),\n",
      "        each provided as a `SparseTensor`, and computes the Levenshtein distance.\n",
      "        You can normalize the edit distance by length of `truth` by setting\n",
      "        `normalize` to true.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Given the following input,\n",
      "        * `hypothesis` is a `tf.SparseTensor` of shape `[2, 1, 1]`\n",
      "        * `truth` is a `tf.SparseTensor` of shape `[2, 2, 2]`\n",
      "        \n",
      "        >>> hypothesis = tf.SparseTensor(\n",
      "        ...   [[0, 0, 0],\n",
      "        ...    [1, 0, 0]],\n",
      "        ...   [\"a\", \"b\"],\n",
      "        ...   (2, 1, 1))\n",
      "        >>> truth = tf.SparseTensor(\n",
      "        ...   [[0, 1, 0],\n",
      "        ...    [1, 0, 0],\n",
      "        ...    [1, 0, 1],\n",
      "        ...    [1, 1, 0]],\n",
      "        ...    [\"a\", \"b\", \"c\", \"a\"],\n",
      "        ...    (2, 2, 2))\n",
      "        >>> tf.edit_distance(hypothesis, truth, normalize=True)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[inf, 1. ],\n",
      "               [0.5, 1. ]], dtype=float32)>\n",
      "        \n",
      "        The operation returns a dense Tensor of shape `[2, 2]` with\n",
      "        edit distances normalized by `truth` lengths.\n",
      "        \n",
      "        **Note**: It is possible to calculate edit distance between two\n",
      "        sparse tensors with variable-length values. However, attempting to create\n",
      "        them while eager execution is enabled will result in a `ValueError`.\n",
      "        \n",
      "        For the following  inputs,\n",
      "        \n",
      "        ```python\n",
      "        # 'hypothesis' is a tensor of shape `[2, 1]` with variable-length values:\n",
      "        #   (0,0) = [\"a\"]\n",
      "        #   (1,0) = [\"b\"]\n",
      "        hypothesis = tf.sparse.SparseTensor(\n",
      "            [[0, 0, 0],\n",
      "             [1, 0, 0]],\n",
      "            [\"a\", \"b\"],\n",
      "            (2, 1, 1))\n",
      "        \n",
      "        # 'truth' is a tensor of shape `[2, 2]` with variable-length values:\n",
      "        #   (0,0) = []\n",
      "        #   (0,1) = [\"a\"]\n",
      "        #   (1,0) = [\"b\", \"c\"]\n",
      "        #   (1,1) = [\"a\"]\n",
      "        truth = tf.sparse.SparseTensor(\n",
      "            [[0, 1, 0],\n",
      "             [1, 0, 0],\n",
      "             [1, 0, 1],\n",
      "             [1, 1, 0]],\n",
      "            [\"a\", \"b\", \"c\", \"a\"],\n",
      "            (2, 2, 2))\n",
      "        \n",
      "        normalize = True\n",
      "        \n",
      "        # The output would be a dense Tensor of shape `(2,)`, with edit distances\n",
      "        normalized by 'truth' lengths.\n",
      "        # output => array([0., 0.5], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          hypothesis: A `SparseTensor` containing hypothesis sequences.\n",
      "          truth: A `SparseTensor` containing truth sequences.\n",
      "          normalize: A `bool`. If `True`, normalizes the Levenshtein distance by\n",
      "            length of `truth.`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense `Tensor` with rank `R - 1`, where R is the rank of the\n",
      "          `SparseTensor` inputs `hypothesis` and `truth`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If either `hypothesis` or `truth` are not a `SparseTensor`.\n",
      "    \n",
      "    eig(tensor, name=None)\n",
      "        Computes the eigen decomposition of a batch of matrices.\n",
      "        \n",
      "        The eigenvalues\n",
      "        and eigenvectors for a non-Hermitian matrix in general are complex. The\n",
      "        eigenvectors are not guaranteed to be linearly independent.\n",
      "        \n",
      "        Computes the eigenvalues and right eigenvectors of the innermost\n",
      "        N-by-N matrices in `tensor` such that\n",
      "        `tensor[...,:,:] * v[..., :,i] = e[..., i] * v[...,:,i]`, for i=0...N-1.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`. Only the lower triangular part of\n",
      "            each inner inner matrix is referenced.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. The eigenvalues are not necessarily\n",
      "             ordered.\n",
      "          v: Eigenvectors. Shape is `[..., N, N]`. The columns of the inner most\n",
      "            matrices contain eigenvectors of the corresponding matrices in `tensor`\n",
      "    \n",
      "    eigvals(tensor, name=None)\n",
      "        Computes the eigenvalues of one or more matrices.\n",
      "        \n",
      "        Note: If your program backpropagates through this function, you should replace\n",
      "        it with a call to tf.linalg.eig (possibly ignoring the second output) to\n",
      "        avoid computing the eigen decomposition twice. This is because the\n",
      "        eigenvectors are used to compute the gradient w.r.t. the eigenvalues. See\n",
      "        _SelfAdjointEigV2Grad in linalg_grad.py.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. The vector `e[..., :]` contains the `N`\n",
      "            eigenvalues of `tensor[..., :, :]`.\n",
      "    \n",
      "    einsum(equation, *inputs, **kwargs)\n",
      "        Tensor contraction over specified indices and outer product.\n",
      "        \n",
      "        Einsum allows defining Tensors by defining their element-wise computation.\n",
      "        This computation is defined by `equation`, a shorthand form based on Einstein\n",
      "        summation. As an example, consider multiplying two matrices A and B to form a\n",
      "        matrix C.  The elements of C are given by:\n",
      "        \n",
      "        $$ C_{i,k} = \\sum_j A_{i,j} B_{j,k} $$\n",
      "        \n",
      "        or\n",
      "        \n",
      "        ```\n",
      "        C[i,k] = sum_j A[i,j] * B[j,k]\n",
      "        ```\n",
      "        \n",
      "        The corresponding einsum `equation` is:\n",
      "        \n",
      "        ```\n",
      "        ij,jk->ik\n",
      "        ```\n",
      "        \n",
      "        In general, to convert the element-wise equation into the `equation` string,\n",
      "        use the following procedure (intermediate strings for matrix multiplication\n",
      "        example provided in parentheses):\n",
      "        \n",
      "        1. remove variable names, brackets, and commas, (`ik = sum_j ij * jk`)\n",
      "        2. replace \"*\" with \",\", (`ik = sum_j ij , jk`)\n",
      "        3. drop summation signs, and (`ik = ij, jk`)\n",
      "        4. move the output to the right, while replacing \"=\" with \"->\". (`ij,jk->ik`)\n",
      "        \n",
      "        Note: If the output indices are not specified repeated indices are summed.\n",
      "        So `ij,jk->ik` can be simplified to `ij,jk`.\n",
      "        \n",
      "        Many common operations can be expressed in this way.  For example:\n",
      "        \n",
      "        **Matrix multiplication**\n",
      "        \n",
      "        >>> m0 = tf.random.normal(shape=[2, 3])\n",
      "        >>> m1 = tf.random.normal(shape=[3, 5])\n",
      "        >>> e = tf.einsum('ij,jk->ik', m0, m1)\n",
      "        >>> # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        Repeated indices are summed if the output indices are not specified.\n",
      "        \n",
      "        >>> e = tf.einsum('ij,jk', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        \n",
      "        **Dot product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[5])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
      "        >>> print(e.shape)\n",
      "        ()\n",
      "        \n",
      "        **Outer product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[3])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 5)\n",
      "        \n",
      "        **Transpose**\n",
      "        \n",
      "        >>> m = tf.ones(2,3)\n",
      "        >>> e = tf.einsum('ij->ji', m0)  # output[j,i] = m0[i,j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 2)\n",
      "        \n",
      "        **Diag**\n",
      "        \n",
      "        >>> m = tf.reshape(tf.range(9), [3,3])\n",
      "        >>> diag = tf.einsum('ii->i', m)\n",
      "        >>> print(diag.shape)\n",
      "        (3,)\n",
      "        \n",
      "        **Trace**\n",
      "        \n",
      "        >>> # Repeated indices are summed.\n",
      "        >>> trace = tf.einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
      "        >>> assert trace == sum(diag)\n",
      "        >>> print(trace.shape)\n",
      "        ()\n",
      "        \n",
      "        **Batch matrix multiplication**\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[7,5,3])\n",
      "        >>> t = tf.random.normal(shape=[7,3,2])\n",
      "        >>> e = tf.einsum('bij,bjk->bik', s, t)\n",
      "        >>> # output[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
      "        >>> print(e.shape)\n",
      "        (7, 5, 2)\n",
      "        \n",
      "        This method does not support broadcasting on named-axes. All axes with\n",
      "        matching labels should have the same length. If you have length-1 axes,\n",
      "        use `tf.squeeze` or `tf.reshape` to eliminate them.\n",
      "        \n",
      "        To write code that is agnostic to the number of indices in the input\n",
      "        use an ellipsis. The ellipsis is a placeholder for \"whatever other indices\n",
      "        fit here\".\n",
      "        \n",
      "        For example, to perform a NumPy-style broadcasting-batch-matrix multiplication\n",
      "        where the matrix multiply acts on the last two axes of the input, use:\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 7, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[11, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Einsum **will** broadcast over axes covered by the ellipsis.\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 1, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[1, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Args:\n",
      "          equation: a `str` describing the contraction, in the same format as\n",
      "            `numpy.einsum`.\n",
      "          *inputs: the inputs to contract (each one a `Tensor`), whose shapes should\n",
      "            be consistent with `equation`.\n",
      "          **kwargs:\n",
      "            - optimize: Optimization strategy to use to find contraction path using\n",
      "              opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or\n",
      "                'auto'. (optional, default: 'greedy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The contracted `Tensor`, with shape determined by `equation`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If\n",
      "            - the format of `equation` is incorrect,\n",
      "            - number of inputs or their shapes are inconsistent with `equation`.\n",
      "    \n",
      "    ensure_shape(x, shape, name=None)\n",
      "        Updates the shape of a tensor and checks at runtime that the shape holds.\n",
      "        \n",
      "        When executed, this operation asserts that the input tensor `x`'s shape\n",
      "        is compatible with the `shape` argument.\n",
      "        See `tf.TensorShape.is_compatible_with` for details.\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3],\n",
      "        ...                  [4, 5, 6]])\n",
      "        >>> x = tf.ensure_shape(x, [2, 3])\n",
      "        \n",
      "        Use `None` for unknown dimensions:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [None, 3])\n",
      "        >>> x = tf.ensure_shape(x, [2, None])\n",
      "        \n",
      "        If the tensor's shape is not compatible with the `shape` argument, an error\n",
      "        is raised:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [5])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError: Shape of tensor dummy_input [3] is not\n",
      "          compatible with expected shape [5]. [Op:EnsureShape]\n",
      "        \n",
      "        During graph construction (typically tracing a `tf.function`),\n",
      "        `tf.ensure_shape` updates the static-shape of the **result** tensor by\n",
      "        merging the two shapes. See `tf.TensorShape.merge_with` for details.\n",
      "        \n",
      "        This is most useful when **you** know a shape that can't be determined\n",
      "        statically by TensorFlow.\n",
      "        \n",
      "        The following trivial `tf.function` prints the input tensor's\n",
      "        static-shape before and after `ensure_shape` is applied.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(tensor):\n",
      "        ...   print(\"Static-shape before:\", tensor.shape)\n",
      "        ...   tensor = tf.ensure_shape(tensor, [None, 3])\n",
      "        ...   print(\"Static-shape after:\", tensor.shape)\n",
      "        ...   return tensor\n",
      "        \n",
      "        This lets you see the effect of `tf.ensure_shape` when the function is traced:\n",
      "        >>> cf = f.get_concrete_function(tf.TensorSpec([None, None]))\n",
      "        Static-shape before: (None, None)\n",
      "        Static-shape after: (None, 3)\n",
      "        \n",
      "        >>> cf(tf.zeros([3, 3])) # Passes\n",
      "        >>> cf(tf.constant([1, 2, 3])) # fails\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError:  Shape of tensor x [3] is not compatible with expected shape [3,3].\n",
      "        \n",
      "        The above example raises `tf.errors.InvalidArgumentError`, because `x`'s\n",
      "        shape, `(3,)`, is not compatible with the `shape` argument, `(None, 3)`\n",
      "        \n",
      "        Inside a `tf.function` or `v1.Graph` context it checks both the buildtime and\n",
      "        runtime shapes. This is stricter than `tf.Tensor.set_shape` which only\n",
      "        checks the buildtime shape.\n",
      "        \n",
      "        Note: This differs from `tf.Tensor.set_shape` in that it sets the static shape\n",
      "        of the resulting tensor and enforces it at runtime, raising an error if the\n",
      "        tensor's runtime shape is incompatible with the specified shape.\n",
      "        `tf.Tensor.set_shape` sets the static shape of the tensor without enforcing it\n",
      "        at runtime, which may result in inconsistencies between the statically-known\n",
      "        shape of tensors and the runtime value of tensors.\n",
      "        \n",
      "        For example, of loading images of a known size:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   image = tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        When tracing a function, no ops are being executed, shapes may be unknown.\n",
      "        See the [Concrete Functions Guide](https://www.tensorflow.org/guide/concrete_function)\n",
      "        for details.\n",
      "        \n",
      "        >>> concrete_decode = decode_image.get_concrete_function(\n",
      "        ...     tf.TensorSpec([], dtype=tf.string))\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.random.uniform(maxval=255, shape=[28, 28, 3], dtype=tf.int32)\n",
      "        >>> image = tf.cast(image,tf.uint8)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        >>> print(image2.shape)\n",
      "        (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.concat([image,image], axis=0)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError:  Shape of tensor DecodePng [56,28,3] is not\n",
      "          compatible with expected shape [28,28,3].\n",
      "        \n",
      "        Caution: if you don't use the result of `tf.ensure_shape` the check may not\n",
      "        run.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad_decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   # BAD: forgot to use the returned tensor.\n",
      "        ...   tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        >>> image = bad_decode_image(png)\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (None, None, 3)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`.\n",
      "          shape: A `TensorShape` representing the shape of this tensor, a\n",
      "            `TensorShapeProto`, a list, a tuple, or None.\n",
      "          name: A name for this operation (optional). Defaults to \"EnsureShape\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If `shape` is incompatible with the shape\n",
      "          of `x`.\n",
      "    \n",
      "    equal(x, y, name=None)\n",
      "        Returns the truth value of (x == y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise equality comparison, returning a Tensor of\n",
      "        boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  False])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    executing_eagerly()\n",
      "        Checks whether the current thread has eager execution enabled.\n",
      "        \n",
      "        Eager execution is enabled by default and this API returns `True`\n",
      "        in most of cases. However, this API might return `False` in the following use\n",
      "        cases.\n",
      "        \n",
      "        *  Executing inside `tf.function`, unless under `tf.init_scope` or\n",
      "           `tf.config.run_functions_eagerly(True)` is previously called.\n",
      "        *  Executing inside a transformation function for `tf.dataset`.\n",
      "        *  `tf.compat.v1.disable_eager_execution()` is called.\n",
      "        \n",
      "        General case:\n",
      "        \n",
      "        >>> print(tf.executing_eagerly())\n",
      "        True\n",
      "        \n",
      "        Inside `tf.function`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        False\n",
      "        \n",
      "        Inside `tf.function` after `tf.config.run_functions_eagerly(True)` is called:\n",
      "        \n",
      "        >>> tf.config.run_functions_eagerly(True)\n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        True\n",
      "        >>> tf.config.run_functions_eagerly(False)\n",
      "        \n",
      "        Inside a transformation function for `tf.dataset`:\n",
      "        \n",
      "        >>> def data_fn(x):\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        ...   return x\n",
      "        >>> dataset = tf.data.Dataset.range(100)\n",
      "        >>> dataset = dataset.map(data_fn)\n",
      "        False\n",
      "        \n",
      "        Returns:\n",
      "          `True` if the current thread has eager execution enabled.\n",
      "    \n",
      "    exp(x, name=None)\n",
      "        Computes exponential of x element-wise.  \\\\(y = e^x\\\\).\n",
      "        \n",
      "        This function computes the exponential of the input tensor element-wise.\n",
      "        i.e. `math.exp(x)` or \\\\(e^x\\\\), where `x` is the input tensor.\n",
      "        \\\\(e\\\\) denotes Euler's number and is approximately equal to 2.718281.\n",
      "        Output is positive for any real input.\n",
      "        \n",
      "        >>> x = tf.constant(2.0)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=7.389056>\n",
      "        \n",
      "        >>> x = tf.constant([2.0, 8.0])\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([   7.389056, 2980.958   ], dtype=float32)>\n",
      "        \n",
      "        For complex numbers, the exponential value is calculated as\n",
      "        $$\n",
      "        e^{x+iy} = {e^x} {e^{iy}} = {e^x} ({\\cos (y) + i \\sin (y)})\n",
      "        $$\n",
      "        \n",
      "        For `1+1j` the value would be computed as:\n",
      "        $$\n",
      "        e^1 (\\cos (1) + i \\sin (1)) = 2.7182817 \\times (0.5403023+0.84147096j)\n",
      "        $$\n",
      "        \n",
      "        >>> x = tf.constant(1 + 1j)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=complex128,\n",
      "        numpy=(1.4686939399158851+2.2873552871788423j)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.exp\n",
      "        @end_compatibility\n",
      "    \n",
      "    expand_dims = expand_dims_v2(input, axis, name=None)\n",
      "        Returns a tensor with a length 1 axis inserted at index `axis`.\n",
      "        \n",
      "        Given a tensor `input`, this operation inserts a dimension of length 1 at the\n",
      "        dimension index `axis` of `input`'s shape. The dimension index follows Python\n",
      "        indexing rules: It's zero-based, a negative index it is counted backward\n",
      "        from the end.\n",
      "        \n",
      "        This operation is useful to:\n",
      "        \n",
      "        * Add an outer \"batch\" dimension to a single element.\n",
      "        * Align axes for broadcasting.\n",
      "        * To add an inner vector length axis to a tensor of scalars.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        If you have a single image of shape `[height, width, channels]`:\n",
      "        \n",
      "        >>> image = tf.zeros([10,10,3])\n",
      "        \n",
      "        You can add an outer `batch` axis by passing `axis=0`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=0).shape.as_list()\n",
      "        [1, 10, 10, 3]\n",
      "        \n",
      "        The new axis location matches Python `list.insert(axis, 1)`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=1).shape.as_list()\n",
      "        [10, 1, 10, 3]\n",
      "        \n",
      "        Following standard Python indexing rules, a negative `axis` counts from the\n",
      "        end so `axis=-1` adds an inner most dimension:\n",
      "        \n",
      "        >>> tf.expand_dims(image, -1).shape.as_list()\n",
      "        [10, 10, 3, 1]\n",
      "        \n",
      "        This operation requires that `axis` is a valid index for `input.shape`,\n",
      "        following Python indexing rules:\n",
      "        \n",
      "        ```\n",
      "        -1-tf.rank(input) <= axis <= tf.rank(input)\n",
      "        ```\n",
      "        \n",
      "        This operation is related to:\n",
      "        \n",
      "        * `tf.squeeze`, which removes dimensions of size 1.\n",
      "        * `tf.reshape`, which provides more flexible reshaping capability.\n",
      "        * `tf.sparse.expand_dims`, which provides this functionality for\n",
      "          `tf.SparseTensor`\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          axis: Integer specifying the dimension index at which to expand the\n",
      "            shape of `input`. Given an input of D dimensions, `axis` must be in range\n",
      "            `[-(D+1), D]` (inclusive).\n",
      "          name: Optional string. The name of the output `Tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor with the same data as `input`, with an additional dimension\n",
      "          inserted at the index specified by `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `axis` is not specified.\n",
      "          InvalidArgumentError: If `axis` is out of range `[-(D+1), D]`.\n",
      "    \n",
      "    extract_volume_patches(input, ksizes, strides, padding, name=None)\n",
      "        Extract `patches` from `input` and put them in the `\"depth\"` output dimension. 3D extension of `extract_image_patches`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 5`.\n",
      "            The size of the sliding window for each dimension of `input`.\n",
      "          strides: A list of `ints` that has length `>= 5`.\n",
      "            1-D of length 5. How far the centers of two consecutive patches are in\n",
      "        \n",
      "            `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "        \n",
      "            \n",
      "        \n",
      "            The size-related attributes are specified as follows:\n",
      "        \n",
      "            \n",
      "        \n",
      "            ```python\n",
      "        \n",
      "            ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]\n",
      "        \n",
      "            strides = [1, stride_planes, strides_rows, strides_cols, 1]\n",
      "        \n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    eye(num_rows, num_columns=None, batch_shape=None, dtype=tf.float32, name=None)\n",
      "        Construct an identity matrix, or a batch of matrices.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.fill`, `tf.one_hot`.\n",
      "        \n",
      "        ```python\n",
      "        # Construct one identity matrix.\n",
      "        tf.eye(2)\n",
      "        ==> [[1., 0.],\n",
      "             [0., 1.]]\n",
      "        \n",
      "        # Construct a batch of 3 identity matrices, each 2 x 2.\n",
      "        # batch_identity[i, :, :] is a 2 x 2 identity matrix, i = 0, 1, 2.\n",
      "        batch_identity = tf.eye(2, batch_shape=[3])\n",
      "        \n",
      "        # Construct one 2 x 3 \"identity\" matrix\n",
      "        tf.eye(2, num_columns=3)\n",
      "        ==> [[ 1.,  0.,  0.],\n",
      "             [ 0.,  1.,  0.]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          num_rows: Non-negative `int32` scalar `Tensor` giving the number of rows\n",
      "            in each batch matrix.\n",
      "          num_columns: Optional non-negative `int32` scalar `Tensor` giving the number\n",
      "            of columns in each batch matrix.  Defaults to `num_rows`.\n",
      "          batch_shape:  A list or tuple of Python integers or a 1-D `int32` `Tensor`.\n",
      "            If provided, the returned `Tensor` will have leading batch dimensions of\n",
      "            this shape.\n",
      "          dtype:  The type of an element in the resulting `Tensor`\n",
      "          name:  A name for this `Op`.  Defaults to \"eye\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of shape `batch_shape + [num_rows, num_columns]`\n",
      "    \n",
      "    fill(dims, value, name=None)\n",
      "        Creates a tensor filled with a scalar value.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\n",
      "        \n",
      "        This operation creates a tensor of shape `dims` and fills it with `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.fill([2, 3], 9)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[9, 9, 9],\n",
      "               [9, 9, 9]], dtype=int32)>\n",
      "        \n",
      "        `tf.fill` evaluates at graph runtime and supports dynamic shapes based on\n",
      "        other runtime `tf.Tensors`, unlike `tf.constant(value, shape=dims)`, which\n",
      "        embeds the value as a `Const` node.\n",
      "        \n",
      "        Args:\n",
      "          dims: A 1-D sequence of non-negative numbers. Represents the shape of the\n",
      "            output `tf.Tensor`. Entries should be of type: `int32`, `int64`.\n",
      "          value: A value to fill the returned `tf.Tensor`.\n",
      "          name: Optional string. The name of the output `tf.Tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` with shape `dims` and the same dtype as `value`.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: `dims` contains negative entries.\n",
      "          NotFoundError: `dims` contains non-integer entries.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `np.full`. In `numpy`, more parameters are supported. Passing a\n",
      "        number argument as the shape (`np.full(5, value)`) is valid in `numpy` for\n",
      "        specifying a 1-D shaped result, while TensorFlow does not support this syntax.\n",
      "        @end_compatibility\n",
      "    \n",
      "    fingerprint(data, method='farmhash64', name=None)\n",
      "        Generates fingerprint values.\n",
      "        \n",
      "        Generates fingerprint values of `data`.\n",
      "        \n",
      "        Fingerprint op considers the first dimension of `data` as the batch dimension,\n",
      "        and `output[i]` contains the fingerprint value generated from contents in\n",
      "        `data[i, ...]` for all `i`.\n",
      "        \n",
      "        Fingerprint op writes fingerprint values as byte arrays. For example, the\n",
      "        default method `farmhash64` generates a 64-bit fingerprint value at a time.\n",
      "        This 8-byte value is written out as an `tf.uint8` array of size 8, in\n",
      "        little-endian order.\n",
      "        \n",
      "        For example, suppose that `data` has data type `tf.int32` and shape (2, 3, 4),\n",
      "        and that the fingerprint method is `farmhash64`. In this case, the output\n",
      "        shape is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the\n",
      "        size of each fingerprint value in bytes. `output[0, :]` is generated from\n",
      "        12 integers in `data[0, :, :]` and similarly `output[1, :]` is generated from\n",
      "        other 12 integers in `data[1, :, :]`.\n",
      "        \n",
      "        Note that this op fingerprints the raw underlying buffer, and it does not\n",
      "        fingerprint Tensor's metadata such as data type and/or shape. For example, the\n",
      "        fingerprint values are invariant under reshapes and bitcasts as long as the\n",
      "        batch dimension remain the same:\n",
      "        \n",
      "        ```python\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.reshape(data, ...))\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.bitcast(data, ...))\n",
      "        ```\n",
      "        \n",
      "        For string data, one should expect `tf.fingerprint(data) !=\n",
      "        tf.fingerprint(tf.string.reduce_join(data))` in general.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must have rank 1 or higher.\n",
      "          method: A `Tensor` of type `tf.string`. Fingerprint method used by this op.\n",
      "            Currently, available method is `farmhash64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A two-dimensional `Tensor` of type `tf.uint8`. The first dimension equals to\n",
      "          `data`'s first dimension, and the second dimension size depends on the\n",
      "          fingerprint algorithm.\n",
      "    \n",
      "    floor(x, name=None)\n",
      "        Returns element-wise largest integer not greater than x.\n",
      "        \n",
      "        Both input range is `(-inf, inf)` and the\n",
      "        output range consists of all integer values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.3324, -1.5, 5.555, -2.532, 0.99, float(\"inf\")])\n",
      "        >>> tf.floor(x).numpy()\n",
      "        array([ 1., -2.,  5., -3.,  0., inf], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          x:  A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    foldl = foldl_v2(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldl on the list of tensors unpacked from `elems` on dimension 0. (deprecated argument values)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(back_prop=False)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "        Instead of:\n",
      "        results = tf.foldl(fn, elems, back_prop=False)\n",
      "        Use:\n",
      "        results = tf.nest.map_structure(tf.stop_gradient, tf.foldl(fn, elems))\n",
      "        \n",
      "        This foldl operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) Deprecated. False disables support for back\n",
      "            propagation. Prefer using `tf.stop_gradient` instead.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from first\n",
      "          to last.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = tf.constant([1, 2, 3, 4, 5, 6])\n",
      "          sum = tf.foldl(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    foldr = foldr_v2(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldr on the list of tensors unpacked from `elems` on dimension 0. (deprecated argument values)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(back_prop=False)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "        Instead of:\n",
      "        results = tf.foldr(fn, elems, back_prop=False)\n",
      "        Use:\n",
      "        results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "        \n",
      "        This foldr operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from last to first. The elements are made of the tensors\n",
      "        unpacked from `elems`. The callable fn takes two tensors as arguments.\n",
      "        The first argument is the accumulated value computed from the preceding\n",
      "        invocation of fn, and the second is the value at the current position of\n",
      "        `elems`. If `initializer` is None, `elems` must contain at least one element,\n",
      "        and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) Deprecated. False disables support for back\n",
      "            propagation. Prefer using `tf.stop_gradient` instead.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from last\n",
      "          to first.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = [1, 2, 3, 4, 5, 6]\n",
      "          sum = tf.foldr(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    function(func=None, input_signature=None, autograph=True, jit_compile=None, reduce_retracing=False, experimental_implements=None, experimental_autograph_options=None, experimental_attributes=None, experimental_relax_shapes=None, experimental_compile=None, experimental_follow_type_hints=None) -> tensorflow.python.types.core.GenericFunction\n",
      "        Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_compile)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_compile is deprecated, use jit_compile instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_relax_shapes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_follow_type_hints)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_follow_type_hints is deprecated\n",
      "        \n",
      "        `tf.function` constructs a `tf.types.experimental.GenericFunction` that\n",
      "        executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "        TensorFlow operations in `func`. More information on the topic can be found\n",
      "        in [Introduction to Graphs and tf.function]\n",
      "        (https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "        \n",
      "        See [Better Performance with tf.function]\n",
      "        (https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "        known limitations.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x, y):\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([2, 3])\n",
      "        >>> y = tf.constant([3, -2])\n",
      "        >>> f(x, y)\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "        special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "        run and create fresh results whenever the `GenericFunction` is called.\n",
      "        \n",
      "        ## Features\n",
      "        \n",
      "        `func` may use data-dependent Python control flow statements, including `if`,\n",
      "        `for`, `while` `break`, `continue` and `return`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   if tf.reduce_sum(x) > 0:\n",
      "        ...     return x * x\n",
      "        ...   else:\n",
      "        ...     return -x // 2\n",
      "        >>> f(tf.constant(-2))\n",
      "        <tf.Tensor: ... numpy=1>\n",
      "        \n",
      "        `func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([-2, -3])\n",
      "        >>> y = tf.Variable([3, -2])\n",
      "        >>> f()\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        `func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "        and others:\n",
      "        \n",
      "        >>> v = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in tf.range(x):\n",
      "        ...     v.assign_add(i)\n",
      "        >>> f(3)\n",
      "        >>> v\n",
      "        <tf.Variable ... numpy=4>\n",
      "        \n",
      "        Important: Any Python side-effects (appending to a list, printing with\n",
      "        `print`, etc) will only happen once, when `func` is traced. To have\n",
      "        side-effects executed into your `tf.function` they need to be written\n",
      "        as TF ops:\n",
      "        \n",
      "        >>> l = []\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in x:\n",
      "        ...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        >>> l\n",
      "        [<tf.Tensor ...>]\n",
      "        \n",
      "        Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "        ...   for i in range(len(x)):\n",
      "        ...     ta = ta.write(i, x[i] + 1)\n",
      "        ...   return ta.stack()\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        <tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "        \n",
      "        ## `tf.function` creates polymorphic callables\n",
      "        \n",
      "        Internally, `tf.types.experimental.GenericFunction` may contain multiple\n",
      "        `tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "        different data types or shapes, since TensorFlow can perform more\n",
      "        optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "        arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "        thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "        each set of Python arguments that it encounters.\n",
      "        For more information, see the\n",
      "        [tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "        \n",
      "        Executing a `GenericFunction` will select and execute the appropriate\n",
      "        `ConcreteFunction` based on the argument types and values.\n",
      "        \n",
      "        To obtain an individual `ConcreteFunction`, use the\n",
      "        `GenericFunction.get_concrete_function` method. It can be called with the\n",
      "        same arguments as `func` and returns a\n",
      "        `tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "        single `tf.Graph`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "        True\n",
      "        \n",
      "        `ConcreteFunction`s can be executed just like `GenericFunction`s, but their\n",
      "        input is resticted to the types to which they're specialized.\n",
      "        \n",
      "        ## Retracing\n",
      "        \n",
      "        `ConcreteFunctions` are built (traced) on the fly, as the `GenericFunction` is\n",
      "        called with new TensorFlow types or shapes, or with new Python values as\n",
      "        arguments. When `GenericFunction` builds a new trace, it is said that `func`\n",
      "        is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "        it can be considerably slower than executing a graph that's already been\n",
      "        traced. It is ideal to minimize the amount of retracing in your code.\n",
      "        \n",
      "        Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "        usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "        possible:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return tf.abs(x)\n",
      "        >>> f1 = f.get_concrete_function(1)\n",
      "        >>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      "        >>> f1 is f2\n",
      "        False\n",
      "        >>> f1 = f.get_concrete_function(tf.constant(1))\n",
      "        >>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      "        >>> f1 is f2\n",
      "        True\n",
      "        \n",
      "        Python numerical arguments should only be used when they take few distinct\n",
      "        values, such as hyperparameters like the number of layers in a neural network.\n",
      "        \n",
      "        ## Input signatures\n",
      "        \n",
      "        For Tensor arguments, `GenericFunction`creates a new `ConcreteFunction` for\n",
      "        every unique set of input shapes and datatypes. The example below creates two\n",
      "        separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        False\n",
      "        \n",
      "        An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "        this process. The input signature specifies the shape and type of each\n",
      "        Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "        shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "        restricts the `GenericFunction` to the specified shapes and types. It is\n",
      "        an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        True\n",
      "        \n",
      "        ## Variables may only be created once\n",
      "        \n",
      "        `tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "        for the first time:\n",
      "        \n",
      "        >>> class MyModule(tf.Module):\n",
      "        ...   def __init__(self):\n",
      "        ...     self.v = None\n",
      "        ...\n",
      "        ...   @tf.function\n",
      "        ...   def __call__(self, x):\n",
      "        ...     if self.v is None:\n",
      "        ...       self.v = tf.Variable(tf.ones_like(x))\n",
      "        ...     return self.v * x\n",
      "        \n",
      "        In general, it is recommended to create `tf.Variable`s outside of\n",
      "        `tf.function`.\n",
      "        In simple cases, persisting state across `tf.function` boundaries may be\n",
      "        implemented using a pure functional style in which state is represented by\n",
      "        `tf.Tensor`s passed as arguments and returned as return values.\n",
      "        \n",
      "        Contrast the two styles below:\n",
      "        \n",
      "        >>> state = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   state.assign_add(x)\n",
      "        >>> f(tf.constant(2))  # Non-pure functional style\n",
      "        >>> state\n",
      "        <tf.Variable ... numpy=3>\n",
      "        \n",
      "        >>> state = tf.constant(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(state, x):\n",
      "        ...   state += x\n",
      "        ...   return state\n",
      "        >>> state = f(state, tf.constant(2))  # Pure functional style\n",
      "        >>> state\n",
      "        <tf.Tensor: ... numpy=3>\n",
      "        \n",
      "        ## Python operations execute only once per trace\n",
      "        \n",
      "        `func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "        However, when the function is executed, only the TensorFlow operations will\n",
      "        run. The Python operations run only once, at trace time. If TensorFlow\n",
      "        operations depend on results from Python operations, those results will be\n",
      "        frozen into the graph.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(a, b):\n",
      "        ...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "        ...   return b\n",
      "        >>> f(1, tf.constant(1))\n",
      "        this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(1, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        >>> f(2, tf.constant(1))\n",
      "        this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(2, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        Args:\n",
      "          func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "            a decorator that can be invoked with a single argument - `func`. In other\n",
      "            words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "            `tf.function(func, input_signature=...)`. The former can be used as\n",
      "            decorator.\n",
      "          input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "            specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "            this function. If `None`, a separate function is instantiated for each\n",
      "            inferred input signature.  If input_signature is specified, every input to\n",
      "            `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "          autograph: Whether autograph should be applied on `func` before tracing a\n",
      "            graph. Data-dependent Python control flow statements require\n",
      "            `autograph=True`. For more information, see the\n",
      "            [tf.function and AutoGraph guide](\n",
      "            https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "          jit_compile: If `True`, compiles the function using\n",
      "            [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "            such as fusion, and attempts to emit more efficient code. This may\n",
      "            drastically improve the performance. If set to `True`,\n",
      "            the whole function needs to be compilable by XLA, or an\n",
      "            `errors.InvalidArgumentError` is thrown.\n",
      "            If `None` (default), compiles the function with XLA when running on TPU\n",
      "            and goes through the regular function execution path when running on\n",
      "            other devices.\n",
      "            If `False`, executes the function without XLA compilation.  Set this value\n",
      "            to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "            TPU cores, one TPU core and its host CPU).\n",
      "            Not all functions are compilable, see a list of\n",
      "            [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "          reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "            amount of retracing, for example by using more generic shapes. This\n",
      "            can be controlled for user objects by customizing their associated\n",
      "            `tf.types.experimental.TraceType`.\n",
      "          experimental_implements: If provided, contains a name of a \"known\" function\n",
      "            this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "            This is stored as an attribute in inference function,\n",
      "            which can then be detected when processing serialized function.\n",
      "            See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "            for details.  For an example of utilizing this attribute see this\n",
      "            [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "            The code above automatically detects and substitutes function that\n",
      "            implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "            implementations. For instance, a tensorflow user can use this\n",
      "             attribute to mark that their function also implements\n",
      "            `embedded_matmul` (perhaps more efficiently!)\n",
      "            by specifying it using this parameter:\n",
      "            `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "            This can either be specified as just the string name of the function or\n",
      "            a NameAttrList corresponding to a list of key-value attributes associated\n",
      "            with the function name. The name of the function will be in the 'name'\n",
      "            field of the NameAttrList. To define a formal TF op for this function\n",
      "            implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "            project.\n",
      "          experimental_autograph_options: Optional tuple of\n",
      "            `tf.autograph.experimental.Feature` values.\n",
      "          experimental_attributes: Optional dictionary of attributes to include in the\n",
      "            generated FunctionDefs.\n",
      "          experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "            instead.\n",
      "          experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "          experimental_follow_type_hints: Deprecated. Please use input_signature or\n",
      "            reduce_retracing instead.\n",
      "        \n",
      "        Returns:\n",
      "           If `func` is not None, returns a `tf.types.experimental.GenericFunction`.\n",
      "           If `func` is None, returns a decorator that, when invoked with a single\n",
      "           `func` argument, returns a `tf.types.experimental.GenericFunction`.\n",
      "        \n",
      "        Raises:\n",
      "           `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "           not available.\n",
      "    \n",
      "    gather = gather_v2(params, indices, validate_indices=None, axis=None, batch_dims=0, name=None)\n",
      "        Gather slices from params axis `axis` according to indices. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(validate_indices)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "        \n",
      "        Gather slices from `params` axis `axis` according to `indices`.  `indices`\n",
      "        must be an integer tensor of any dimension (often 1-D).\n",
      "        \n",
      "        `Tensor.__getitem__` works for scalars, `tf.newaxis`, and\n",
      "        [python slices](https://numpy.org/doc/stable/reference/arrays.indexing.html#basic-slicing-and-indexing)\n",
      "        \n",
      "        `tf.gather` extends indexing to handle tensors of indices.\n",
      "        \n",
      "        In the simplest case it's identical to scalar indexing:\n",
      "        \n",
      "        >>> params = tf.constant(['p0', 'p1', 'p2', 'p3', 'p4', 'p5'])\n",
      "        >>> params[3].numpy()\n",
      "        b'p3'\n",
      "        >>> tf.gather(params, 3).numpy()\n",
      "        b'p3'\n",
      "        \n",
      "        The most common case is to pass a single axis tensor of indices (this\n",
      "        can't be expressed as a python slice because the indices are not sequential):\n",
      "        \n",
      "        >>> indices = [2, 0, 2, 5]\n",
      "        >>> tf.gather(params, indices).numpy()\n",
      "        array([b'p2', b'p0', b'p2', b'p5'], dtype=object)\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/Gather.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        The indices can have any shape. When the `params` has 1 axis, the\n",
      "        output shape is equal to the input shape:\n",
      "        \n",
      "        >>> tf.gather(params, [[2, 0], [2, 5]]).numpy()\n",
      "        array([[b'p2', b'p0'],\n",
      "               [b'p2', b'p5']], dtype=object)\n",
      "        \n",
      "        The `params` may also have any shape. `gather` can select slices\n",
      "        across any axis depending on the `axis` argument (which defaults to 0).\n",
      "        Below it is used to gather first rows, then columns from a matrix:\n",
      "        \n",
      "        >>> params = tf.constant([[0, 1.0, 2.0],\n",
      "        ...                       [10.0, 11.0, 12.0],\n",
      "        ...                       [20.0, 21.0, 22.0],\n",
      "        ...                       [30.0, 31.0, 32.0]])\n",
      "        >>> tf.gather(params, indices=[3,1]).numpy()\n",
      "        array([[30., 31., 32.],\n",
      "               [10., 11., 12.]], dtype=float32)\n",
      "        >>> tf.gather(params, indices=[2,1], axis=1).numpy()\n",
      "        array([[ 2.,  1.],\n",
      "               [12., 11.],\n",
      "               [22., 21.],\n",
      "               [32., 31.]], dtype=float32)\n",
      "        \n",
      "        More generally: The output shape has the same shape as the input, with the\n",
      "        indexed-axis replaced by the shape of the indices.\n",
      "        \n",
      "        >>> def result_shape(p_shape, i_shape, axis=0):\n",
      "        ...   return p_shape[:axis] + i_shape + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> result_shape([1, 2, 3], [], axis=1)\n",
      "        [1, 3]\n",
      "        >>> result_shape([1, 2, 3], [7], axis=1)\n",
      "        [1, 7, 3]\n",
      "        >>> result_shape([1, 2, 3], [7, 5], axis=1)\n",
      "        [1, 7, 5, 3]\n",
      "        \n",
      "        Here are some examples:\n",
      "        \n",
      "        >>> params.shape.as_list()\n",
      "        [4, 3]\n",
      "        >>> indices = tf.constant([[0, 2]])\n",
      "        >>> tf.gather(params, indices=indices, axis=0).shape.as_list()\n",
      "        [1, 2, 3]\n",
      "        >>> tf.gather(params, indices=indices, axis=1).shape.as_list()\n",
      "        [4, 1, 2]\n",
      "        \n",
      "        >>> params = tf.random.normal(shape=(5, 6, 7, 8))\n",
      "        >>> indices = tf.random.uniform(shape=(10, 11), maxval=7, dtype=tf.int32)\n",
      "        >>> result = tf.gather(params, indices, axis=2)\n",
      "        >>> result.shape.as_list()\n",
      "        [5, 6, 10, 11, 8]\n",
      "        \n",
      "        This is because each index takes a slice from `params`, and\n",
      "        places it at the corresponding location in the output. For the above example\n",
      "        \n",
      "        >>> # For any location in indices\n",
      "        >>> a, b = 0, 1\n",
      "        >>> tf.reduce_all(\n",
      "        ...     # the corresponding slice of the result\n",
      "        ...     result[:, :, a, b, :] ==\n",
      "        ...     # is equal to the slice of `params` along `axis` at the index.\n",
      "        ...     params[:, :, indices[a, b], :]\n",
      "        ... ).numpy()\n",
      "        True\n",
      "        \n",
      "        ### Batching:\n",
      "        \n",
      "        The `batch_dims` argument lets you gather different items from each element\n",
      "        of a batch.\n",
      "        \n",
      "        Using `batch_dims=1` is equivalent to having an outer loop over the first\n",
      "        axis of `params` and `indices`:\n",
      "        \n",
      "        >>> params = tf.constant([\n",
      "        ...     [0, 0, 1, 0, 2],\n",
      "        ...     [3, 0, 0, 0, 4],\n",
      "        ...     [0, 5, 0, 6, 0]])\n",
      "        >>> indices = tf.constant([\n",
      "        ...     [2, 4],\n",
      "        ...     [0, 4],\n",
      "        ...     [1, 3]])\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        This is equivalent to:\n",
      "        \n",
      "        >>> def manually_batched_gather(params, indices, axis):\n",
      "        ...   batch_dims=1\n",
      "        ...   result = []\n",
      "        ...   for p,i in zip(params, indices):\n",
      "        ...     r = tf.gather(p, i, axis=axis-batch_dims)\n",
      "        ...     result.append(r)\n",
      "        ...   return tf.stack(result)\n",
      "        >>> manually_batched_gather(params, indices, axis=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        Higher values of `batch_dims` are equivalent to multiple nested loops over\n",
      "        the outer axes of `params` and `indices`. So the overall shape function is\n",
      "        \n",
      "        >>> def batched_result_shape(p_shape, i_shape, axis=0, batch_dims=0):\n",
      "        ...   return p_shape[:axis] + i_shape[batch_dims:] + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> batched_result_shape(\n",
      "        ...     p_shape=params.shape.as_list(),\n",
      "        ...     i_shape=indices.shape.as_list(),\n",
      "        ...     axis=1,\n",
      "        ...     batch_dims=1)\n",
      "        [3, 2]\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).shape.as_list()\n",
      "        [3, 2]\n",
      "        \n",
      "        This comes up naturally if you need to use the indices of an operation like\n",
      "        `tf.argsort`, or `tf.math.top_k` where the last dimension of the indices\n",
      "        indexes into the last dimension of input, at the corresponding location.\n",
      "        In this case you can use `tf.gather(values, indices, batch_dims=-1)`.\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.Tensor.__getitem__`: The direct tensor index operation (`t[]`), handles\n",
      "          scalars and python-slices `tensor[..., 7, 1:-1]`\n",
      "        * `tf.scatter`: A collection of operations similar to `__setitem__`\n",
      "          (`t[i] = x`)\n",
      "        * `tf.gather_nd`: An operation similar to `tf.gather` but gathers across\n",
      "          multiple axis at once (it can gather elements of a matrix instead of rows\n",
      "          or columns)\n",
      "        * `tf.boolean_mask`, `tf.where`: Binary indexing.\n",
      "        * `tf.slice` and `tf.strided_slice`: For lower level access to the\n",
      "          implementation of `__getitem__`'s python-slice handling (`t[1:-1:2]`)\n",
      "        \n",
      "        Args:\n",
      "          params: The `Tensor` from which to gather values. Must be at least rank\n",
      "            `axis + 1`.\n",
      "          indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "            `int64`. The values must be in range `[0, params.shape[axis])`.\n",
      "          validate_indices: Deprecated, does nothing. Indices are always validated on\n",
      "            CPU, never validated on GPU.\n",
      "        \n",
      "            Caution: On CPU, if an out of bound index is found, an error is raised.\n",
      "            On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "            corresponding output value.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`. The\n",
      "            `axis` in `params` to gather `indices` from. Must be greater than or equal\n",
      "            to `batch_dims`.  Defaults to the first non-batch dimension. Supports\n",
      "            negative indexes.\n",
      "          batch_dims: An `integer`.  The number of batch dimensions.  Must be less\n",
      "            than or equal to `rank(indices)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    gather_nd = gather_nd_v2(params, indices, batch_dims=0, name=None)\n",
      "        Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "        \n",
      "        `indices` is a `Tensor` of indices into `params`. The index vectors are\n",
      "        arranged along the last axis of `indices`.\n",
      "        \n",
      "        This is similar to `tf.gather`, in which `indices` defines slices into the\n",
      "        first dimension of `params`. In `tf.gather_nd`, `indices` defines slices into\n",
      "        the first `N` dimensions of `params`, where `N = indices.shape[-1]`.\n",
      "        \n",
      "        Caution: On CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "        corresponding output value.\n",
      "        \n",
      "        ## Gathering scalars\n",
      "        \n",
      "        In the simplest case the vectors in `indices` index the full rank of `params`:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices=[[0, 0],\n",
      "        ...              [1, 1]],\n",
      "        ...     params = [['a', 'b'],\n",
      "        ...               ['c', 'd']]).numpy()\n",
      "        array([b'a', b'd'], dtype=object)\n",
      "        \n",
      "        In this case the result has 1-axis fewer than `indices`, and each index vector\n",
      "        is replaced by the scalar indexed from `params`.\n",
      "        \n",
      "        In this case the shape relationship is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        assert index_depth == params.shape.rank\n",
      "        result_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        If `indices` has a rank of `K`, it is helpful to think `indices` as a\n",
      "        (K-1)-dimensional tensor of indices into `params`.\n",
      "        \n",
      "        ## Gathering slices\n",
      "        \n",
      "        If the index vectors do not index the full rank of `params` then each location\n",
      "        in the result contains a slice of params. This example collects rows from a\n",
      "        matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [['a', 'b', 'c'],\n",
      "        ...               ['d', 'e', 'f']]).numpy()\n",
      "        array([[b'd', b'e', b'f'],\n",
      "               [b'a', b'b', b'c']], dtype=object)\n",
      "        \n",
      "        Here `indices` contains `[2]` index vectors, each with a length of `1`.\n",
      "        The index vectors each refer to rows of the `params` matrix. Each\n",
      "        row has a shape of `[3]` so the output shape is `[2, 3]`.\n",
      "        \n",
      "        In this case, the relationship between the shapes is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        outer_shape = indices.shape[:-1]\n",
      "        assert index_depth <= params.shape.rank\n",
      "        inner_shape = params.shape[index_depth:]\n",
      "        output_shape = outer_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        It is helpful to think of the results in this case as tensors-of-tensors.\n",
      "        The shape of the outer tensor is set by the leading dimensions of `indices`.\n",
      "        While the shape of the inner tensors is the shape of a single slice.\n",
      "        \n",
      "        ## Batches\n",
      "        \n",
      "        Additionally, both `params` and `indices` can have `M` leading batch\n",
      "        dimensions that exactly match. In this case `batch_dims` must be set to `M`.\n",
      "        \n",
      "        For example, to collect one row from each of a batch of matrices you could\n",
      "        set the leading elements of the index vectors to be their location in the\n",
      "        batch:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1],\n",
      "        ...                [1, 0],\n",
      "        ...                [2, 4],\n",
      "        ...                [3, 2],\n",
      "        ...                [4, 1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        The `batch_dims` argument lets you omit those leading location dimensions\n",
      "        from the index:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims=1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0],\n",
      "        ...                [4],\n",
      "        ...                [2],\n",
      "        ...                [1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        This is equivalent to caling a separate `gather_nd` for each location in the\n",
      "        batch dimensions.\n",
      "        \n",
      "        \n",
      "        >>> params=tf.zeros([5, 7, 3])\n",
      "        >>> indices=tf.zeros([5, 1])\n",
      "        >>> batch_dims = 1\n",
      "        >>>\n",
      "        >>> index_depth = indices.shape[-1]\n",
      "        >>> batch_shape = indices.shape[:batch_dims]\n",
      "        >>> assert params.shape[:batch_dims] == batch_shape\n",
      "        >>> outer_shape = indices.shape[batch_dims:-1]\n",
      "        >>> assert index_depth <= params.shape.rank\n",
      "        >>> inner_shape = params.shape[batch_dims + index_depth:]\n",
      "        >>> output_shape = batch_shape + outer_shape + inner_shape\n",
      "        >>> output_shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        ### More examples\n",
      "        \n",
      "        Indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'a1', b'b1'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1], [1, 0]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 0, 1], [1, 0, 1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([b'b0', b'b1'], dtype=object)\n",
      "        \n",
      "        The examples below are for the case when only indices have leading extra\n",
      "        dimensions. If both 'params' and 'indices' have leading batch dimensions, use\n",
      "        the 'batch_dims' parameter to run gather_nd in batch mode.\n",
      "        \n",
      "        Batched indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0]], [[0, 1]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[b'a'],\n",
      "               [b'b']], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Batched slice indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[[b'c', b'd']],\n",
      "               [[b'a', b'b']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        Batched indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[[b'a1', b'b1'],\n",
      "                 [b'c1', b'd1']]],\n",
      "               [[[b'a0', b'b0'],\n",
      "                 [b'c0', b'd0']]]], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0'],\n",
      "                [b'a1', b'b1']],\n",
      "               [[b'a0', b'b0'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'b0', b'b1'],\n",
      "               [b'd0', b'c1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        Examples with batched 'params' and 'indices':\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [[['a0', 'b0'],\n",
      "        ...                ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'],\n",
      "        ...                ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0']],\n",
      "               [[b'a1', b'b1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1, 0]], [[0, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0'],\n",
      "               [b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        See also `tf.gather`.\n",
      "        \n",
      "        Args:\n",
      "          params: A `Tensor`. The tensor from which to gather values.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          name: A name for the operation (optional).\n",
      "          batch_dims: An integer or a scalar 'Tensor'. The number of batch dimensions.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    get_current_name_scope()\n",
      "        Returns current full name scope specified by `tf.name_scope(...)`s.\n",
      "        \n",
      "        For example,\n",
      "        ```python\n",
      "        with tf.name_scope(\"outer\"):\n",
      "          tf.get_current_name_scope()  # \"outer\"\n",
      "        \n",
      "          with tf.name_scope(\"inner\"):\n",
      "            tf.get_current_name_scope()  # \"outer/inner\"\n",
      "        ```\n",
      "        \n",
      "        In other words, `tf.get_current_name_scope()` returns the op name prefix that\n",
      "        will be prepended to, if an op is created at that place.\n",
      "        \n",
      "        Note that `@tf.function` resets the name scope stack as shown below.\n",
      "        \n",
      "        ```\n",
      "        with tf.name_scope(\"outer\"):\n",
      "        \n",
      "          @tf.function\n",
      "          def foo(x):\n",
      "            with tf.name_scope(\"inner\"):\n",
      "              return tf.add(x * x)  # Op name is \"inner/Add\", not \"outer/inner/Add\"\n",
      "        ```\n",
      "    \n",
      "    get_logger()\n",
      "        Return TF logger instance.\n",
      "        \n",
      "        Returns:\n",
      "          An instance of the Python logging library Logger.\n",
      "        \n",
      "        See Python documentation (https://docs.python.org/3/library/logging.html)\n",
      "        for detailed API. Below is only a summary.\n",
      "        \n",
      "        The logger has 5 levels of logging from the most serious to the least:\n",
      "        \n",
      "        1. FATAL\n",
      "        2. ERROR\n",
      "        3. WARN\n",
      "        4. INFO\n",
      "        5. DEBUG\n",
      "        \n",
      "        The logger has the following methods, based on these logging levels:\n",
      "        \n",
      "        1. fatal(msg, *args, **kwargs)\n",
      "        2. error(msg, *args, **kwargs)\n",
      "        3. warn(msg, *args, **kwargs)\n",
      "        4. info(msg, *args, **kwargs)\n",
      "        5. debug(msg, *args, **kwargs)\n",
      "        \n",
      "        The `msg` can contain string formatting.  An example of logging at the `ERROR`\n",
      "        level\n",
      "        using string formating is:\n",
      "        \n",
      "        >>> tf.get_logger().error(\"The value %d is invalid.\", 3)\n",
      "        \n",
      "        You can also specify the logging verbosity.  In this case, the\n",
      "        WARN level log will not be emitted:\n",
      "        \n",
      "        >>> tf.get_logger().setLevel(ERROR)\n",
      "        >>> tf.get_logger().warn(\"This is a warning.\")\n",
      "    \n",
      "    get_static_value = constant_value(tensor, partial=False)\n",
      "        Returns the constant value of the given tensor, if efficiently calculable.\n",
      "        \n",
      "        This function attempts to partially evaluate the given tensor, and\n",
      "        returns its value as a numpy ndarray if this succeeds.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> a = tf.constant(10)\n",
      "        >>> tf.get_static_value(a)\n",
      "        10\n",
      "        >>> b = tf.constant(20)\n",
      "        >>> tf.get_static_value(tf.add(a, b))\n",
      "        30\n",
      "        \n",
      "        >>> # `tf.Variable` is not supported.\n",
      "        >>> c = tf.Variable(30)\n",
      "        >>> print(tf.get_static_value(c))\n",
      "        None\n",
      "        \n",
      "        Using `partial` option is most relevant when calling `get_static_value` inside\n",
      "        a `tf.function`. Setting it to `True` will return the results but for the\n",
      "        values that cannot be evaluated will be `None`. For example:\n",
      "        \n",
      "        ```python\n",
      "        class Foo:\n",
      "          def __init__(self):\n",
      "            self.a = tf.Variable(1)\n",
      "            self.b = tf.constant(2)\n",
      "        \n",
      "          @tf.function\n",
      "          def bar(self, partial):\n",
      "            packed = tf.raw_ops.Pack(values=[self.a, self.b])\n",
      "            static_val = tf.get_static_value(packed, partial=partial)\n",
      "            tf.print(static_val)\n",
      "        \n",
      "        f = Foo()\n",
      "        f.bar(partial=True)  # `array([None, array(2, dtype=int32)], dtype=object)`\n",
      "        f.bar(partial=False)  # `None`\n",
      "        ```\n",
      "        \n",
      "        Compatibility(V1): If `constant_value(tensor)` returns a non-`None` result, it\n",
      "        will no longer be possible to feed a different value for `tensor`. This allows\n",
      "        the result of this function to influence the graph that is constructed, and\n",
      "        permits static shape optimizations.\n",
      "        \n",
      "        Args:\n",
      "          tensor: The Tensor to be evaluated.\n",
      "          partial: If True, the returned numpy array is allowed to have partially\n",
      "            evaluated values. Values that can't be evaluated will be None.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy ndarray containing the constant value of the given `tensor`,\n",
      "          or None if it cannot be calculated.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor is not an ops.Tensor.\n",
      "    \n",
      "    grad_pass_through(f)\n",
      "        Creates a grad-pass-through op with the forward behavior provided in f.\n",
      "        \n",
      "        Use this function to wrap any op, maintaining its behavior in the forward\n",
      "        pass, but replacing the original op in the backward graph with an identity.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.Variable(1.0, name=\"x\")\n",
      "        z = tf.Variable(3.0, name=\"z\")\n",
      "        \n",
      "        with tf.GradientTape() as tape:\n",
      "          # y will evaluate to 9.0\n",
      "          y = tf.grad_pass_through(x.assign)(z**2)\n",
      "        # grads will evaluate to 6.0\n",
      "        grads = tape.gradient(y, z)\n",
      "        ```\n",
      "        \n",
      "        Another example is a 'differentiable' moving average approximation, where\n",
      "        gradients are allowed to flow into the last value fed to the moving average,\n",
      "        but the moving average is still used for the forward pass:\n",
      "        \n",
      "        ```python\n",
      "        x = ... # Some scalar value\n",
      "        # A moving average object, we don't need to know how this is implemented\n",
      "        moving_average = MovingAverage()\n",
      "        with backprop.GradientTape() as tape:\n",
      "          # mavg_x will evaluate to the current running average value\n",
      "          mavg_x = tf.grad_pass_through(moving_average)(x)\n",
      "        grads = tape.gradient(mavg_x, x) # grads will evaluate to 1.0\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`\n",
      "            outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same values as `f(x)` and whose\n",
      "          gradients are the same as those of an identity function.\n",
      "    \n",
      "    gradients = gradients_v2(ys, xs, grad_ys=None, name='gradients', gate_gradients=False, aggregation_method=None, stop_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "        Constructs symbolic derivatives of sum of `ys` w.r.t. x in `xs`.\n",
      "        \n",
      "        `tf.gradients` is only valid in a graph context. In particular,\n",
      "        it is valid in the context of a `tf.function` wrapper, where code\n",
      "        is executing as a graph.\n",
      "        \n",
      "        `ys` and `xs` are each a `Tensor` or a list of tensors.  `grad_ys`\n",
      "        is a list of `Tensor`, holding the gradients received by the\n",
      "        `ys`. The list must be the same length as `ys`.\n",
      "        \n",
      "        `gradients()` adds ops to the graph to output the derivatives of `ys` with\n",
      "        respect to `xs`.  It returns a list of `Tensor` of length `len(xs)` where\n",
      "        each tensor is the `sum(dy/dx)` for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        `grad_ys` is a list of tensors of the same length as `ys` that holds\n",
      "        the initial gradients for each y in `ys`.  When `grad_ys` is None,\n",
      "        we fill in a tensor of '1's of the shape of y for each y in `ys`.  A\n",
      "        user can provide their own initial `grad_ys` to compute the\n",
      "        derivatives using a different initial gradient for each y (e.g., if\n",
      "        one wanted to weight the gradient differently for each value in\n",
      "        each y).\n",
      "        \n",
      "        `stop_gradients` is a `Tensor` or a list of tensors to be considered constant\n",
      "        with respect to all `xs`. These tensors will not be backpropagated through,\n",
      "        as though they had been explicitly disconnected using `stop_gradient`.  Among\n",
      "        other things, this allows computation of partial derivatives as opposed to\n",
      "        total derivatives. For example:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def example():\n",
      "        ...   a = tf.constant(0.)\n",
      "        ...   b = 2 * a\n",
      "        ...   return tf.gradients(a + b, [a, b], stop_gradients=[a, b])\n",
      "        >>> example()\n",
      "        [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      "        \n",
      "        Here the partial derivatives `g` evaluate to `[1.0, 1.0]`, compared to the\n",
      "        total derivatives `tf.gradients(a + b, [a, b])`, which take into account the\n",
      "        influence of `a` on `b` and evaluate to `[3.0, 1.0]`.  Note that the above is\n",
      "        equivalent to:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def example():\n",
      "        ...   a = tf.stop_gradient(tf.constant(0.))\n",
      "        ...   b = tf.stop_gradient(2 * a)\n",
      "        ...   return tf.gradients(a + b, [a, b])\n",
      "        >>> example()\n",
      "        [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      "        \n",
      "        `stop_gradients` provides a way of stopping gradient after the graph has\n",
      "        already been constructed, as compared to `tf.stop_gradient` which is used\n",
      "        during graph construction.  When the two approaches are combined,\n",
      "        backpropagation stops at both `tf.stop_gradient` nodes and nodes in\n",
      "        `stop_gradients`, whichever is encountered first.\n",
      "        \n",
      "        All integer tensors are considered constant with respect to all `xs`, as if\n",
      "        they were included in `stop_gradients`.\n",
      "        \n",
      "        `unconnected_gradients` determines the value returned for each x in xs if it\n",
      "        is unconnected in the graph to ys. By default this is None to safeguard\n",
      "        against errors. Mathematically these gradients are zero which can be requested\n",
      "        using the `'zero'` option. `tf.UnconnectedGradients` provides the\n",
      "        following options and behaviors:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def example(use_zero):\n",
      "        ...   a = tf.ones([1, 2])\n",
      "        ...   b = tf.ones([3, 1])\n",
      "        ...   if use_zero:\n",
      "        ...     return tf.gradients([b], [a], unconnected_gradients='zero')\n",
      "        ...   else:\n",
      "        ...     return tf.gradients([b], [a], unconnected_gradients='none')\n",
      "        >>> example(False)\n",
      "        [None]\n",
      "        >>> example(True)\n",
      "        [<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 0.]], ...)>]\n",
      "        \n",
      "        Let us take one practical example which comes during the back propogation\n",
      "        phase. This function is used to evaluate the derivatives of the cost function\n",
      "        with respect to Weights `Ws` and Biases `bs`. Below sample implementation\n",
      "        provides the exaplantion of what it is actually used for :\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def example():\n",
      "        ...   Ws = tf.constant(0.)\n",
      "        ...   bs = 2 * Ws\n",
      "        ...   cost = Ws + bs  # This is just an example. Please ignore the formulas.\n",
      "        ...   g = tf.gradients(cost, [Ws, bs])\n",
      "        ...   dCost_dW, dCost_db = g\n",
      "        ...   return dCost_dW, dCost_db\n",
      "        >>> example()\n",
      "        (<tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          grad_ys: Optional. A `Tensor` or list of tensors the same size as\n",
      "            `ys` and holding the gradients computed for each y in `ys`.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'gradients'.\n",
      "          gate_gradients: If True, add a tuple around the gradients returned\n",
      "            for an operations.  This avoids some race conditions.\n",
      "          aggregation_method: Specifies the method used to combine gradient terms.\n",
      "            Accepted values are constants defined in the class `AggregationMethod`.\n",
      "          stop_gradients: Optional. A `Tensor` or list of tensors not to differentiate\n",
      "            through.\n",
      "          unconnected_gradients: Optional. Specifies the gradient value returned when\n",
      "            the given input tensors are unconnected. Accepted values are constants\n",
      "            defined in the class `tf.UnconnectedGradients` and the default value is\n",
      "            `none`.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` of length `len(xs)` where each tensor is the `sum(dy/dx)`\n",
      "          for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `x` and `y` does not\n",
      "            have a registered gradient function.\n",
      "          ValueError: if the arguments are invalid.\n",
      "          RuntimeError: if called in Eager mode.\n",
      "    \n",
      "    greater(x, y, name=None)\n",
      "        Returns the truth value of (x > y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5, 2, 5])\n",
      "        \n",
      "        tf.math.greater(x, y) ==> [False, True, True]\n",
      "        \n",
      "        \n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5])\n",
      "        \n",
      "        tf.math.greater(x, y) ==> [False, False, True]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    greater_equal(x, y, name=None)\n",
      "        Returns the truth value of (x >= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        \n",
      "        y = tf.constant([5, 2, 5, 10])\n",
      "        \n",
      "        tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "        \n",
      "        \n",
      "        \n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        \n",
      "        y = tf.constant([5])\n",
      "        \n",
      "        tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    group(*inputs, **kwargs)\n",
      "        Create an op that groups multiple operations.\n",
      "        \n",
      "        When this op finishes, all ops in `inputs` have finished. This op has no\n",
      "        output.\n",
      "        \n",
      "        Note: *In TensorFlow 2 with eager and/or Autograph, you should not require\n",
      "        this method, as ops execute in the expected order thanks to automatic control\n",
      "        dependencies.* Only use `tf.group` when working with v1\n",
      "        `tf.Graph` code.\n",
      "        \n",
      "        When operating in a v1-style graph context, ops are not executed in the same\n",
      "        order as specified in the code; TensorFlow will attempt to execute ops in\n",
      "        parallel or in an order convenient to the result it is computing.  `tf.group`\n",
      "        allows you to request that one or more results finish before execution\n",
      "        continues.\n",
      "        \n",
      "        `tf.group` creates a single op (of type `NoOp`), and then adds appropriate\n",
      "        control dependencies.  Thus, `c = tf.group(a, b)` will compute the same graph\n",
      "        as this:\n",
      "        \n",
      "            with tf.control_dependencies([a, b]):\n",
      "                c = tf.no_op()\n",
      "        \n",
      "        See also `tf.tuple` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Zero or more tensors to group.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          An Operation that executes all its inputs.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unknown keyword argument is provided.\n",
      "    \n",
      "    guarantee_const(input, name=None)\n",
      "        Promise to the TF runtime that the input tensor is a constant. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Not for public use.\n",
      "        \n",
      "        The runtime is then free to make optimizations based on this.\n",
      "        \n",
      "        Returns the input tensor without modification.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for this operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same dtype as `input`.\n",
      "    \n",
      "    hessians = HessiansV2(ys, xs, gate_gradients=False, aggregation_method=None, name='hessians')\n",
      "        Constructs the Hessian of sum of `ys` with respect to `x` in `xs`.\n",
      "        \n",
      "        `hessians()` adds ops to the graph to output the Hessian matrix of `ys`\n",
      "        with respect to `xs`.  It returns a list of `Tensor` of length `len(xs)`\n",
      "        where each tensor is the Hessian of `sum(ys)`.\n",
      "        \n",
      "        The Hessian is a matrix of second-order partial derivatives of a scalar\n",
      "        tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).\n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          gate_gradients: See `gradients()` documentation for details.\n",
      "          aggregation_method: See `gradients()` documentation for details.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'hessians'.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Hessian matrices of `sum(ys)` for each `x` in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `xs` and `ys` does not\n",
      "            have a registered gradient function.\n",
      "    \n",
      "    histogram_fixed_width(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Return histogram of values.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 histogram counting\n",
      "        the number of entries in `values` that fell into every bin.  The bins are\n",
      "        equal width and determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D `Tensor` holding histogram of values.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)\n",
      "        >>> hist.numpy()\n",
      "        array([2, 1, 1, 0, 2], dtype=int32)\n",
      "    \n",
      "    histogram_fixed_width_bins(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Bins the given values for use in a histogram.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 `Tensor`\n",
      "        representing the indices of a histogram into which each element\n",
      "        of `values` would be binned. The bins are equal width and\n",
      "        determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` holding the indices of the binned values whose shape matches\n",
      "          `values`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> indices = tf.histogram_fixed_width_bins(new_values, value_range, nbins=5)\n",
      "        >>> indices.numpy()\n",
      "        array([0, 0, 1, 2, 4, 4], dtype=int32)\n",
      "    \n",
      "    identity(input, name=None)\n",
      "        Return a Tensor with the same shape and contents as input.\n",
      "        \n",
      "        The return value is not the same Tensor as the original, but contains the same\n",
      "        values.  This operation is fast when used on the same device.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([0.78])\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        >>> a_identity.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        \n",
      "        Calling `tf.identity` on a variable will make a Tensor that represents the\n",
      "        value of that variable at the time it is called. This is equivalent to calling\n",
      "        `<variable>.read_value()`.\n",
      "        \n",
      "        >>> a = tf.Variable(5)\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.assign_add(1)\n",
      "        <tf.Variable ... shape=() dtype=int32, numpy=6>\n",
      "        >>> a.numpy()\n",
      "        6\n",
      "        >>> a_identity.numpy()\n",
      "        5\n",
      "        \n",
      "        This function can also be used to explicitly transfer tensors between devices.\n",
      "        For example, to transfer a tensor in GPU memory back to host memory, one can\n",
      "        use:\n",
      "        \n",
      "        >>> with tf.device(\"/gpu:0\"):\n",
      "        ...   x_on_gpu = tf.constant(1)\n",
      "        >>> with tf.device(\"/cpu:0\"):\n",
      "        ...   x_on_cpu = tf.identity(x_on_gpu)\n",
      "        >>> x_on_cpu.device\n",
      "        '/job:localhost/replica:0/task:0/device:CPU:0'\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`, a `Variable`, a `CompositeTensor` or anything that can be\n",
      "          converted to a tensor using `tf.convert_to_tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or CompositeTensor. Has the same type and contents as `input`.\n",
      "    \n",
      "    identity_n(input, name=None)\n",
      "        Returns a list of tensors with the same shapes and contents as the input\n",
      "        \n",
      "        tensors.\n",
      "        \n",
      "        \n",
      "        \n",
      "        This op can be used to override the gradient for complicated functions. For\n",
      "        \n",
      "        example, suppose y = f(x) and we wish to apply a custom function g for backprop\n",
      "        \n",
      "        such that dx = g(dy). In Python,\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        with tf.get_default_graph().gradient_override_map(\n",
      "        \n",
      "            {'IdentityN': 'OverrideGradientWithG'}):\n",
      "        \n",
      "          y, _ = identity_n([f(x), x])\n",
      "        \n",
      "        \n",
      "        \n",
      "        @tf.RegisterGradient('OverrideGradientWithG')\n",
      "        \n",
      "        def ApplyG(op, dy, _):\n",
      "        \n",
      "          return [None, g(dy)]  # Do not backprop to f(x).\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A list of `Tensor` objects.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `input`.\n",
      "    \n",
      "    import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None)\n",
      "        Imports the graph from `graph_def` into the current default `Graph`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(op_dict)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n",
      "        \n",
      "        This function provides a way to import a serialized TensorFlow\n",
      "        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "        protocol buffer, and extract individual objects in the `GraphDef` as\n",
      "        `tf.Tensor` and `tf.Operation` objects. Once extracted,\n",
      "        these objects are placed into the current default `Graph`. See\n",
      "        `tf.Graph.as_graph_def` for a way to create a `GraphDef`\n",
      "        proto.\n",
      "        \n",
      "        Args:\n",
      "          graph_def: A `GraphDef` proto containing operations to be imported into\n",
      "            the default graph.\n",
      "          input_map: A dictionary mapping input names (as strings) in `graph_def`\n",
      "            to `Tensor` objects. The values of the named input tensors in the\n",
      "            imported graph will be re-mapped to the respective `Tensor` values.\n",
      "          return_elements: A list of strings containing operation names in\n",
      "            `graph_def` that will be returned as `Operation` objects; and/or\n",
      "            tensor names in `graph_def` that will be returned as `Tensor` objects.\n",
      "          name: (Optional.) A prefix that will be prepended to the names in\n",
      "            `graph_def`. Note that this does not apply to imported function names.\n",
      "            Defaults to `\"import\"`.\n",
      "          op_dict: (Optional.) Deprecated, do not use.\n",
      "          producer_op_list: (Optional.) An `OpList` proto with the (possibly stripped)\n",
      "            list of `OpDef`s used by the producer of the graph. If provided,\n",
      "            unrecognized attrs for ops in `graph_def` that have their default value\n",
      "            according to `producer_op_list` will be removed. This will allow some more\n",
      "            `GraphDef`s produced by later binaries to be accepted by earlier binaries.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Operation` and/or `Tensor` objects from the imported graph,\n",
      "          corresponding to the names in `return_elements`,\n",
      "          and None if `returns_elements` is None.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `graph_def` is not a `GraphDef` proto,\n",
      "            `input_map` is not a dictionary mapping strings to `Tensor` objects,\n",
      "            or `return_elements` is not a list of strings.\n",
      "          ValueError: If `input_map`, or `return_elements` contains names that\n",
      "            do not appear in `graph_def`, or `graph_def` is not well-formed (e.g.\n",
      "            it refers to an unknown tensor).\n",
      "    \n",
      "    init_scope()\n",
      "        A context manager that lifts ops out of control-flow scopes and function-building graphs.\n",
      "        \n",
      "        There is often a need to lift variable initialization ops out of control-flow\n",
      "        scopes, function-building graphs, and gradient tapes. Entering an\n",
      "        `init_scope` is a mechanism for satisfying these desiderata. In particular,\n",
      "        entering an `init_scope` has three effects:\n",
      "        \n",
      "          (1) All control dependencies are cleared the moment the scope is entered;\n",
      "              this is equivalent to entering the context manager returned from\n",
      "              `control_dependencies(None)`, which has the side-effect of exiting\n",
      "              control-flow scopes like `tf.cond` and `tf.while_loop`.\n",
      "        \n",
      "          (2) All operations that are created while the scope is active are lifted\n",
      "              into the lowest context on the `context_stack` that is not building a\n",
      "              graph function. Here, a context is defined as either a graph or an eager\n",
      "              context. Every context switch, i.e., every installation of a graph as\n",
      "              the default graph and every switch into eager mode, is logged in a\n",
      "              thread-local stack called `context_switches`; the log entry for a\n",
      "              context switch is popped from the stack when the context is exited.\n",
      "              Entering an `init_scope` is equivalent to crawling up\n",
      "              `context_switches`, finding the first context that is not building a\n",
      "              graph function, and entering it. A caveat is that if graph mode is\n",
      "              enabled but the default graph stack is empty, then entering an\n",
      "              `init_scope` will simply install a fresh graph as the default one.\n",
      "        \n",
      "          (3) The gradient tape is paused while the scope is active.\n",
      "        \n",
      "        When eager execution is enabled, code inside an init_scope block runs with\n",
      "        eager execution enabled even when tracing a `tf.function`. For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        @tf.function\n",
      "        def func():\n",
      "          # A function constructs TensorFlow graphs,\n",
      "          # it does not execute eagerly.\n",
      "          assert not tf.executing_eagerly()\n",
      "          with tf.init_scope():\n",
      "            # Initialization runs with eager execution enabled\n",
      "            assert tf.executing_eagerly()\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if graph state is incompatible with this initialization.\n",
      "    \n",
      "    inside_function()\n",
      "        Indicates whether the caller code is executing inside a `tf.function`.\n",
      "        \n",
      "        Returns:\n",
      "          Boolean, True if the caller code is executing inside a `tf.function`\n",
      "          rather than eagerly.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> tf.inside_function()\n",
      "        False\n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   print(tf.inside_function())\n",
      "        >>> f()\n",
      "        True\n",
      "    \n",
      "    is_symbolic_tensor(tensor)\n",
      "        Test if `tensor` is a symbolic Tensor.\n",
      "        \n",
      "        Args:\n",
      "          tensor: a tensor-like object\n",
      "        \n",
      "        Returns:\n",
      "          True if `tensor` is a symbolic tensor (not an eager tensor).\n",
      "    \n",
      "    is_tensor = is_tf_type(x)\n",
      "        Checks whether `x` is a TF-native type that can be passed to many TF ops.\n",
      "        \n",
      "        Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\n",
      "        without any conversion (e.g., `tf.Tensor`, `tf.SparseTensor`, and\n",
      "        `tf.RaggedTensor`) from types that need to be converted into tensors before\n",
      "        they are ingested (e.g., numpy `ndarray` and Python scalars).\n",
      "        \n",
      "        For example, in the following code block:\n",
      "        \n",
      "        ```python\n",
      "        if not tf.is_tensor(t):\n",
      "          t = tf.convert_to_tensor(t)\n",
      "        return t.shape, t.dtype\n",
      "        ```\n",
      "        \n",
      "        we check to make sure that `t` is a tensor (and convert it if not) before\n",
      "        accessing its `shape` and `dtype`.  (But note that not all TensorFlow native\n",
      "        types have shapes or dtypes; `tf.data.Dataset` is an example of a TensorFlow\n",
      "        native type that has neither shape nor dtype.)\n",
      "        \n",
      "        Args:\n",
      "          x: A python object to check.\n",
      "        \n",
      "        Returns:\n",
      "          `True` if `x` is a TensorFlow-native type.\n",
      "    \n",
      "    less(x, y, name=None)\n",
      "        Returns the truth value of (x < y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5])\n",
      "        \n",
      "        tf.math.less(x, y) ==> [False, True, False]\n",
      "        \n",
      "        \n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5, 6, 7])\n",
      "        \n",
      "        tf.math.less(x, y) ==> [False, True, True]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    less_equal(x, y, name=None)\n",
      "        Returns the truth value of (x <= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5])\n",
      "        \n",
      "        tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "        \n",
      "        \n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        \n",
      "        y = tf.constant([5, 6, 6])\n",
      "        \n",
      "        tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    linspace = linspace_nd(start, stop, num, name=None, axis=0)\n",
      "        Generates evenly-spaced values in an interval along a given axis.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`\n",
      "        along a given `axis`.\n",
      "        If `num > 1`, the values in the sequence increase by\n",
      "        `(stop - start) / (num - 1)`, so that the last one is exactly `stop`.\n",
      "        If `num <= 0`, `ValueError` is raised.\n",
      "        \n",
      "        Matches\n",
      "        [np.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)'s\n",
      "        behaviour\n",
      "        except when `num == 0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        `Start` and `stop` can be tensors of arbitrary size:\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  5.  ],\n",
      "               [ 2.5 , 13.75],\n",
      "               [ 5.  , 22.5 ],\n",
      "               [ 7.5 , 31.25],\n",
      "               [10.  , 40.  ]], dtype=float32)>\n",
      "        \n",
      "        `Axis` is where the values will be generated (the dimension in the\n",
      "        returned tensor which corresponds to the axis will be equal to `num`)\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=-1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  2.5 ,  5.  ,  7.5 , 10.  ],\n",
      "               [ 5.  , 13.75, 22.5 , 31.25, 40.  ]], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`,\n",
      "            `float32`, `float64`. N-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type and shape as `start`. N-D tensor.\n",
      "            Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D\n",
      "            tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "          axis: Axis along which the operation is performed (used only when N-D\n",
      "            tensors are provided).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    load_library(library_location)\n",
      "        Loads a TensorFlow plugin.\n",
      "        \n",
      "        \"library_location\" can be a path to a specific shared object, or a folder.\n",
      "        If it is a folder, all shared objects that are named \"libtfkernel*\" will be\n",
      "        loaded. When the library is loaded, kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process.\n",
      "        \n",
      "        Args:\n",
      "          library_location: Path to the plugin or the folder of plugins.\n",
      "            Relative or absolute filesystem path to a dynamic library file or folder.\n",
      "        \n",
      "        Returns:\n",
      "          None\n",
      "        \n",
      "        Raises:\n",
      "          OSError: When the file to be loaded is not found.\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_op_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing custom ops and kernels.\n",
      "        \n",
      "        Pass \"library_filename\" to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here. When the\n",
      "        library is loaded, ops and kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process. Note\n",
      "        that ops with the same name as an existing op are rejected and not\n",
      "        registered with the process.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          A python module containing the Python wrappers for Ops defined in\n",
      "          the plugin.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library or get the python wrappers.\n",
      "    \n",
      "    logical_and(x, y, name=None)\n",
      "        Returns the truth value of x AND y element-wise.\n",
      "        \n",
      "        Logical AND function.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        \n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        \n",
      "        \n",
      "          - Two single elements of type `bool`.\n",
      "        \n",
      "          - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "        \n",
      "            be calculated by applying logical AND with the single element to each\n",
      "        \n",
      "            element in the larger Tensor.\n",
      "        \n",
      "          - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "        \n",
      "            the result will be the element-wise logical AND of the two input tensors.\n",
      "        \n",
      "        \n",
      "        \n",
      "        You can also use the `&` operator instead.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "        \n",
      "          >>> b = tf.constant([False])\n",
      "        \n",
      "          >>> tf.math.logical_and(a, b)\n",
      "        \n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "        \n",
      "          >>> a & b\n",
      "        \n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> c = tf.constant([True])\n",
      "        \n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "        \n",
      "          >>> tf.math.logical_and(c, x)\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "          >>> c & x\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "        \n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "        \n",
      "          >>> tf.math.logical_and(y, z)\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "        \n",
      "          >>> y & z\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> tf.logical_and([[True, False]], [[True], [False]])\n",
      "        \n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "        \n",
      "            array([[ True, False],\n",
      "        \n",
      "                   [False, False]])>\n",
      "        \n",
      "        \n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_all`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "        \n",
      "            x: A `tf.Tensor` of type bool.\n",
      "        \n",
      "            y: A `tf.Tensor` of type bool.\n",
      "        \n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        \n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_not(x, name=None)\n",
      "        Returns the truth value of `NOT x` element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "        \n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_or(x, y, name=None)\n",
      "        Returns the truth value of x OR y element-wise.\n",
      "        \n",
      "        Logical OR function.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        \n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        \n",
      "        \n",
      "        - Two single elements of type `bool`.\n",
      "        \n",
      "        - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "        \n",
      "          be calculated by applying logical OR with the single element to each\n",
      "        \n",
      "          element in the larger Tensor.\n",
      "        \n",
      "        - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "        \n",
      "          the result will be the element-wise logical OR of the two input tensors.\n",
      "        \n",
      "        \n",
      "        \n",
      "        You can also use the `|` operator instead.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "        \n",
      "          >>> b = tf.constant([False])\n",
      "        \n",
      "          >>> tf.math.logical_or(a, b)\n",
      "        \n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "          >>> a | b\n",
      "        \n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> c = tf.constant([False])\n",
      "        \n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "        \n",
      "          >>> tf.math.logical_or(c, x)\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "        \n",
      "          >>> c | x\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "        \n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "        \n",
      "          >>> tf.math.logical_or(y, z)\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "        \n",
      "          >>> y | z\n",
      "        \n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "        \n",
      "        \n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "        \n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "        \n",
      "          array([[ True,  True],\n",
      "        \n",
      "               [ True, False]])>\n",
      "        \n",
      "        \n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "        \n",
      "            x: A `tf.Tensor` of type bool.\n",
      "        \n",
      "            y: A `tf.Tensor` of type bool.\n",
      "        \n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        \n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    make_ndarray = MakeNdarray(tensor)\n",
      "        Create a numpy ndarray from a tensor.\n",
      "        \n",
      "        Create a numpy ndarray with the same shape and data as the tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Tensor a has shape (2,3)\n",
      "        a = tf.constant([[1,2,3],[4,5,6]])\n",
      "        proto_tensor = tf.make_tensor_proto(a)  # convert `tensor a` to a proto tensor\n",
      "        tf.make_ndarray(proto_tensor) # output: array([[1, 2, 3],\n",
      "        #                                              [4, 5, 6]], dtype=int32)\n",
      "        # output has shape (2,3)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A TensorProto.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy array with the tensor contents.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor has unsupported type.\n",
      "    \n",
      "    make_tensor_proto(values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False)\n",
      "        Create a TensorProto.\n",
      "        \n",
      "        In TensorFlow 2.0, representing tensors as protos should no longer be a\n",
      "        common workflow. That said, this utility function is still useful for\n",
      "        generating TF Serving request protos:\n",
      "        \n",
      "        ```python\n",
      "          request = tensorflow_serving.apis.predict_pb2.PredictRequest()\n",
      "          request.model_spec.name = \"my_model\"\n",
      "          request.model_spec.signature_name = \"serving_default\"\n",
      "          request.inputs[\"images\"].CopyFrom(tf.make_tensor_proto(X_new))\n",
      "        ```\n",
      "        \n",
      "        `make_tensor_proto` accepts \"values\" of a python scalar, a python list, a\n",
      "        numpy ndarray, or a numpy scalar.\n",
      "        \n",
      "        If \"values\" is a python scalar or a python list, make_tensor_proto\n",
      "        first convert it to numpy ndarray. If dtype is None, the\n",
      "        conversion tries its best to infer the right numpy data\n",
      "        type. Otherwise, the resulting numpy array has a compatible data\n",
      "        type with the given dtype.\n",
      "        \n",
      "        In either case above, the numpy ndarray (either the caller provided\n",
      "        or the auto-converted) must have the compatible type with dtype.\n",
      "        \n",
      "        `make_tensor_proto` then converts the numpy array to a tensor proto.\n",
      "        \n",
      "        If \"shape\" is None, the resulting tensor proto represents the numpy\n",
      "        array precisely.\n",
      "        \n",
      "        Otherwise, \"shape\" specifies the tensor's shape and the numpy array\n",
      "        can not have more elements than what \"shape\" specifies.\n",
      "        \n",
      "        Args:\n",
      "          values:         Values to put in the TensorProto.\n",
      "          dtype:          Optional tensor_pb2 DataType value.\n",
      "          shape:          List of integers representing the dimensions of tensor.\n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "          allow_broadcast:  Boolean that enables allowing scalars and 1 length vector\n",
      "              broadcasting. Cannot be true when verify_shape is true.\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorProto`. Depending on the type, it may contain data in the\n",
      "          \"tensor_content\" attribute, which is not directly useful to Python programs.\n",
      "          To access the values you should convert the proto back to a numpy ndarray\n",
      "          with `tf.make_ndarray(proto)`.\n",
      "        \n",
      "          If `values` is a `TensorProto`, it is immediately returned; `dtype` and\n",
      "          `shape` are ignored.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  if unsupported types are provided.\n",
      "          ValueError: if arguments have inappropriate values or if verify_shape is\n",
      "           True and shape of values is not equals to a shape from the argument.\n",
      "    \n",
      "    map_fn = map_fn_v2(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None, fn_output_signature=None)\n",
      "        Transforms `elems` by applying `fn` to each element unstacked on axis 0. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use fn_output_signature instead\n",
      "        \n",
      "        See also `tf.scan`.\n",
      "        \n",
      "        `map_fn` unstacks `elems` on axis 0 to obtain a sequence of elements;\n",
      "        calls `fn` to transform each element; and then stacks the transformed\n",
      "        values back together.\n",
      "        \n",
      "        #### Mapping functions with single-Tensor inputs and outputs\n",
      "        \n",
      "        If `elems` is a single tensor and `fn`'s signature is `tf.Tensor->tf.Tensor`,\n",
      "        then `map_fn(fn, elems)` is equivalent to\n",
      "        `tf.stack([fn(elem) for elem in tf.unstack(elems)])`.  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=lambda t: tf.range(t, t + 3), elems=tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        `map_fn(fn, elems).shape = [elems.shape[0]] + fn(elems[0]).shape`.\n",
      "        \n",
      "        #### Mapping functions with multi-arity inputs and outputs\n",
      "        \n",
      "        `map_fn` also supports functions with multi-arity inputs and outputs:\n",
      "        \n",
      "        * If `elems` is a tuple (or nested structure) of tensors, then those tensors\n",
      "          must all have the same outer-dimension size (`num_elems`); and `fn` is\n",
      "          used to transform each tuple (or structure) of corresponding slices from\n",
      "          `elems`.  E.g., if `elems` is a tuple `(t1, t2, t3)`, then `fn` is used to\n",
      "          transform each tuple of slices `(t1[i], t2[i], t3[i])`\n",
      "          (where `0 <= i < num_elems`).\n",
      "        \n",
      "        * If `fn` returns a tuple (or nested structure) of tensors, then the\n",
      "          result is formed by stacking corresponding elements from those structures.\n",
      "        \n",
      "        #### Specifying `fn`'s output signature\n",
      "        \n",
      "        If `fn`'s input and output signatures are different, then the output\n",
      "        signature must be specified using `fn_output_signature`.  (The input and\n",
      "        output signatures are differ if their structures, dtypes, or tensor types do\n",
      "        not match).  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=tf.strings.length,  # input & output have different dtypes\n",
      "        ...           elems=tf.constant([\"hello\", \"moon\"]),\n",
      "        ...           fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 4], dtype=int32)>\n",
      "        >>> tf.map_fn(fn=tf.strings.join,  # input & output have different structures\n",
      "        ...           elems=[tf.constant(['The', 'A']), tf.constant(['Dog', 'Cat'])],\n",
      "        ...           fn_output_signature=tf.string)\n",
      "        <tf.Tensor: shape=(2,), dtype=string,\n",
      "         numpy=array([b'TheDog', b'ACat'], dtype=object)>\n",
      "        \n",
      "        `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "        * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "        * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "        * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "        * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        #### RaggedTensors\n",
      "        \n",
      "        `map_fn` supports `tf.RaggedTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `RaggedTensor`, then `fn` will be called with each\n",
      "          row of that ragged tensor.\n",
      "          * If `elems` has only one ragged dimension, then the values passed to\n",
      "            `fn` will be `tf.Tensor`s.\n",
      "          * If `elems` has multiple ragged dimensions, then the values passed to\n",
      "            `fn` will be `tf.RaggedTensor`s with one fewer ragged dimension.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `RaggedTensor`, then use a\n",
      "          `tf.RaggedTensorSpec` to specify `fn_output_signature`.\n",
      "          * If `fn` returns `tf.Tensor`s with varying sizes, then use a\n",
      "            `tf.RaggedTensorSpec` with `ragged_rank=0` to combine them into a\n",
      "            single ragged tensor (which will have ragged_rank=1).\n",
      "          * If `fn` returns `tf.RaggedTensor`s, then use a `tf.RaggedTensorSpec`\n",
      "            with the same `ragged_rank`.\n",
      "        \n",
      "        >>> # Example: RaggedTensor input\n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.map_fn(tf.reduce_sum, rt, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([6, 0, 9, 6], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: RaggedTensor output\n",
      "        >>> elems = tf.constant([3, 5, 0, 2])\n",
      "        >>> tf.map_fn(tf.range, elems,\n",
      "        ...           fn_output_signature=tf.RaggedTensorSpec(shape=[None],\n",
      "        ...                                                   dtype=tf.int32))\n",
      "        <tf.RaggedTensor [[0, 1, 2], [0, 1, 2, 3, 4], [], [0, 1]]>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `RaggedTensor`.  If you wish to map a function over the\n",
      "        individual values, then you should use:\n",
      "        \n",
      "        * `tf.ragged.map_flat_values(fn, rt)`\n",
      "          (if fn is expressible as TensorFlow ops)\n",
      "        * `rt.with_flat_values(map_fn(fn, rt.flat_values))`\n",
      "          (otherwise)\n",
      "        \n",
      "        E.g.:\n",
      "        \n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.ragged.map_flat_values(lambda x: x + 2, rt)\n",
      "        <tf.RaggedTensor [[3, 4, 5], [], [6, 7], [8]]>\n",
      "        \n",
      "        #### SparseTensors\n",
      "        \n",
      "        `map_fn` supports `tf.sparse.SparseTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `SparseTensor`, then `fn` will be called with each row\n",
      "          of that sparse tensor. In particular, the value passed to `fn` will be a\n",
      "          `tf.sparse.SparseTensor` with one fewer dimension than `elems`.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `SparseTensor`, then use a\n",
      "          `tf.SparseTensorSpec` to specify `fn_output_signature`.  The individual\n",
      "          `SparseTensor`s returned by `fn` will be stacked into a single\n",
      "          `SparseTensor` with one more dimension.\n",
      "        \n",
      "        >>> # Example: SparseTensor input\n",
      "        >>> st = tf.sparse.SparseTensor([[0, 0], [2, 0], [2, 1]], [2, 3, 4], [4, 4])\n",
      "        >>> tf.map_fn(tf.sparse.reduce_sum, st, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 0, 7, 0], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: SparseTensor output\n",
      "        >>> tf.sparse.to_dense(\n",
      "        ...     tf.map_fn(tf.sparse.eye, tf.constant([2, 3]),\n",
      "        ...               fn_output_signature=tf.SparseTensorSpec(None, tf.float32)))\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
      "          array([[[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 0.]],\n",
      "                 [[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 1.]]], dtype=float32)>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `SparseTensor`.  If you wish to map a function over the nonzero\n",
      "        values, then you should use:\n",
      "        \n",
      "        * If the function is expressible as TensorFlow ops, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, fn(st.values), st.dense_shape)\n",
      "          ```\n",
      "        * Otherwise, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, tf.map_fn(fn, st.values),\n",
      "                                 st.dense_shape)\n",
      "          ```\n",
      "        \n",
      "        #### `map_fn` vs. vectorized operations\n",
      "        \n",
      "        `map_fn` will apply the operations used by `fn` to each element of `elems`,\n",
      "        resulting in `O(elems.shape[0])` total operations.  This is somewhat\n",
      "        mitigated by the fact that `map_fn` can process elements in parallel.\n",
      "        However, a transform expressed using `map_fn` is still typically less\n",
      "        efficient than an equivalent transform expressed using vectorized operations.\n",
      "        \n",
      "        `map_fn` should typically only be used if one of the following is true:\n",
      "        \n",
      "        * It is difficult or expensive to express the desired transform with\n",
      "          vectorized operations.\n",
      "        * `fn` creates large intermediate values, so an equivalent vectorized\n",
      "          transform would take too much memory.\n",
      "        * Processing elements in parallel is more efficient than an equivalent\n",
      "          vectorized transform.\n",
      "        * Efficiency of the transform is not critical, and using `map_fn` is\n",
      "          more readable.\n",
      "        \n",
      "        E.g., the example given above that maps `fn=lambda t: tf.range(t, t + 3)`\n",
      "        across `elems` could be rewritten more efficiently using vectorized ops:\n",
      "        \n",
      "        >>> elems = tf.constant([3, 5, 2])\n",
      "        >>> tf.range(3) + tf.expand_dims(elems, 1)\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        In some cases, `tf.vectorized_map` can be used to automatically convert a\n",
      "        function to a vectorized equivalent.\n",
      "        \n",
      "        #### Eager execution\n",
      "        \n",
      "        When executing eagerly, `map_fn` does not execute in parallel even if\n",
      "        `parallel_iterations` is set to a value > 1. You can still get the\n",
      "        performance benefits of running a function in parallel by using the\n",
      "        `tf.function` decorator:\n",
      "        \n",
      "        >>> fn=lambda t: tf.range(t, t + 3)\n",
      "        >>> @tf.function\n",
      "        ... def func(elems):\n",
      "        ...   return tf.map_fn(fn, elems, parallel_iterations=3)\n",
      "        >>> func(tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        Note: if you use the `tf.function` decorator, any non-TensorFlow Python\n",
      "        code that you may have written in your function won't get executed. See\n",
      "        `tf.function` for more  details. The recommendation would be to debug without\n",
      "        `tf.function` but switch to it to get performance benefits of running `map_fn`\n",
      "        in parallel.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`.  Its output must have the\n",
      "            same structure as `fn_output_signature` if one is provided; otherwise it\n",
      "            must have the same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unstacked along their first dimension.  `fn` will be applied to the\n",
      "            nested sequence of the resulting slices.  `elems` may include ragged and\n",
      "            sparse tensors. `elems` must consist of at least one tensor.\n",
      "          dtype: Deprecated: Equivalent to `fn_output_signature`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel. When graph building, the default value is 10. While executing\n",
      "            eagerly, the default value is set to 1.\n",
      "          back_prop: (optional) Deprecated: prefer using `tf.stop_gradient` instead.  False disables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "          fn_output_signature: The output signature of `fn`. Must be specified if\n",
      "            `fn`'s input and output signatures are different (i.e., if their\n",
      "            structures, dtypes, or tensor types do not match).\n",
      "            `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "            * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "            * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "            * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "            * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor stacks the\n",
      "          results of applying `fn` to tensors unstacked from `elems` along the first\n",
      "          dimension, from first to last.  The result may include ragged and sparse\n",
      "          tensors.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `fn_output_signature` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `fn_output_signature`\n",
      "            do not match, or if the `elems` does not contain any tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          >>> tf.map_fn(lambda x: x * x, elems)\n",
      "          <tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36])>\n",
      "        \n",
      "          >>> elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
      "          >>> tf.map_fn(lambda x: x[0] * x[1], elems, fn_output_signature=tf.int64)\n",
      "          <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1,  2, -3])>\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3])\n",
      "          >>> tf.map_fn(lambda x: (x, -x), elems,\n",
      "          ...          fn_output_signature=(tf.int64, tf.int64))\n",
      "          (<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>,\n",
      "           <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1, -2, -3])>)\n",
      "    \n",
      "    matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, output_type=None, name=None)\n",
      "        Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "        \n",
      "        The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "        where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "        and any further outer dimensions specify matching batch size.\n",
      "        \n",
      "        Both matrices must be of the same type. The supported types are:\n",
      "        `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "        `complex64`, `complex128`.\n",
      "        \n",
      "        Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "        the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "        by default.\n",
      "        \n",
      "        If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "        multiplication algorithm can be used by setting the corresponding\n",
      "        `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "        This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "        datatypes `bfloat16` or `float32`.\n",
      "        \n",
      "        A simple 2-D tensor matrix multiplication:\n",
      "        \n",
      "        >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "        >>> a  # 2-D tensor\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "        >>> b  # 2-D tensor\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[ 7,  8],\n",
      "               [ 9, 10],\n",
      "               [11, 12]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[ 58,  64],\n",
      "               [139, 154]], dtype=int32)>\n",
      "        \n",
      "        A batch matrix multiplication with batch shape [2]:\n",
      "        \n",
      "        >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "        >>> a  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "        array([[[ 1,  2,  3],\n",
      "                [ 4,  5,  6]],\n",
      "               [[ 7,  8,  9],\n",
      "                [10, 11, 12]]], dtype=int32)>\n",
      "        >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "        >>> b  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "        array([[[13, 14],\n",
      "                [15, 16],\n",
      "                [17, 18]],\n",
      "               [[19, 20],\n",
      "                [21, 22],\n",
      "                [23, 24]]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "        array([[[ 94, 100],\n",
      "                [229, 244]],\n",
      "               [[508, 532],\n",
      "                [697, 730]]], dtype=int32)>\n",
      "        \n",
      "        Since python >= 3.5 the @ operator is supported\n",
      "        (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "        it simply calls the `tf.matmul()` function, so the following lines are\n",
      "        equivalent:\n",
      "        \n",
      "        >>> d = a @ b @ [[10], [11]]\n",
      "        >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "        \n",
      "        Args:\n",
      "          a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "            `complex64`, `complex128` and rank > 1.\n",
      "          b: `tf.Tensor` with same type and rank as `a`.\n",
      "          transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "          transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "          adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `a` are zero.\n",
      "            See `tf.sparse.sparse_dense_matmul`\n",
      "            for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "          b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `b` are zero.\n",
      "            See `tf.sparse.sparse_dense_matmul`\n",
      "            for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "          output_type: The output datatype if needed. Defaults to None in which case\n",
      "            the output_type is the same as input type. Currently only works when input\n",
      "            tensors are type (u)int8 and output_type can be int32.\n",
      "          name: Name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "          is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "          transpose or adjoint attributes are `False`:\n",
      "        \n",
      "          `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "          for all indices `i`, `j`.\n",
      "        \n",
      "          Note: This is matrix product, not element-wise product.\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "            `adjoint_b` are both set to `True`.\n",
      "          TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "            `output_type` is not (u)int8, (u)int8 and int32.\n",
      "    \n",
      "    matrix_square_root(input, name=None)\n",
      "        Computes the matrix square root of one or more square matrices:\n",
      "        \n",
      "        matmul(sqrtm(A), sqrtm(A)) = A\n",
      "        \n",
      "        \n",
      "        \n",
      "        The input matrix should be invertible. If the input matrix is real, it should\n",
      "        \n",
      "        have no eigenvalues which are real and negative (pairs of complex conjugate\n",
      "        \n",
      "        eigenvalues are allowed).\n",
      "        \n",
      "        \n",
      "        \n",
      "        The matrix square root is computed by first reducing the matrix to\n",
      "        \n",
      "        quasi-triangular form with the real Schur decomposition. The square root\n",
      "        \n",
      "        of the quasi-triangular matrix is then computed directly. Details of\n",
      "        \n",
      "        the algorithm can be found in: Nicholas J. Higham, \"Computing real\n",
      "        \n",
      "        square roots of a real matrix\", Linear Algebra Appl., 1987.\n",
      "        \n",
      "        \n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        \n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        \n",
      "        containing the matrix square root for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    maximum(x, y, name=None)\n",
      "        Returns the max of x and y (i.e. x > y ? x : y) element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        \n",
      "        >>> y = tf.constant([-2., 0., 2., 5.])\n",
      "        \n",
      "        >>> tf.math.maximum(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 2., 5.], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note that `maximum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        \n",
      "        >>> y = tf.constant([-3.])\n",
      "        \n",
      "        >>> tf.math.maximum(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-3., 0., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_max`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    meshgrid(*args, **kwargs)\n",
      "        Broadcasts parameters for evaluation on an N-D grid.\n",
      "        \n",
      "        Given N one-dimensional coordinate arrays `*args`, returns a list `outputs`\n",
      "        of N-D coordinate arrays for evaluating expressions on an N-D grid.\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        `meshgrid` supports cartesian ('xy') and matrix ('ij') indexing conventions.\n",
      "        When the `indexing` argument is set to 'xy' (the default), the broadcasting\n",
      "        instructions for the first two dimensions are swapped.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        Calling `X, Y = meshgrid(x, y)` with the tensors\n",
      "        \n",
      "        ```python\n",
      "        x = [1, 2, 3]\n",
      "        y = [4, 5, 6]\n",
      "        X, Y = tf.meshgrid(x, y)\n",
      "        # X = [[1, 2, 3],\n",
      "        #      [1, 2, 3],\n",
      "        #      [1, 2, 3]]\n",
      "        # Y = [[4, 4, 4],\n",
      "        #      [5, 5, 5],\n",
      "        #      [6, 6, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          *args: `Tensor`s with rank 1.\n",
      "          **kwargs:\n",
      "            - indexing: Either 'xy' or 'ij' (optional, default: 'xy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          outputs: A list of N `Tensor`s with rank N.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: When no keyword arguments (kwargs) are passed.\n",
      "          ValueError: When indexing keyword argument is not one of `xy` or `ij`.\n",
      "    \n",
      "    minimum(x, y, name=None)\n",
      "        Returns the min of x and y (i.e. x < y ? x : y) element-wise.\n",
      "        \n",
      "        Both inputs are number-type tensors (except complex).  `minimum` expects that\n",
      "        \n",
      "        both tensors have the same `dtype`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        \n",
      "        >>> y = tf.constant([-5., -2., 0., 3.])\n",
      "        \n",
      "        >>> tf.math.minimum(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -2., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note that `minimum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        \n",
      "        >>> y = tf.constant([-3.])\n",
      "        \n",
      "        >>> tf.math.minimum(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -3., -3., -3.], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_min`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    multiply(x, y, name=None)\n",
      "        Returns an element-wise x * y.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "        >>> tf.math.multiply(x, x)\n",
      "        <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "        \n",
      "        Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "        pass in non-`Tensor` arguments:\n",
      "        \n",
      "        >>> tf.math.multiply(7,6)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "        \n",
      "        If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "        compatible shape. (More about broadcasting\n",
      "        [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.ones([1, 2]);\n",
      "        >>> y = tf.ones([2, 1]);\n",
      "        >>> x * y  # Taking advantage of operator overriding\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[1., 1.],\n",
      "             [1., 1.]], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "            `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "            `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "        A `Tensor`.  Has the same type as `x`.\n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "         * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "    \n",
      "    negative = neg(x, name=None)\n",
      "        Computes numerical negative value element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = -x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    no_gradient(op_type)\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    no_op(name=None)\n",
      "        Does nothing. Only useful as a placeholder for control edges.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    nondifferentiable_batch_function = batch_function(num_batch_threads, max_batch_size, batch_timeout_micros, allowed_batch_sizes=None, max_enqueued_batches=10, autograph=True, enable_large_batch_splitting=True)\n",
      "        Batches the computation done by the decorated function.\n",
      "        \n",
      "        So, for example, in the following code\n",
      "        \n",
      "        ```python\n",
      "        @batch_function(1, 2, 3)\n",
      "        def layer(a):\n",
      "          return tf.matmul(a, a)\n",
      "        \n",
      "        b = layer(w)\n",
      "        ```\n",
      "        \n",
      "        if more than one session.run call is simultaneously trying to compute `b`\n",
      "        the values of `w` will be gathered, non-deterministically concatenated\n",
      "        along the first axis, and only one thread will run the computation. See the\n",
      "        documentation of the `Batch` op for more details.\n",
      "        \n",
      "        Assumes that all arguments of the decorated function are Tensors which will\n",
      "        be batched along their first dimension.\n",
      "        \n",
      "        SparseTensor is not supported. The return value of the decorated function\n",
      "        must be a Tensor or a list/tuple of Tensors.\n",
      "        \n",
      "        Args:\n",
      "          num_batch_threads: Number of scheduling threads for processing batches\n",
      "           of work. Determines the number of batches processed in parallel.\n",
      "          max_batch_size: Batch sizes will never be bigger than this.\n",
      "          batch_timeout_micros: Maximum number of microseconds to wait before\n",
      "           outputting an incomplete batch.\n",
      "          allowed_batch_sizes: Optional list of allowed batch sizes. If left empty,\n",
      "           does nothing. Otherwise, supplies a list of batch sizes, causing the op\n",
      "           to pad batches up to one of those sizes. The entries must increase\n",
      "           monotonically, and the final entry must equal max_batch_size.\n",
      "          max_enqueued_batches: The maximum depth of the batch queue. Defaults to 10.\n",
      "          autograph: Whether to use autograph to compile python and eager style code\n",
      "           for efficient graph-mode execution.\n",
      "          enable_large_batch_splitting: The value of this option doesn't affect\n",
      "           processing output given the same input; it affects implementation details\n",
      "           as stated below: 1. Improve batching efficiency by eliminating unnecessary\n",
      "           adding. 2.`max_batch_size` specifies the limit of input and\n",
      "           `allowed_batch_sizes` specifies the limit of a task to be processed. API\n",
      "           user can give an input of size 128 when 'max_execution_batch_size'\n",
      "           is 32 -> implementation can split input of 128 into 4 x 32, schedule\n",
      "           concurrent processing, and then return concatenated results corresponding\n",
      "           to 128.\n",
      "        \n",
      "        Returns:\n",
      "          The decorated function will return the unbatched computation output Tensors.\n",
      "    \n",
      "    norm = norm_v2(tensor, ord='euclidean', axis=None, keepdims=None, name=None)\n",
      "        Computes the norm of vectors, matrices, and tensors.\n",
      "        \n",
      "        This function can compute several different vector norms (the 1-norm, the\n",
      "        Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and\n",
      "        matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of types `float32`, `float64`, `complex64`, `complex128`\n",
      "          ord: Order of the norm. Supported values are `'fro'`, `'euclidean'`,\n",
      "            `1`, `2`, `np.inf` and any positive real number yielding the corresponding\n",
      "            p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if\n",
      "            `tensor` is a matrix and equivalent to 2-norm for vectors.\n",
      "            Some restrictions apply:\n",
      "              a) The Frobenius norm `'fro'` is not defined for vectors,\n",
      "              b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,\n",
      "                 `2`, `np.inf` are supported.\n",
      "            See the description of `axis` on how to compute norms for a batch of\n",
      "            vectors or matrices stored in a tensor.\n",
      "          axis: If `axis` is `None` (the default), the input is considered a vector\n",
      "            and a single vector norm is computed over the entire set of values in the\n",
      "            tensor, i.e. `norm(tensor, ord=ord)` is equivalent to\n",
      "            `norm(reshape(tensor, [-1]), ord=ord)`.\n",
      "            If `axis` is a Python integer, the input is considered a batch of vectors,\n",
      "            and `axis` determines the axis in `tensor` over which to compute vector\n",
      "            norms.\n",
      "            If `axis` is a 2-tuple of Python integers it is considered a batch of\n",
      "            matrices and `axis` determines the axes in `tensor` over which to compute\n",
      "            a matrix norm.\n",
      "            Negative indices are supported. Example: If you are passing a tensor that\n",
      "            can be either a matrix or a batch of matrices at runtime, pass\n",
      "            `axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are\n",
      "            computed.\n",
      "          keepdims: If True, the axis indicated in `axis` are kept with size 1.\n",
      "            Otherwise, the dimensions in `axis` are removed from the output shape.\n",
      "          name: The name of the op.\n",
      "        \n",
      "        Returns:\n",
      "          output: A `Tensor` of the same type as tensor, containing the vector or\n",
      "            matrix norms. If `keepdims` is True then the rank of output is equal to\n",
      "            the rank of `tensor`. Otherwise, if `axis` is none the output is a scalar,\n",
      "            if `axis` is an integer, the rank of `output` is one less than the rank\n",
      "            of `tensor`, if `axis` is a 2-tuple the rank of `output` is two less\n",
      "            than the rank of `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `ord` or `axis` is invalid.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.norm.\n",
      "        Not supported: ord <= 0, 2-norm for matrices, nuclear norm.\n",
      "        Other differences:\n",
      "          a) If axis is `None`, treats the flattened `tensor` as a vector\n",
      "           regardless of rank.\n",
      "          b) Explicitly supports 'euclidean' norm as the default, including for\n",
      "           higher order tensors.\n",
      "        @end_compatibility\n",
      "    \n",
      "    not_equal(x, y, name=None)\n",
      "        Returns the truth value of (x != y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise inequality comparison, returning a Tensor\n",
      "        of boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  False])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    numpy_function(func, inp, Tout, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func` wrap this function as an operation in a\n",
      "        TensorFlow function. `func` must take numpy arrays as its arguments and\n",
      "        return numpy arrays as its outputs.\n",
      "        \n",
      "        The following example creates a TensorFlow graph with `np.sinh()` as an\n",
      "        operation in the graph:\n",
      "        \n",
      "        >>> def my_numpy_func(x):\n",
      "        ...   # x will be a numpy array with the contents of the input to the\n",
      "        ...   # tf.function\n",
      "        ...   return np.sinh(x)\n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
      "        ... def tf_function(input):\n",
      "        ...   y = tf.numpy_function(my_numpy_func, [input], tf.float32)\n",
      "        ...   return y * y\n",
      "        >>> tf_function(tf.constant(1.))\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.3810978>\n",
      "        \n",
      "        Comparison to `tf.py_function`:\n",
      "        `tf.py_function` and `tf.numpy_function` are very similar, except that\n",
      "        `tf.numpy_function` takes numpy arrays, and not `tf.Tensor`s. If you want the\n",
      "        function to contain `tf.Tensors`, and have any TensorFlow operations executed\n",
      "        in the function be differentiable, please use `tf.py_function`.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.numpy_function` outside of\n",
      "        prototyping and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.numpy_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program. Therefore, you are discouraged to use `tf.numpy_function` outside\n",
      "          of prototyping and experimentation.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `tf.SavedModel`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.numpy_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.numpy_function`  you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.numpy_function` is not compatible with XLA. Calling\n",
      "          `tf.numpy_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        * Since the function takes numpy arrays, you cannot take gradients\n",
      "          through a numpy_function. If you require something that is differentiable,\n",
      "          please consider using tf.py_function.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `numpy.ndarray` objects as arguments\n",
      "            and returns a list of `numpy.ndarray` objects (or a single\n",
      "            `numpy.ndarray`). This function must accept as many arguments as there are\n",
      "            tensors in `inp`, and these argument types will match the corresponding\n",
      "            `tf.Tensor` objects in `inp`. The returns `numpy.ndarray`s must match the\n",
      "            number and types defined `Tout`.\n",
      "            Important Note: Input and output `numpy.ndarray`s of `func` are not\n",
      "              guaranteed to be copies. In some cases their underlying memory will be\n",
      "              shared with the corresponding TensorFlow tensors. In-place modification\n",
      "              or storing `func` input or return values in python datastructures\n",
      "              without explicit (np.)copy can have non-deterministic consequences.\n",
      "          inp: A list of `tf.Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) Setting this argument to False tells the runtime to\n",
      "            treat the function as stateless, which enables certain optimizations.\n",
      "            A function is stateless when given the same input it will return the\n",
      "            same output and have no side effects; its only purpose is to have a\n",
      "            return value.\n",
      "            The behavior for a stateful function with the `stateful` argument False\n",
      "            is undefined. In particular, caution should be taken when\n",
      "            mutating the input arguments as this is a stateful operation.\n",
      "          name: (Optional) A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          Single or list of `tf.Tensor` which `func` computes.\n",
      "    \n",
      "    one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
      "        Returns a one-hot tensor.\n",
      "        \n",
      "        See also `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        The locations represented by indices in `indices` take value `on_value`,\n",
      "        while all other locations take value `off_value`.\n",
      "        \n",
      "        `on_value` and `off_value` must have matching data types. If `dtype` is also\n",
      "        provided, they must be the same data type as specified by `dtype`.\n",
      "        \n",
      "        If `on_value` is not provided, it will default to the value `1` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If `off_value` is not provided, it will default to the value `0` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If the input `indices` is rank `N`, the output will have rank `N+1`. The\n",
      "        new axis is created at dimension `axis` (default: the new axis is appended\n",
      "        at the end).\n",
      "        \n",
      "        If `indices` is a scalar the output shape will be a vector of length `depth`\n",
      "        \n",
      "        If `indices` is a vector of length `features`, the output shape will be:\n",
      "        \n",
      "        ```\n",
      "          features x depth if axis == -1\n",
      "          depth x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a matrix (batch) with shape `[batch, features]`, the output\n",
      "        shape will be:\n",
      "        \n",
      "        ```\n",
      "          batch x features x depth if axis == -1\n",
      "          batch x depth x features if axis == 1\n",
      "          depth x batch x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a RaggedTensor, the 'axis' argument must be positive and refer\n",
      "        to a non-ragged axis. The output will be equivalent to applying 'one_hot' on\n",
      "        the values of the RaggedTensor, and creating a new RaggedTensor from the\n",
      "        result.\n",
      "        \n",
      "        If `dtype` is not provided, it will attempt to assume the data type of\n",
      "        `on_value` or `off_value`, if one or both are passed in. If none of\n",
      "        `on_value`, `off_value`, or `dtype` are provided, `dtype` will default to the\n",
      "        value `tf.float32`.\n",
      "        \n",
      "        Note: If a non-numeric data type output is desired (`tf.string`, `tf.bool`,\n",
      "        etc.), both `on_value` and `off_value` _must_ be provided to `one_hot`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        indices = [0, 1, 2]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [3 x 3]\n",
      "        # [[1., 0., 0.],\n",
      "        #  [0., 1., 0.],\n",
      "        #  [0., 0., 1.]]\n",
      "        \n",
      "        indices = [0, 2, -1, 1]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=5.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [4 x 3]\n",
      "        # [[5.0, 0.0, 0.0],  # one_hot(0)\n",
      "        #  [0.0, 0.0, 5.0],  # one_hot(2)\n",
      "        #  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
      "        #  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
      "        \n",
      "        indices = [[0, 2], [1, -1]]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=1.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [2 x 2 x 3]\n",
      "        # [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
      "        #   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
      "        #  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
      "        #   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
      "        \n",
      "        indices = tf.ragged.constant([[0, 1], [2]])\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [2 x None x 3]\n",
      "        # [[[1., 0., 0.],\n",
      "        #   [0., 1., 0.]],\n",
      "        #  [[0., 0., 1.]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor` of indices.\n",
      "          depth: A scalar defining the depth of the one hot dimension.\n",
      "          on_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            = i`. (default: 1)\n",
      "          off_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            != i`. (default: 0)\n",
      "          axis: The axis to fill (default: -1, a new inner-most axis).\n",
      "          dtype: The data type of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: The one-hot tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If dtype of either `on_value` or `off_value` don't match `dtype`\n",
      "          TypeError: If dtype of `on_value` and `off_value` don't match one another\n",
      "    \n",
      "    ones(shape, dtype=tf.float32, name=None)\n",
      "        Creates a tensor with all elements set to one (1).\n",
      "        \n",
      "        See also `tf.ones_like`, `tf.zeros`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to one.\n",
      "        \n",
      "        >>> tf.ones([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[1, 1, 1, 1],\n",
      "               [1, 1, 1, 1],\n",
      "               [1, 1, 1, 1]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or\n",
      "            a 1-D `Tensor` of type `int32`.\n",
      "          dtype: Optional DType of an element in the resulting `Tensor`. Default is\n",
      "            `tf.float32`.\n",
      "          name: Optional string. A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to one (1).\n",
      "    \n",
      "    ones_like = ones_like_v2(input, dtype=None, name=None)\n",
      "        Creates a tensor of all ones that has the same shape as the input.\n",
      "        \n",
      "        See also `tf.ones`.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the\n",
      "        same type and shape as `tensor` with all elements set to 1. Optionally,\n",
      "        you can use `dtype` to specify a new type for the returned tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        >>> tf.ones_like(tensor)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[1, 1, 1],\n",
      "                 [1, 1, 1]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float16`, `float32`,\n",
      "            `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,\n",
      "            `complex64`, `complex128`, `bool` or `string`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to one.\n",
      "    \n",
      "    pad = pad_v2(tensor, paddings, mode='CONSTANT', constant_values=0, name=None)\n",
      "        Pads a tensor.\n",
      "        \n",
      "        This operation pads a `tensor` according to the `paddings` you specify.\n",
      "        `paddings` is an integer tensor with shape `[n, 2]`, where n is the rank of\n",
      "        `tensor`. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
      "        many values to add before the contents of `tensor` in that dimension, and\n",
      "        `paddings[D, 1]` indicates how many values to add after the contents of\n",
      "        `tensor` in that dimension. If `mode` is \"REFLECT\" then both `paddings[D, 0]`\n",
      "        and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If\n",
      "        `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be\n",
      "        no greater than `tensor.dim_size(D)`.\n",
      "        \n",
      "        The padded size of each dimension D of the output is:\n",
      "        \n",
      "        `paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        paddings = tf.constant([[1, 1,], [2, 2]])\n",
      "        # 'constant_values' is 0.\n",
      "        # rank of 't' is 2.\n",
      "        tf.pad(t, paddings, \"CONSTANT\")  # [[0, 0, 0, 0, 0, 0, 0],\n",
      "                                         #  [0, 0, 1, 2, 3, 0, 0],\n",
      "                                         #  [0, 0, 4, 5, 6, 0, 0],\n",
      "                                         #  [0, 0, 0, 0, 0, 0, 0]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"REFLECT\")  # [[6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1],\n",
      "                                        #  [6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"SYMMETRIC\")  # [[2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          paddings: A `Tensor` of type `int32`.\n",
      "          mode: One of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\" (case-insensitive)\n",
      "          constant_values: In \"CONSTANT\" mode, the scalar pad value to use. Must be\n",
      "            same type as `tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "    \n",
      "    parallel_stack(values, name='parallel_stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor in parallel.\n",
      "        \n",
      "        Requires that the shape of inputs be known at graph construction time.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the first dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`; the `output`\n",
      "        tensor will have the shape `(N, A, B, C)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 4])\n",
      "        y = tf.constant([2, 5])\n",
      "        z = tf.constant([3, 6])\n",
      "        tf.parallel_stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]]\n",
      "        ```\n",
      "        \n",
      "        The difference between `stack` and `parallel_stack` is that `stack` requires\n",
      "        all the inputs be computed before the operation will begin but doesn't require\n",
      "        that the input shapes be known during graph construction.\n",
      "        \n",
      "        `parallel_stack` will copy pieces of the input into the output as they become\n",
      "        available, in some situations this can provide a performance benefit.\n",
      "        \n",
      "        Unlike `stack`, `parallel_stack` does NOT support backpropagation.\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is\n",
      "        \n",
      "            tf.parallel_stack([x, y, z]) = np.asarray([x, y, z])\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        parallel_stack is not compatible with eager execution.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if executed in eager mode.\n",
      "    \n",
      "    pow(x, y, name=None)\n",
      "        Computes the power of one value to another.\n",
      "        \n",
      "        Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "        corresponding elements in `x` and `y`. For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[2, 2], [3, 3]])\n",
      "        y = tf.constant([[8, 16], [2, 3]])\n",
      "        tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.\n",
      "    \n",
      "    print = print_v2(*inputs, **kwargs)\n",
      "        Print the specified inputs.\n",
      "        \n",
      "        A TensorFlow operator that prints the specified inputs to a desired\n",
      "        output stream or logging level. The inputs may be dense or sparse Tensors,\n",
      "        primitive python objects, data structures that contain tensors, and printable\n",
      "        Python objects. Printed tensors will recursively show the first and last\n",
      "        elements of each dimension to summarize.\n",
      "        \n",
      "        Example:\n",
      "          Single-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(tensor, output_stream=sys.stderr)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "          Multi-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(\"tensors:\", tensor, {2: tensor * 2}, output_stream=sys.stdout)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "          Changing the input separator:\n",
      "          ```python\n",
      "          tensor_a = tf.range(2)\n",
      "          tensor_b = tensor_a * 2\n",
      "          tf.print(tensor_a, tensor_b, output_stream=sys.stderr, sep=',')\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1],[0 2]\" to sys.stderr)\n",
      "        \n",
      "          Usage in a `tf.function`:\n",
      "        \n",
      "          ```python\n",
      "          @tf.function\n",
      "          def f():\n",
      "              tensor = tf.range(10)\n",
      "              tf.print(tensor, output_stream=sys.stderr)\n",
      "              return tensor\n",
      "        \n",
      "          range_tensor = f()\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "        *Compatibility usage in TF 1.x graphs*:\n",
      "        \n",
      "          In graphs manually created outside of `tf.function`, this method returns\n",
      "          the created TF operator that prints the data. To make sure the\n",
      "          operator runs, users need to pass the produced op to\n",
      "          `tf.compat.v1.Session`'s run method, or to use the op as a control\n",
      "          dependency for executed ops by specifying\n",
      "          `with tf.compat.v1.control_dependencies([print_op])`.\n",
      "        \n",
      "          ```python\n",
      "          tf.compat.v1.disable_v2_behavior()  # for TF1 compatibility only\n",
      "        \n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "            tensor = tf.range(10)\n",
      "            print_op = tf.print(\"tensors:\", tensor, {2: tensor * 2},\n",
      "                                output_stream=sys.stdout)\n",
      "            with tf.control_dependencies([print_op]):\n",
      "              tripled_tensor = tensor * 3\n",
      "        \n",
      "            sess.run(tripled_tensor)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "        Note: In Jupyter notebooks and colabs, `tf.print` prints to the notebook\n",
      "          cell outputs. It will not write to the notebook kernel's console logs.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Positional arguments that are the inputs to print. Inputs in the\n",
      "            printed output will be separated by spaces. Inputs may be python\n",
      "            primitives, tensors, data structures such as dicts and lists that may\n",
      "            contain tensors (with the data structures possibly nested in arbitrary\n",
      "            ways), and printable python objects.\n",
      "          output_stream: The output stream, logging level, or file to print to.\n",
      "            Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info,\n",
      "            tf.compat.v1.logging.warning, tf.compat.v1.logging.error,\n",
      "            absl.logging.info, absl.logging.warning and absl.logging.error are also\n",
      "            supported. To print to a file, pass a string started with \"file://\"\n",
      "            followed by the file path, e.g., \"file:///tmp/foo.out\".\n",
      "          summarize: The first and last `summarize` elements within each dimension are\n",
      "            recursively printed per Tensor. If None, then the first 3 and last 3\n",
      "            elements of each dimension are printed for each tensor. If set to -1, it\n",
      "            will print all elements of every tensor.\n",
      "          sep: The string to use to separate the inputs. Defaults to \" \".\n",
      "          end: End character that is appended at the end the printed string. Defaults\n",
      "            to the newline character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          None when executing eagerly. During graph tracing this returns\n",
      "          a TF operator that prints the specified inputs in the specified output\n",
      "          stream or logging level. This operator will be automatically executed\n",
      "          except inside of `tf.compat.v1` graphs and sessions.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unsupported output stream is specified.\n",
      "    \n",
      "    py_function = eager_py_func(func, inp, Tout, name=None)\n",
      "        Wraps a python function into a TensorFlow op that executes it eagerly.\n",
      "        \n",
      "        This function allows expressing computations in a TensorFlow graph as\n",
      "        Python functions. In particular, it wraps a Python function `func`\n",
      "        in a once-differentiable TensorFlow operation that executes it with eager\n",
      "        execution enabled. As a consequence, `tf.py_function` makes it\n",
      "        possible to express control flow using Python constructs (`if`, `while`,\n",
      "        `for`, etc.), instead of TensorFlow control flow constructs (`tf.cond`,\n",
      "        `tf.while_loop`). For example, you might use `tf.py_function` to\n",
      "        implement the log huber function:\n",
      "        \n",
      "        ```python\n",
      "        def log_huber(x, m):\n",
      "          if tf.abs(x) <= m:\n",
      "            return x**2\n",
      "          else:\n",
      "            return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        \n",
      "        x = tf.constant(1.0)\n",
      "        m = tf.constant(2.0)\n",
      "        \n",
      "        with tf.GradientTape() as t:\n",
      "          t.watch([x, m])\n",
      "          y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)\n",
      "        \n",
      "        dy_dx = t.gradient(y, x)\n",
      "        assert dy_dx.numpy() == 2.0\n",
      "        ```\n",
      "        \n",
      "        You can also use `tf.py_function` to debug your models at runtime\n",
      "        using Python tools, i.e., you can isolate portions of your code that\n",
      "        you want to debug, wrap them in Python functions and insert `pdb` tracepoints\n",
      "        or print statements as desired, and wrap those functions in\n",
      "        `tf.py_function`.\n",
      "        \n",
      "        For more information on eager execution, see the\n",
      "        [Eager guide](https://tensorflow.org/guide/eager).\n",
      "        \n",
      "        `tf.py_function` is similar in spirit to `tf.compat.v1.py_func`, but unlike\n",
      "        the latter, the former lets you use TensorFlow operations in the wrapped\n",
      "        Python function. In particular, while `tf.compat.v1.py_func` only runs on CPUs\n",
      "        and wraps functions that take NumPy arrays as inputs and return NumPy arrays\n",
      "        as outputs, `tf.py_function` can be placed on GPUs and wraps functions\n",
      "        that take Tensors as inputs, execute TensorFlow operations in their bodies,\n",
      "        and return Tensors as outputs.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.py_function` outside of prototyping\n",
      "        and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.py_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.py_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.py_function()` and you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.py_function` is not compatible with XLA. Calling\n",
      "          `tf.py_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function that accepts `inp` as arguments, and returns a\n",
      "            value (or list of values) whose type is described by `Tout`.\n",
      "        \n",
      "          inp: Input arguments for `func`.  A list whose elements are `Tensor`s or\n",
      "            `CompositeTensors` (such as `tf.RaggedTensor`); or a single `Tensor` or\n",
      "            `CompositeTensor`.\n",
      "        \n",
      "          Tout: The type(s) of the value(s) returned by `func`.  One of the\n",
      "            following.\n",
      "        \n",
      "            * If `func` returns a `Tensor` (or a value that can be converted to a\n",
      "              Tensor): the `tf.DType` for that value.\n",
      "            * If `func` returns a `CompositeTensor`: The `tf.TypeSpec` for that value.\n",
      "            * If `func` returns `None`: the empty list (`[]`).\n",
      "            * If `func` returns a list of `Tensor` and `CompositeTensor` values:\n",
      "              a corresponding list of `tf.DType`s and `tf.TypeSpec`s for each value.\n",
      "        \n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The value(s) computed by `func`: a `Tensor`, `CompositeTensor`, or list of\n",
      "          `Tensor` and `CompositeTensor`; or an empty list if `func` returns `None`.\n",
      "    \n",
      "    ragged_fill_empty_rows(value_rowids, values, nrows, default_value, name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          value_rowids: A `Tensor` of type `int64`.\n",
      "          values: A `Tensor`.\n",
      "          nrows: A `Tensor` of type `int64`.\n",
      "          default_value: A `Tensor`. Must have the same type as `values`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output_value_rowids, output_values, empty_row_indicator, reverse_index_map).\n",
      "        \n",
      "          output_value_rowids: A `Tensor` of type `int64`.\n",
      "          output_values: A `Tensor`. Has the same type as `values`.\n",
      "          empty_row_indicator: A `Tensor` of type `bool`.\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "    \n",
      "    ragged_fill_empty_rows_grad(reverse_index_map, grad_values, name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "          grad_values: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (d_values, d_default_value).\n",
      "        \n",
      "          d_values: A `Tensor`. Has the same type as `grad_values`.\n",
      "          d_default_value: A `Tensor`. Has the same type as `grad_values`.\n",
      "    \n",
      "    random_index_shuffle(index, seed, max_index, rounds=4, name=None)\n",
      "        Outputs the position of `value` in a permutation of [0, ..., max_index].\n",
      "        \n",
      "        Output values are a bijection of the `index` for any combination and `seed` and `max_index`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        If multiple inputs are vectors (matrix in case of seed) then the size of the\n",
      "        \n",
      "        first dimension must match.\n",
      "        \n",
      "        \n",
      "        \n",
      "        The outputs are deterministic.\n",
      "        \n",
      "        Args:\n",
      "          index: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A scalar tensor or a vector of dtype `dtype`. The index (or indices) to be shuffled. Must be within [0, max_index].\n",
      "          seed: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A tensor of dtype `Tseed` and shape [3] or [n, 3]. The random seed.\n",
      "          max_index: A `Tensor`. Must have the same type as `index`.\n",
      "            A scalar tensor or vector of dtype `dtype`. The upper bound(s) of the interval (inclusive).\n",
      "          rounds: An optional `int`. Defaults to `4`.\n",
      "            The number of rounds to use the in block cipher.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `index`.\n",
      "    \n",
      "    range(start, limit=None, delta=1, dtype=None, name='range')\n",
      "        Creates a sequence of numbers.\n",
      "        \n",
      "        Creates a sequence of numbers that begins at `start` and extends by\n",
      "        increments of `delta` up to but not including `limit`.\n",
      "        \n",
      "        The dtype of the resulting tensor is inferred from the inputs unless\n",
      "        it is provided explicitly.\n",
      "        \n",
      "        Like the Python builtin `range`, `start` defaults to 0, so that\n",
      "        `range(n) = range(0, n)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 18\n",
      "        >>> delta = 3\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 3,  6,  9, 12, 15], dtype=int32)>\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 1\n",
      "        >>> delta = -0.5\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([3. , 2.5, 2. , 1.5], dtype=float32)>\n",
      "        \n",
      "        >>> limit = 5\n",
      "        >>> tf.range(limit)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          start: A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`\n",
      "            is not None; otherwise, acts as range limit and first entry defaults to 0.\n",
      "          limit: A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None,\n",
      "            defaults to the value of `start` while the first entry of the range\n",
      "            defaults to 0.\n",
      "          delta: A 0-D `Tensor` (scalar). Number that increments `start`. Defaults to\n",
      "            1.\n",
      "          dtype: The type of the elements of the resulting tensor.\n",
      "          name: A name for the operation. Defaults to \"range\".\n",
      "        \n",
      "        Returns:\n",
      "          An 1-D `Tensor` of type `dtype`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.arange\n",
      "        @end_compatibility\n",
      "    \n",
      "    rank(input, name=None)\n",
      "        Returns the rank of a tensor.\n",
      "        \n",
      "        See also `tf.shape`.\n",
      "        \n",
      "        Returns a 0-D `int32` `Tensor` representing the rank of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # shape of tensor 't' is [2, 2, 3]\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.rank(t)  # 3\n",
      "        ```\n",
      "        \n",
      "        **Note**: The rank of a tensor is not the same as the rank of a matrix. The\n",
      "        rank of a tensor is the number of indices required to uniquely select each\n",
      "        element of the tensor. Rank is also known as \"order\", \"degree\", or \"ndims.\"\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ndim\n",
      "        @end_compatibility\n",
      "    \n",
      "    realdiv = real_div(x, y, name=None)\n",
      "        Returns x / y element-wise for real types.\n",
      "        \n",
      "        If `x` and `y` are reals, this will return the floating-point division.\n",
      "        \n",
      "        \n",
      "        \n",
      "        *NOTE*: `Div` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    recompute_grad(f)\n",
      "        Defines a function as a recompute-checkpoint for the tape auto-diff.\n",
      "        \n",
      "        Tape checkpointing is a technique to reduce the memory consumption of the\n",
      "        auto-diff tape:\n",
      "        \n",
      "        - Without tape checkpointing operations and intermediate values are\n",
      "        recorded to the tape for use in the backward pass.\n",
      "        \n",
      "        - With tape checkpointing, only the function call and its inputs are\n",
      "        recorded. During back-propagation the `recompute_grad` custom gradient\n",
      "        (`tf.custom_gradient`) recomputes the function under a localized Tape object.\n",
      "        This recomputation of the function during backpropagation performs redundant\n",
      "        calculation, but reduces the overall memory usage of the Tape.\n",
      "        \n",
      "        >>> y = tf.Variable(1.0)\n",
      "        \n",
      "        >>> def my_function(x):\n",
      "        ...   tf.print('running')\n",
      "        ...   z = x*y\n",
      "        ...   return z\n",
      "        \n",
      "        >>> my_function_recompute = tf.recompute_grad(my_function)\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Without `recompute_grad`, the tape contains all intermitate steps, and no\n",
      "        recomputation is performed.\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        \n",
      "        \n",
      "        If `f` was a `tf.keras` `Model` or `Layer` object, methods and attributes\n",
      "        such as `f.variables` are not available on the returned function `g`.\n",
      "        Either keep a reference of `f` , or use `g.__wrapped__` for accessing\n",
      "        these variables and methods.\n",
      "        \n",
      "        \n",
      "        >>> def print_running_and_return(x):\n",
      "        ...   tf.print(\"running\")\n",
      "        ...   return x\n",
      "        \n",
      "        >>> model = tf.keras.Sequential([\n",
      "        ...   tf.keras.layers.Lambda(print_running_and_return),\n",
      "        ...   tf.keras.layers.Dense(2)\n",
      "        ... ])\n",
      "        \n",
      "        >>> model_recompute = tf.recompute_grad(model)\n",
      "        \n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   r = tf.constant([[1,2]])\n",
      "        ...   for i in range(4):\n",
      "        ...     r = model_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Alternatively, use the `__wrapped__` attribute to access the original\n",
      "        model object.\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model_recompute.__wrapped__.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or sequence of `Tensor` outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `g` wrapping `f` that defines a custom gradient, which recomputes\n",
      "          `f` on the backwards pass of a gradient call.\n",
      "    \n",
      "    reduce_all(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes `tf.math.logical_and` of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_and` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.math.reduce_all(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "          >>> tf.math.reduce_all(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False, False])>\n",
      "          >>> tf.math.reduce_all(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.all\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_any(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes `tf.math.logical_or` of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_or` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.reduce_any(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "          >>> tf.reduce_any(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "          >>> tf.reduce_any(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.any\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_logsumexp(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes log(sum(exp(elements across dimensions of a tensor))).\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        This function is more numerically stable than log(sum(exp(input))). It avoids\n",
      "        overflows caused by taking the exp of large inputs and underflows caused by\n",
      "        taking the log of small inputs.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0., 0., 0.], [0., 0., 0.]])\n",
      "        tf.reduce_logsumexp(x)  # log(6)\n",
      "        tf.reduce_logsumexp(x, 0)  # [log(2), log(2), log(2)]\n",
      "        tf.reduce_logsumexp(x, 1)  # [log(3), log(3)]\n",
      "        tf.reduce_logsumexp(x, 1, keepdims=True)  # [[log(3)], [log(3)]]\n",
      "        tf.reduce_logsumexp(x, [0, 1])  # log(6)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_max(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes `tf.math.maximum` of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.maximum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Usage example:\n",
      "        \n",
      "          >>> x = tf.constant([5, 1, 2, 4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "          >>> x = tf.constant([-5, -1, -2, -4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=-1>\n",
      "          >>> x = tf.constant([4, float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('nan'), float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('-inf'), float('inf')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
      "        \n",
      "        See the numpy docs for `np.amax` and `np.nanmax` behavior.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_mean(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes the mean of elements across dimensions of a tensor.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis` by computing the\n",
      "        mean of elements across the dimensions in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a tensor with a single\n",
      "        element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1., 1.], [2., 2.]])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.5>\n",
      "        >>> tf.reduce_mean(x, 0)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5, 1.5], dtype=float32)>\n",
      "        >>> tf.reduce_mean(x, 1)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.mean\n",
      "        \n",
      "        Please note that `np.mean` has a `dtype` parameter that could be used to\n",
      "        specify the output type. By default this is `dtype=float64`. On the other\n",
      "        hand, `tf.reduce_mean` has an aggressive type inference from `input_tensor`,\n",
      "        for example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 0, 1, 0])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        >>> y = tf.constant([1., 0., 1., 0.])\n",
      "        >>> tf.reduce_mean(y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.5>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_min(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes the `tf.math.minimum` of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.minimum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([\n",
      "        ...   [[1, 2], [3, 4]],\n",
      "        ...   [[1, 2], [3, 4]]\n",
      "        ... ])\n",
      "        >>> tf.reduce_min(a)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        Choosing a specific axis returns minimum element in the given axis:\n",
      "        \n",
      "        >>> b = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        >>> tf.reduce_min(b, axis=0)\n",
      "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n",
      "        >>> tf.reduce_min(b, axis=1)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4], dtype=int32)>\n",
      "        \n",
      "        Setting `keepdims` to `True` retains the dimension of `input_tensor`:\n",
      "        \n",
      "        >>> tf.reduce_min(a, keepdims=True)\n",
      "        <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[1]]], dtype=int32)>\n",
      "        >>> tf.math.reduce_min(a, axis=0, keepdims=True)\n",
      "        <tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
      "        array([[[1, 2],\n",
      "                [3, 4]]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.min\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_prod(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes `tf.math.multiply` of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.multiply` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[1., 2.], [3., 4.]])\n",
      "          >>> tf.math.reduce_prod(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=24.>\n",
      "          >>> tf.math.reduce_prod(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 8.], dtype=float32)>\n",
      "          >>> tf.math.reduce_prod(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 12.],\n",
      "          dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.prod\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_sum(input_tensor, axis=None, keepdims=False, name=None)\n",
      "        Computes the sum of elements across dimensions of a tensor.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.add` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "          >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "          >>> x.numpy()\n",
      "          array([[1, 1, 1],\n",
      "                 [1, 1, 1]], dtype=int32)\n",
      "          >>> # sum all the elements\n",
      "          >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "          >>> tf.reduce_sum(x).numpy()\n",
      "          6\n",
      "          >>> # reduce along the first dimension\n",
      "          >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> tf.reduce_sum(x, 0).numpy()\n",
      "          array([2, 2, 2], dtype=int32)\n",
      "          >>> # reduce along the second dimension\n",
      "          >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "          >>> tf.reduce_sum(x, 1).numpy()\n",
      "          array([3, 3], dtype=int32)\n",
      "          >>> # keep the original dimensions\n",
      "          >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "          array([[3],\n",
      "                 [3]], dtype=int32)\n",
      "          >>> # reduce along both dimensions\n",
      "          >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "          >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "          >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> # 2 + 2 + 2 = 6\n",
      "          >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "          6\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor)]`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor, of the same dtype as the input_tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "        int64 while tensorflow returns the same dtype as the input.\n",
      "        @end_compatibility\n",
      "    \n",
      "    register_tensor_conversion_function(base_type, conversion_func, priority=100)\n",
      "        Registers a function for converting objects of `base_type` to `Tensor`.\n",
      "        \n",
      "        The conversion function must have the following signature:\n",
      "        \n",
      "        ```python\n",
      "            def conversion_func(value, dtype=None, name=None, as_ref=False):\n",
      "              # ...\n",
      "        ```\n",
      "        \n",
      "        It must return a `Tensor` with the given `dtype` if specified. If the\n",
      "        conversion function creates a new `Tensor`, it should use the given\n",
      "        `name` if specified. All exceptions will be propagated to the caller.\n",
      "        \n",
      "        The conversion function may return `NotImplemented` for some\n",
      "        inputs. In this case, the conversion process will continue to try\n",
      "        subsequent conversion functions.\n",
      "        \n",
      "        If `as_ref` is true, the function must return a `Tensor` reference,\n",
      "        such as a `Variable`.\n",
      "        \n",
      "        NOTE: The conversion functions will execute in order of priority,\n",
      "        followed by order of registration. To ensure that a conversion function\n",
      "        `F` runs before another conversion function `G`, ensure that `F` is\n",
      "        registered with a smaller priority than `G`.\n",
      "        \n",
      "        Args:\n",
      "          base_type: The base type or tuple of base types for all objects that\n",
      "            `conversion_func` accepts.\n",
      "          conversion_func: A function that converts instances of `base_type` to\n",
      "            `Tensor`.\n",
      "          priority: Optional integer that indicates the priority for applying this\n",
      "            conversion function. Conversion functions with smaller priority values run\n",
      "            earlier than conversion functions with larger priority values. Defaults to\n",
      "            100.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the arguments do not have the appropriate type.\n",
      "    \n",
      "    repeat(input, repeats, axis=None, name=None)\n",
      "        Repeat elements of `input`.\n",
      "        \n",
      "        See also `tf.concat`, `tf.stack`, `tf.tile`.\n",
      "        \n",
      "        Args:\n",
      "          input: An `N`-dimensional Tensor.\n",
      "          repeats: An 1-D `int` Tensor. The number of repetitions for each element.\n",
      "            repeats is broadcasted to fit the shape of the given axis. `len(repeats)`\n",
      "            must equal `input.shape[axis]` if axis is not None.\n",
      "          axis: An int. The axis along which to repeat values. By default, (axis=None),\n",
      "            use the flattened input array, and return a flat output array.\n",
      "          name: A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor which has the same shape as `input`, except along the given axis.\n",
      "            If axis is None then the output array is flattened to match the flattened\n",
      "            input array.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)\n",
      "        <tf.Tensor: shape=(5,), dtype=string,\n",
      "        numpy=array([b'a', b'a', b'a', b'c', b'c'], dtype=object)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [1, 2],\n",
      "               [3, 4],\n",
      "               [3, 4],\n",
      "               [3, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
      "        array([[1, 1, 2, 2, 2],\n",
      "               [3, 3, 4, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat(3, repeats=4)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 3, 3, 3], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1,2], [3,4]], repeats=2)\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32)>\n",
      "    \n",
      "    required_space_to_batch_paddings(input_shape, block_shape, base_paddings=None, name=None)\n",
      "        Calculate padding required to make block_shape divide input_shape.\n",
      "        \n",
      "        This function can be used to calculate a suitable paddings argument for use\n",
      "        with space_to_batch_nd and batch_to_space_nd.\n",
      "        \n",
      "        Args:\n",
      "          input_shape: int32 Tensor of shape [N].\n",
      "          block_shape: int32 Tensor of shape [N].\n",
      "          base_paddings: Optional int32 Tensor of shape [N, 2].  Specifies the minimum\n",
      "            amount of padding to use.  All elements must be >= 0.  If not specified,\n",
      "            defaults to 0.\n",
      "          name: string.  Optional name prefix.\n",
      "        \n",
      "        Returns:\n",
      "          (paddings, crops), where:\n",
      "        \n",
      "          `paddings` and `crops` are int32 Tensors of rank 2 and shape [N, 2]\n",
      "          satisfying:\n",
      "        \n",
      "              paddings[i, 0] = base_paddings[i, 0].\n",
      "              0 <= paddings[i, 1] - base_paddings[i, 1] < block_shape[i]\n",
      "              (input_shape[i] + paddings[i, 0] + paddings[i, 1]) % block_shape[i] == 0\n",
      "        \n",
      "              crops[i, 0] = 0\n",
      "              crops[i, 1] = paddings[i, 1] - base_paddings[i, 1]\n",
      "        \n",
      "        Raises: ValueError if called with incompatible shapes.\n",
      "    \n",
      "    reshape(tensor, shape, name=None)\n",
      "        Reshapes a tensor.\n",
      "        \n",
      "        Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
      "        values as `tensor` in the same order, except with a new shape given by\n",
      "        `shape`.\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3],\n",
      "        ...       [4, 5, 6]]\n",
      "        >>> print(tf.shape(t1).numpy())\n",
      "        [2 3]\n",
      "        >>> t2 = tf.reshape(t1, [6])\n",
      "        >>> t2\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t2, [3, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        The `tf.reshape` does not change the order of or the total number of elements\n",
      "        in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
      "        a fast operation independent of how big of a tensor it is operating on.\n",
      "        \n",
      "        >>> tf.reshape([1, 2, 3], [2, 2])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
      "        requested shape has 4\n",
      "        \n",
      "        To instead reorder the data to rearrange the dimensions of a tensor, see\n",
      "        `tf.transpose`.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [3, 2]).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total size remains constant.  In particular,\n",
      "        a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "        be -1.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t, [3, -1])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        >>> tf.reshape(t, [-1, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
      "        \n",
      "        >>> tf.reshape([7], []).numpy()\n",
      "        7\n",
      "        \n",
      "        More examples:\n",
      "        \n",
      "        >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [9]\n",
      "        >>> tf.reshape(t, [3, 3])\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[1, 2, 3],\n",
      "                 [4, 5, 6],\n",
      "                 [7, 8, 9]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1], [2, 2]],\n",
      "        ...      [[3, 3], [4, 4]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [2 2 2]\n",
      "        >>> tf.reshape(t, [2, 4])\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "          array([[1, 1, 2, 2],\n",
      "                 [3, 3, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1, 1],\n",
      "        ...       [2, 2, 2]],\n",
      "        ...      [[3, 3, 3],\n",
      "        ...       [4, 4, 4]],\n",
      "        ...      [[5, 5, 5],\n",
      "        ...       [6, 6, 6]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [3 2 3]\n",
      "        >>> # Pass '[-1]' to flatten 't'.\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(18,), dtype=int32,\n",
      "          numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
      "          dtype=int32)>\n",
      "        >>> # -- Using -1 to infer the shape --\n",
      "        >>> # Here -1 is inferred to be 9:\n",
      "        >>> tf.reshape(t, [2, -1])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 2:\n",
      "        >>> tf.reshape(t, [-1, 9])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 3:\n",
      "        >>> tf.reshape(t, [ 2, -1, 3])\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "          array([[[1, 1, 1],\n",
      "                  [2, 2, 2],\n",
      "                  [3, 3, 3]],\n",
      "                 [[4, 4, 4],\n",
      "                  [5, 5, 5],\n",
      "                  [6, 6, 6]]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Defines the shape of the output tensor.\n",
      "          name: Optional string. A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    reverse = reverse_v2(tensor, axis, name=None)\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        \n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        \n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        \n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        \n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        \n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        \n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        \n",
      "        #                 [[12, 13, 14, 15],\n",
      "        \n",
      "        #                  [16, 17, 18, 19],\n",
      "        \n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        \n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        \n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        \n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "        \n",
      "                                [ 7,  6,  5,  4],\n",
      "        \n",
      "                                [ 11, 10, 9, 8]],\n",
      "        \n",
      "                               [[15, 14, 13, 12],\n",
      "        \n",
      "                                [19, 18, 17, 16],\n",
      "        \n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        \n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        \n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "        \n",
      "                                [16, 17, 18, 19],\n",
      "        \n",
      "                                [20, 21, 22, 23]\n",
      "        \n",
      "                               [[ 0,  1,  2,  3],\n",
      "        \n",
      "                                [ 4,  5,  6,  7],\n",
      "        \n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        \n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        \n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "        \n",
      "                                [4, 5, 6, 7],\n",
      "        \n",
      "                                [0, 1, 2, 3]]\n",
      "        \n",
      "                               [[20, 21, 22, 23],\n",
      "        \n",
      "                                [16, 17, 18, 19],\n",
      "        \n",
      "                                [12, 13, 14, 15]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "        \n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    reverse_sequence = reverse_sequence_v2(input, seq_lengths, seq_axis=None, batch_axis=None, name=None)\n",
      "        Reverses variable length slices.\n",
      "        \n",
      "        This op first slices `input` along the dimension `batch_axis`, and for\n",
      "        each slice `i`, reverses the first `seq_lengths[i]` elements along the\n",
      "        dimension `seq_axis`.\n",
      "        \n",
      "        The elements of `seq_lengths` must obey `seq_lengths[i] <=\n",
      "        input.dims[seq_axis]`, and `seq_lengths` must be a vector of length\n",
      "        `input.dims[batch_axis]`.\n",
      "        \n",
      "        The output slice `i` along dimension `batch_axis` is then given by\n",
      "        input slice `i`, with the first `seq_lengths[i]` slices along\n",
      "        dimension `seq_axis` reversed.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> seq_lengths = [7, 2, 3, 5]\n",
      "        >>> input = [[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 0, 0, 0, 0, 0, 0],\n",
      "        ...          [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n",
      "        >>> output = tf.reverse_sequence(input, seq_lengths, seq_axis=1, batch_axis=0)\n",
      "        >>> output\n",
      "        <tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
      "        array([[0, 0, 5, 4, 3, 2, 1, 0],\n",
      "               [2, 1, 0, 0, 0, 0, 0, 0],\n",
      "               [3, 2, 1, 4, 0, 0, 0, 0],\n",
      "               [5, 4, 3, 2, 1, 6, 7, 8]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The input to reverse.\n",
      "          seq_lengths: A `Tensor`. Must be one of the following types: `int32`,\n",
      "            `int64`. 1-D with length `input.dims(batch_axis)` and `max(seq_lengths) <=\n",
      "            input.dims(seq_axis)`\n",
      "          seq_axis: An `int`. The dimension which is partially reversed.\n",
      "          batch_axis: An optional `int`. Defaults to `0`. The dimension along which\n",
      "            reversal is performed.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as input.\n",
      "    \n",
      "    roll(input, shift, axis, name=None)\n",
      "        Rolls the elements of a tensor along an axis.\n",
      "        \n",
      "        The elements are shifted positively (towards larger indices) by the offset of\n",
      "        \n",
      "        `shift` along the dimension of `axis`. Negative `shift` values will shift\n",
      "        \n",
      "        elements in the opposite direction. Elements that roll passed the last position\n",
      "        \n",
      "        will wrap around to the first and vice versa. Multiple shifts along multiple\n",
      "        \n",
      "        axes may be specified.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        # 't' is [0, 1, 2, 3, 4]\n",
      "        \n",
      "        roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]\n",
      "        \n",
      "        \n",
      "        \n",
      "        # shifting along multiple dimensions\n",
      "        \n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        \n",
      "        roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]\n",
      "        \n",
      "        \n",
      "        \n",
      "        # shifting along the same axis multiple times\n",
      "        \n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        \n",
      "        roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          shift: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which\n",
      "        \n",
      "            elements are shifted positively (towards larger indices) along the dimension\n",
      "        \n",
      "            specified by `axis[i]`. Negative shifts will roll the elements in the opposite\n",
      "        \n",
      "            direction.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift\n",
      "        \n",
      "            `shift[i]` should occur. If the same axis is referenced more than once, the\n",
      "        \n",
      "            total shift for that axis will be the sum of all the shifts that belong to that\n",
      "        \n",
      "            axis.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    round(x, name=None)\n",
      "        Rounds the values of a tensor to the nearest integer, element-wise.\n",
      "        \n",
      "        Rounds half to even.  Also known as bankers rounding. If you want to round\n",
      "        according to the current system rounding mode use tf::cint.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.9, 2.5, 2.3, 1.5, -4.5])\n",
      "        tf.round(x)  # [ 1.0, 2.0, 2.0, 2.0, -4.0 ]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, or `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as `x`.\n",
      "    \n",
      "    saturate_cast(value, dtype, name=None)\n",
      "        Performs a safe saturating cast of `value` to `dtype`.\n",
      "        \n",
      "        This function casts the input to `dtype` without overflow.  If\n",
      "        there is a danger that values would over or underflow in the cast, this op\n",
      "        applies the appropriate clamping before the cast.  See `tf.cast` for more\n",
      "        details.\n",
      "        \n",
      "        Args:\n",
      "          value: A `Tensor`.\n",
      "          dtype: The desired output `DType`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `value` safely cast to `dtype`.\n",
      "    \n",
      "    scalar_mul = scalar_mul_v2(scalar, x, name=None)\n",
      "        Multiplies a scalar times a `Tensor` or `IndexedSlices` object.\n",
      "        \n",
      "        This is a special case of `tf.math.multiply`, where the first value must be a\n",
      "        `scalar`. Unlike the general form of `tf.math.multiply`, this is operation is\n",
      "        guaranteed to be efficient for `tf.IndexedSlices`.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(30, dtype=tf.float32), [10, 3])\n",
      "        >>> with tf.GradientTape() as g:\n",
      "        ...   g.watch(x)\n",
      "        ...   y = tf.gather(x, [1, 2])  # IndexedSlices\n",
      "        ...   z = tf.math.scalar_mul(10.0, y)\n",
      "        \n",
      "        Args:\n",
      "          scalar: A 0-D scalar `Tensor`. Must have known shape.\n",
      "          x: A `Tensor` or `IndexedSlices` to be scaled.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `scalar * x` of the same type (`Tensor` or `IndexedSlices`) as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if scalar is not a 0-D `scalar`.\n",
      "    \n",
      "    scan = scan_v2(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, reverse=False, name=None)\n",
      "        scan on the list of tensors unpacked from `elems` on dimension 0. (deprecated argument values)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(back_prop=False)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "        Instead of:\n",
      "        results = tf.scan(fn, elems, back_prop=False)\n",
      "        Use:\n",
      "        results = tf.nest.map_structure(tf.stop_gradient, tf.scan(fn, elems))\n",
      "        \n",
      "        The simplest version of `scan` repeatedly applies the callable `fn` to a\n",
      "        sequence of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `[len(values)] + fn(initializer, values[0]).shape`.\n",
      "        If reverse=True, it's fn(initializer, values[-1]).shape.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and accumulator.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The second argument of\n",
      "        `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If no `initializer` is provided, the output structure and dtypes of `fn`\n",
      "        are assumed to be the same as its input; and in this case, the first\n",
      "        argument of `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If an `initializer` is provided, then the output of `fn` must have the same\n",
      "        structure as `initializer`; and the first argument of `fn` must match\n",
      "        this structure.\n",
      "        \n",
      "        For example, if `elems` is `(t1, [t2, t3])` and `initializer` is\n",
      "        `[i1, i2]` then an appropriate signature for `fn` in `python2` is:\n",
      "        `fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):` and `fn` must return a list,\n",
      "        `[acc_n1, acc_n2]`.  An alternative correct signature for `fn`, and the\n",
      "         one that works in `python3`, is:\n",
      "        `fn = lambda a, t:`, where `a` and `t` correspond to the input tuples.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts two arguments.  The first will\n",
      "            have the same structure as `initializer` if one is provided, otherwise it\n",
      "            will have the same structure as `elems`.  The second will have the same\n",
      "            (possibly nested) structure as `elems`.  Its output must have the same\n",
      "            structure as `initializer` if one is provided, otherwise it must have the\n",
      "            same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            initial value for the accumulator, and the expected output type of `fn`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) Deprecated. False disables support for back\n",
      "            propagation. Prefer using `tf.stop_gradient` instead.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          reverse: (optional) True scans the tensor last to first (instead of first to\n",
      "            last).\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "          results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "          dimension, and the previous accumulator value(s), from first to last (or\n",
      "          last to first, if `reverse=True`).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `initializer` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `initializer`\n",
      "            do not match.\n",
      "        \n",
      "        Examples:\n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          sum = scan(lambda a, x: a + x, elems)\n",
      "          # sum == [1, 3, 6, 10, 15, 21]\n",
      "          sum = scan(lambda a, x: a + x, elems, reverse=True)\n",
      "          # sum == [21, 20, 18, 15, 11, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          initializer = np.array(0)\n",
      "          sum_one = scan(\n",
      "              lambda a, x: x[0] - x[1] + a, (elems + 1, elems), initializer)\n",
      "          # sum_one == [1, 2, 3, 4, 5, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 0, 0, 0, 0, 0])\n",
      "          initializer = (np.array(0), np.array(1))\n",
      "          fibonaccis = scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)\n",
      "          # fibonaccis == ([1, 1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 13])\n",
      "          ```\n",
      "    \n",
      "    scatter_nd(indices, updates, shape, name=None)\n",
      "        Scatters `updates` into a tensor of shape `shape` according to `indices`.\n",
      "        \n",
      "        Scatter sparse `updates` according to individual values at the specified\n",
      "        \n",
      "        `indices`. This op returns an output tensor with the `shape` you specify. This\n",
      "        \n",
      "        op is the inverse of the `tf.gather_nd` operator which extracts values or slices\n",
      "        \n",
      "        from a given tensor.\n",
      "        \n",
      "        \n",
      "        \n",
      "        This operation is similar to `tf.tensor_scatter_nd_add`, except that the tensor\n",
      "        \n",
      "        is zero-initialized. Calling `tf.scatter_nd(indices, updates, shape)`\n",
      "        \n",
      "        is identical to calling\n",
      "        \n",
      "        `tf.tensor_scatter_nd_add(tf.zeros(shape, updates.dtype), indices, updates)`\n",
      "        \n",
      "        \n",
      "        \n",
      "        If `indices` contains duplicates, the associated `updates` are accumulated\n",
      "        \n",
      "        (summed) into the output tensor.\n",
      "        \n",
      "        \n",
      "        \n",
      "        **WARNING**: For floating-point data types, the output may be nondeterministic.\n",
      "        \n",
      "        This is because the order in which the updates are applied is nondeterministic\n",
      "        \n",
      "        and when floating-point numbers are added in different orders the resulting\n",
      "        \n",
      "        numerical approximation error can be slightly different. However, the output\n",
      "        \n",
      "        will be deterministic if op determinism is enabled via\n",
      "        \n",
      "        `tf.config.experimental.enable_op_determinism`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        `indices` is an integer tensor containing indices into the output tensor. The\n",
      "        \n",
      "        last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "        \n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        \n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices of elements\n",
      "        \n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        \n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        \n",
      "        `shape`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        `updates` is a tensor with shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        \n",
      "        \n",
      "        The simplest form of the scatter op is to insert individual elements in\n",
      "        \n",
      "        a tensor by index. Consider an example where you want to insert 4 scattered\n",
      "        \n",
      "        elements in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        \n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        \n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        \n",
      "        </div>\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "        \n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "        \n",
      "            shape = tf.constant([8])\n",
      "        \n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "        \n",
      "            print(scatter)\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "            [0, 11, 0, 10, 9, 0, 0, 12]\n",
      "        \n",
      "        \n",
      "        \n",
      "        You can also insert entire slices of a higher rank tensor all at once. For\n",
      "        \n",
      "        example, you can insert two slices in the first dimension of a rank-3 tensor\n",
      "        \n",
      "        with two matrices of new values.\n",
      "        \n",
      "        \n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        \n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd2.png\" alt>\n",
      "        \n",
      "        </div>\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            indices = tf.constant([[1], [3]])\n",
      "        \n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        \n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        \n",
      "            shape = tf.constant([4, 4, 4])\n",
      "        \n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "        \n",
      "            print(scatter)\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "            [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "        \n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        \n",
      "             [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "        \n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]]]\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        \n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            Tensor of indices.\n",
      "          updates: A `Tensor`. Values to scatter into the output tensor.\n",
      "          shape: A `Tensor`. Must have the same type as `indices`.\n",
      "            1-D. The shape of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `updates`.\n",
      "    \n",
      "    searchsorted(sorted_sequence, values, side='left', out_type=tf.int32, name=None)\n",
      "        Searches for where a value would go in a sorted sequence.\n",
      "        \n",
      "        This is not a method for checking containment (like python `in`).\n",
      "        \n",
      "        The typical use case for this operation is \"binning\", \"bucketing\", or\n",
      "        \"discretizing\". The `values` are assigned to bucket-indices based on the\n",
      "        **edges** listed in `sorted_sequence`. This operation\n",
      "        returns the bucket-index for each value.\n",
      "        \n",
      "        >>> edges = [-1, 3.3, 9.1, 10.0]\n",
      "        >>> values = [0.0, 4.1, 12.0]\n",
      "        >>> tf.searchsorted(edges, values).numpy()\n",
      "        array([1, 2, 4], dtype=int32)\n",
      "        \n",
      "        The `side` argument controls which index is returned if a value lands exactly\n",
      "        on an edge:\n",
      "        \n",
      "        >>> seq = [0, 3, 9, 10, 10]\n",
      "        >>> values = [0, 4, 10]\n",
      "        >>> tf.searchsorted(seq, values).numpy()\n",
      "        array([0, 2, 3], dtype=int32)\n",
      "        >>> tf.searchsorted(seq, values, side=\"right\").numpy()\n",
      "        array([1, 2, 5], dtype=int32)\n",
      "        \n",
      "        The `axis` is not settable for this operation. It always operates on the\n",
      "        innermost dimension (`axis=-1`). The operation will accept any number of\n",
      "        outer dimensions. Here it is applied to the rows of a matrix:\n",
      "        \n",
      "        >>> sorted_sequence = [[0., 3., 8., 9., 10.],\n",
      "        ...                    [1., 2., 3., 4., 5.]]\n",
      "        >>> values = [[9.8, 2.1, 4.3],\n",
      "        ...           [0.1, 6.6, 4.5, ]]\n",
      "        >>> tf.searchsorted(sorted_sequence, values).numpy()\n",
      "        array([[4, 1, 2],\n",
      "               [0, 5, 4]], dtype=int32)\n",
      "        \n",
      "        Note: This operation assumes that `sorted_sequence` **is sorted** along the\n",
      "        innermost axis, maybe using `tf.sort(..., axis=-1)`. **If the sequence is not\n",
      "        sorted, no error is raised** and the content of the returned tensor is not well\n",
      "        defined.\n",
      "        \n",
      "        Args:\n",
      "          sorted_sequence: N-D `Tensor` containing a sorted sequence.\n",
      "          values: N-D `Tensor` containing the search values.\n",
      "          side: 'left' or 'right'; 'left' corresponds to lower_bound and 'right' to\n",
      "            upper_bound.\n",
      "          out_type: The output type (`int32` or `int64`).  Default is `tf.int32`.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An N-D `Tensor` the size of `values` containing the result of applying\n",
      "          either lower_bound or upper_bound (depending on side) to each value.  The\n",
      "          result is not a global index to the entire `Tensor`, but the index in the\n",
      "          last dimension.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the last dimension of `sorted_sequence >= 2^31-1` elements.\n",
      "                      If the total size of `values` exceeds `2^31 - 1` elements.\n",
      "                      If the first `N-1` dimensions of the two tensors don't match.\n",
      "    \n",
      "    sequence_mask(lengths, maxlen=None, dtype=tf.bool, name=None)\n",
      "        Returns a mask tensor representing the first N positions of each cell.\n",
      "        \n",
      "        If `lengths` has shape `[d_1, d_2, ..., d_n]` the resulting tensor `mask` has\n",
      "        dtype `dtype` and shape `[d_1, d_2, ..., d_n, maxlen]`, with\n",
      "        \n",
      "        ```\n",
      "        mask[i_1, i_2, ..., i_n, j] = (j < lengths[i_1, i_2, ..., i_n])\n",
      "        ```\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
      "                                        #  [True, True, True, False, False],\n",
      "                                        #  [True, True, False, False, False]]\n",
      "        \n",
      "        tf.sequence_mask([[1, 3],[2,0]])  # [[[True, False, False],\n",
      "                                          #   [True, True, True]],\n",
      "                                          #  [[True, True, False],\n",
      "                                          #   [False, False, False]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lengths: integer tensor, all its values <= maxlen.\n",
      "          maxlen: scalar integer tensor, size of last dimension of returned tensor.\n",
      "            Default is the maximum value in `lengths`.\n",
      "          dtype: output type of the resulting tensor.\n",
      "          name: name of the op.\n",
      "        \n",
      "        Returns:\n",
      "          A mask tensor of shape `lengths.shape + (maxlen,)`, cast to specified dtype.\n",
      "        Raises:\n",
      "          ValueError: if `maxlen` is not a scalar.\n",
      "    \n",
      "    shape = shape_v2(input, out_type=tf.int32, name=None)\n",
      "        Returns a tensor containing the shape of the input tensor.\n",
      "        \n",
      "        See also `tf.size`, `tf.rank`.\n",
      "        \n",
      "        `tf.shape` returns a 1-D integer tensor representing the shape of `input`.\n",
      "        For a scalar input, the tensor returned has a shape of (0,) and its value is\n",
      "        the empty vector (i.e. []).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.shape(1.)\n",
      "        <tf.Tensor: shape=(0,), dtype=int32, numpy=array([], dtype=int32)>\n",
      "        \n",
      "        >>> t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        >>> tf.shape(t)\n",
      "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 2, 3], dtype=int32)>\n",
      "        \n",
      "        Note: When using symbolic tensors, such as when using the Keras API,\n",
      "        tf.shape() will return the shape of the symbolic tensor.\n",
      "        \n",
      "        >>> a = tf.keras.layers.Input((None, 10))\n",
      "        >>> tf.shape(a)\n",
      "        <... shape=(3,) dtype=int32...>\n",
      "        \n",
      "        In these cases, using `tf.Tensor.shape` will return more informative results.\n",
      "        \n",
      "        >>> a.shape\n",
      "        TensorShape([None, None, 10])\n",
      "        \n",
      "        (The first `None` represents the as yet unknown batch size.)\n",
      "        \n",
      "        `tf.shape` and `Tensor.shape` should be identical in eager mode.  Within\n",
      "        `tf.function` or within a `compat.v1` context, not all dimensions may be\n",
      "        known until execution time. Hence, when defining custom layers and models\n",
      "        for graph mode, prefer the dynamic `tf.shape(x)` over the static `x.shape`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          out_type: (Optional) The specified output type of the operation (`int32` or\n",
      "            `int64`). Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    shape_n(input, out_type=tf.int32, name=None)\n",
      "        Returns shape of a list of tensors.\n",
      "        \n",
      "        Given a list of tensors, `tf.shape_n` is much faster than applying `tf.shape`\n",
      "        to each tensor individually.\n",
      "        >>> a = tf.ones([1, 2])\n",
      "        >>> b = tf.ones([2, 3])\n",
      "        >>> c = tf.ones([3, 4])\n",
      "        >>> tf.shape_n([a, b, c])\n",
      "        [<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>]\n",
      "        \n",
      "        Args:\n",
      "          input: A list of at least 1 `Tensor` object with the same dtype.\n",
      "          out_type: The specified output type of the operation (`int32` or `int64`).\n",
      "            Defaults to `tf.int32`(optional).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` specifying the shape of each input tensor with type of\n",
      "          `out_type`.\n",
      "    \n",
      "    sigmoid(x, name=None)\n",
      "        Computes sigmoid of `x` element-wise.\n",
      "        \n",
      "        Formula for calculating $\\mathrm{sigmoid}(x) = y = 1 / (1 + \\exp(-x))$.\n",
      "        \n",
      "        For $x \\in (-\\infty, \\infty)$, $\\mathrm{sigmoid}(x) \\in (0, 1)$.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        If a positive number is large, then its sigmoid will approach to 1 since the\n",
      "        formula will be `y = <large_num> / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([0.5, 0.7310586, 1.0, 1.0], dtype=float32)>\n",
      "        \n",
      "        If a negative number is large, its sigmoid will approach to 0 since the\n",
      "        formula will be `y = 1 / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([-100.0, -50.0, -1.0, 0.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([0.0000000e+00, 1.9287499e-22, 2.6894143e-01, 0.5],\n",
      "              dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float16`, `float32`, `float64`, `complex64`, or\n",
      "            `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        Usage Example:\n",
      "        \n",
      "        >>> x = tf.constant([-128.0, 0.0, 128.0], dtype=tf.float32)\n",
      "        >>> tf.sigmoid(x)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([0. , 0.5, 1. ], dtype=float32)>\n",
      "        \n",
      "        @compatibility(scipy)\n",
      "        Equivalent to scipy.special.expit\n",
      "        @end_compatibility\n",
      "    \n",
      "    sign(x, name=None)\n",
      "        Returns an element-wise indication of the sign of a number.\n",
      "        \n",
      "        `y = sign(x) = -1 if x < 0; 0 if x == 0; 1 if x > 0`.\n",
      "        \n",
      "        For complex numbers, `y = sign(x) = x / |x| if x != 0, otherwise y = 0`.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> tf.math.sign([0., 2., -3.])\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([ 0.,  1., -1.], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> tf.math.sign([1 + 1j, 0 + 0j])\n",
      "        <tf.Tensor: shape=(2,), dtype=complex128,\n",
      "        numpy=array([0.70710678+0.70710678j, 0.        +0.j        ])>\n",
      "        \n",
      "        Args:\n",
      "         x: A Tensor. Must be one of the following types: bfloat16, half, float32,\n",
      "           float64, int32, int64, complex64, complex128.\n",
      "         name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "         A Tensor. Has the same type as x.\n",
      "        \n",
      "         If x is a SparseTensor, returns SparseTensor(x.indices,\n",
      "           tf.math.sign(x.values, ...), x.dense_shape).\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sign(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    sin(x, name=None)\n",
      "        Computes sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes sine of every\n",
      "        \n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "        \n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10, float(\"inf\")])\n",
      "        \n",
      "          tf.math.sin(x) ==> [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    sinh(x, name=None)\n",
      "        Computes hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic sine of every\n",
      "        \n",
      "          element in the tensor. Input range is `[-inf,inf]` and output range\n",
      "        \n",
      "          is `[-inf,inf]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "        \n",
      "          tf.math.sinh(x) ==> [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    size = size_v2(input, out_type=tf.int32, name=None)\n",
      "        Returns the size of a tensor.\n",
      "        \n",
      "        See also `tf.shape`.\n",
      "        \n",
      "        Returns a 0-D `Tensor` representing the number of elements in `input`\n",
      "        of type `out_type`. Defaults to tf.int32.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        >>> tf.size(t)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=12>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified non-quantized numeric output type of the\n",
      "            operation. Defaults to `tf.int32`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`. Defaults to `tf.int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.size()\n",
      "        @end_compatibility\n",
      "    \n",
      "    slice(input_, begin, size, name=None)\n",
      "        Extracts a slice from a tensor.\n",
      "        \n",
      "        See also `tf.strided_slice`.\n",
      "        \n",
      "        This operation extracts a slice of size `size` from a tensor `input_` starting\n",
      "        at the location specified by `begin`. The slice `size` is represented as a\n",
      "        tensor shape, where `size[i]` is the number of elements of the 'i'th dimension\n",
      "        of `input_` that you want to slice. The starting location (`begin`) for the\n",
      "        slice is represented as an offset in each dimension of `input_`. In other\n",
      "        words, `begin[i]` is the offset into the i'th dimension of `input_` that you\n",
      "        want to slice from.\n",
      "        \n",
      "        Note that `tf.Tensor.__getitem__` is typically a more pythonic way to\n",
      "        perform slices, as it allows you to write `foo[3:7, :-2]` instead of\n",
      "        `tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])`.\n",
      "        \n",
      "        `begin` is zero-based; `size` is one-based. If `size[i]` is -1,\n",
      "        all remaining elements in dimension i are included in the\n",
      "        slice. In other words, this is equivalent to setting:\n",
      "        \n",
      "        `size[i] = input_.dim_size(i) - begin[i]`\n",
      "        \n",
      "        This operation requires that:\n",
      "        \n",
      "        `0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
      "        tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
      "                                           #   [4, 4, 4]]]\n",
      "        tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
      "                                           #  [[5, 5, 5]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          size: An `int32` or `int64` `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input_`.\n",
      "    \n",
      "    sort(values, axis=-1, direction='ASCENDING', name=None)\n",
      "        Sorts a tensor.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        >>> a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> tf.sort(a).numpy()\n",
      "        array([  1.  ,   2.8 ,  10.  ,  26.9 ,  62.3 , 166.32], dtype=float32)\n",
      "        \n",
      "        >>> tf.sort(a, direction='DESCENDING').numpy()\n",
      "        array([166.32,  62.3 ,  26.9 ,  10.  ,   2.8 ,   1.  ], dtype=float32)\n",
      "        \n",
      "        For multidimensional inputs you can control which axis the sort is applied\n",
      "        along. The default `axis=-1` sorts the innermost axis.\n",
      "        \n",
      "        >>> mat = [[3,2,1],\n",
      "        ...        [2,1,3],\n",
      "        ...        [1,3,2]]\n",
      "        >>> tf.sort(mat, axis=-1).numpy()\n",
      "        array([[1, 2, 3],\n",
      "               [1, 2, 3],\n",
      "               [1, 2, 3]], dtype=int32)\n",
      "        >>> tf.sort(mat, axis=0).numpy()\n",
      "        array([[1, 1, 1],\n",
      "               [2, 2, 2],\n",
      "               [3, 3, 3]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.argsort`: Like sort, but it returns the sort indices.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same dtype and shape as `values`, with the elements\n",
      "              sorted along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "    \n",
      "    space_to_batch = space_to_batch_v2(input, block_shape, paddings, name=None)\n",
      "        SpaceToBatch for N-D tensors of type T.\n",
      "        \n",
      "        This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\n",
      "        \n",
      "        grid of blocks of shape `block_shape`, and interleaves these blocks with the\n",
      "        \n",
      "        \"batch\" dimension (0) such that in the output, the spatial dimensions\n",
      "        \n",
      "        `[1, ..., M]` correspond to the position within the grid, and the batch\n",
      "        \n",
      "        dimension combines both the position within a spatial block and the original\n",
      "        \n",
      "        batch position.  Prior to division into blocks, the spatial dimensions of the\n",
      "        \n",
      "        input are optionally zero padded according to `paddings`. See below for a\n",
      "        \n",
      "        precise description.\n",
      "        \n",
      "        \n",
      "        \n",
      "        This operation is equivalent to the following steps:\n",
      "        \n",
      "        \n",
      "        \n",
      "        1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n",
      "        \n",
      "           input according to `paddings` to produce `padded` of shape `padded_shape`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        2. Reshape `padded` to `reshaped_padded` of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             [batch] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "               block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1],\n",
      "        \n",
      "              block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        3. Permute dimensions of `reshaped_padded` to produce\n",
      "        \n",
      "           `permuted_reshaped_padded` of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             block_shape +\n",
      "        \n",
      "             [batch] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch\n",
      "        \n",
      "           dimension, producing an output tensor of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             [batch * prod(block_shape)] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        \n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "        \n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "        \n",
      "              [[5],   [6],  [7],  [8]],\n",
      "        \n",
      "              [[9],  [10], [11],  [12]],\n",
      "        \n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "        \n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "        \n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "        \n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and\n",
      "        \n",
      "            paddings = `[[0, 0], [2, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "        \n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "        \n",
      "             [[[9],  [10], [11],  [12]],\n",
      "        \n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[8, 1, 3, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "        \n",
      "             [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "        \n",
      "             [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "        \n",
      "             [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        \n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "        \n",
      "            where spatial_shape has `M` dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "        \n",
      "              `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension\n",
      "        \n",
      "              `i + 1`, which corresponds to spatial dimension `i`.  It is required that\n",
      "        \n",
      "              `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_batch_nd(input, block_shape, paddings, name=None)\n",
      "        SpaceToBatch for N-D tensors of type T.\n",
      "        \n",
      "        This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\n",
      "        \n",
      "        grid of blocks of shape `block_shape`, and interleaves these blocks with the\n",
      "        \n",
      "        \"batch\" dimension (0) such that in the output, the spatial dimensions\n",
      "        \n",
      "        `[1, ..., M]` correspond to the position within the grid, and the batch\n",
      "        \n",
      "        dimension combines both the position within a spatial block and the original\n",
      "        \n",
      "        batch position.  Prior to division into blocks, the spatial dimensions of the\n",
      "        \n",
      "        input are optionally zero padded according to `paddings`. See below for a\n",
      "        \n",
      "        precise description.\n",
      "        \n",
      "        \n",
      "        \n",
      "        This operation is equivalent to the following steps:\n",
      "        \n",
      "        \n",
      "        \n",
      "        1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n",
      "        \n",
      "           input according to `paddings` to produce `padded` of shape `padded_shape`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        2. Reshape `padded` to `reshaped_padded` of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             [batch] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "               block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1],\n",
      "        \n",
      "              block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        3. Permute dimensions of `reshaped_padded` to produce\n",
      "        \n",
      "           `permuted_reshaped_padded` of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             block_shape +\n",
      "        \n",
      "             [batch] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch\n",
      "        \n",
      "           dimension, producing an output tensor of shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "             [batch * prod(block_shape)] +\n",
      "        \n",
      "             [padded_shape[1] / block_shape[0],\n",
      "        \n",
      "              ...,\n",
      "        \n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "        \n",
      "             remaining_shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        \n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "        \n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and\n",
      "        \n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "        \n",
      "              [[5],   [6],  [7],  [8]],\n",
      "        \n",
      "              [[9],  [10], [11],  [12]],\n",
      "        \n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "        \n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "        \n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "        \n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and\n",
      "        \n",
      "            paddings = `[[0, 0], [2, 0]]`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "        \n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "        \n",
      "             [[[9],  [10], [11],  [12]],\n",
      "        \n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The output tensor has shape `[8, 1, 3, 1]` and value:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "        \n",
      "             [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "        \n",
      "             [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "        \n",
      "             [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        \n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "        \n",
      "            where spatial_shape has `M` dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "        \n",
      "              `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension\n",
      "        \n",
      "              `i + 1`, which corresponds to spatial dimension `i`.  It is required that\n",
      "        \n",
      "              `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    split(value, num_or_size_splits, axis=0, num=None, name='split')\n",
      "        Splits a tensor `value` into a list of sub tensors.\n",
      "        \n",
      "        See also `tf.unstack`.\n",
      "        \n",
      "        If `num_or_size_splits` is an `int`,  then it splits `value` along the\n",
      "        dimension `axis` into `num_or_size_splits` smaller tensors. This requires that\n",
      "        `value.shape[axis]` is divisible by `num_or_size_splits`.\n",
      "        \n",
      "        If `num_or_size_splits` is a 1-D Tensor (or list), then `value` is split into\n",
      "        `len(num_or_size_splits)` elements. The shape of the `i`-th\n",
      "        element has the same size as the `value` except along dimension `axis` where\n",
      "        the size is `num_or_size_splits[i]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.Variable(tf.random.uniform([5, 30], -1, 1))\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors along dimension 1\n",
      "        >>> s0, s1, s2 = tf.split(x, num_or_size_splits=3, axis=1)\n",
      "        >>> tf.shape(s0).numpy()\n",
      "        array([ 5, 10], dtype=int32)\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
      "        >>> split0, split1, split2 = tf.split(x, [4, 15, 11], 1)\n",
      "        >>> tf.shape(split0).numpy()\n",
      "        array([5, 4], dtype=int32)\n",
      "        >>> tf.shape(split1).numpy()\n",
      "        array([ 5, 15], dtype=int32)\n",
      "        >>> tf.shape(split2).numpy()\n",
      "        array([ 5, 11], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          value: The `Tensor` to split.\n",
      "          num_or_size_splits: Either an `int` indicating the number of splits\n",
      "            along `axis` or a 1-D integer `Tensor` or Python list containing the sizes\n",
      "            of each output tensor along `axis`. If an `int`, then it must evenly\n",
      "            divide `value.shape[axis]`; otherwise the sum of sizes along the split\n",
      "            axis must match that of the `value`.\n",
      "          axis: An `int` or scalar `int32` `Tensor`. The dimension along which\n",
      "            to split. Must be in the range `[-rank(value), rank(value))`. Defaults to\n",
      "            0.\n",
      "          num: Optional, an `int`, used to specify the number of outputs when it\n",
      "            cannot be inferred from the shape of `size_splits`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          if `num_or_size_splits` is an `int` returns a list of\n",
      "          `num_or_size_splits` `Tensor` objects; if `num_or_size_splits` is a 1-D\n",
      "          list or 1-D `Tensor` returns `num_or_size_splits.get_shape[0]`\n",
      "          `Tensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          ValueError: If `num_or_size_splits` is a scalar `Tensor`.\n",
      "    \n",
      "    sqrt(x, name=None)\n",
      "        Computes element-wise square root of the input tensor.\n",
      "        \n",
      "        Note: This operation does not support integer types.\n",
      "        \n",
      "        >>> x = tf.constant([[4.0], [16.0]])\n",
      "        >>> tf.sqrt(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[2.],\n",
      "                 [4.]], dtype=float32)>\n",
      "        >>> y = tf.constant([[-4.0], [16.0]])\n",
      "        >>> tf.sqrt(y)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[nan],\n",
      "                 [ 4.]], dtype=float32)>\n",
      "        >>> z = tf.constant([[-1.0], [16.0]], dtype=tf.complex128)\n",
      "        >>> tf.sqrt(z)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=complex128, numpy=\n",
      "          array([[0.0+1.j],\n",
      "                 [4.0+0.j]])>\n",
      "        \n",
      "        Note: In order to support complex type, please provide an input tensor\n",
      "        of `complex64` or `complex128`.\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor` of type `bfloat16`, `half`, `float32`, `float64`,\n",
      "            `complex64`, `complex128`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of same size, type and sparsity as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    square(x, name=None)\n",
      "        Computes square of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = x * x = x^2\\\\).\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.math.square([-2., 0., 3.])\n",
      "        \n",
      "        <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    squeeze = squeeze_v2(input, axis=None, name=None)\n",
      "        Removes dimensions of size 1 from the shape of a tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of the same type with\n",
      "        all dimensions of size 1 removed. If you don't want to remove all size 1\n",
      "        dimensions, you can remove specific size 1 dimensions by specifying\n",
      "        `axis`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        tf.shape(tf.squeeze(t))  # [2, 3]\n",
      "        ```\n",
      "        \n",
      "        Or, to remove specific size 1 dimensions:\n",
      "        \n",
      "        ```python\n",
      "        # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        tf.shape(tf.squeeze(t, [2, 4]))  # [1, 2, 3, 1]\n",
      "        ```\n",
      "        \n",
      "        Unlike the older op `tf.compat.v1.squeeze`, this op does not accept a\n",
      "        deprecated `squeeze_dims` argument.\n",
      "        \n",
      "        Note: if `input` is a `tf.RaggedTensor`, then this operation takes `O(N)`\n",
      "        time, where `N` is the number of elements in the squeezed dimensions.\n",
      "        \n",
      "        Note: If squeeze is performed on dimensions of unknown sizes, then the\n",
      "        returned Tensor will be of unknown shape. A common situation is when the\n",
      "        first (batch) dimension is of size `None`, `tf.squeeze` returns\n",
      "        `<unknown>` shape which may be a surprise. Specify the `axis=` argument\n",
      "        to get the expected result, as illustrated in the following example:\n",
      "        \n",
      "        ```python\n",
      "        @tf.function\n",
      "        def func(x):\n",
      "          print('x.shape:', x.shape)\n",
      "          known_axes = [i for i, size in enumerate(x.shape) if size == 1]\n",
      "          y = tf.squeeze(x, axis=known_axes)\n",
      "          print('shape of tf.squeeze(x, axis=known_axes):', y.shape)\n",
      "          y = tf.squeeze(x)\n",
      "          print('shape of tf.squeeze(x):', y.shape)\n",
      "          return 0\n",
      "        \n",
      "        _ = func.get_concrete_function(tf.TensorSpec([None, 1, 2], dtype=tf.int32))\n",
      "        # Output is.\n",
      "        # x.shape: (None, 1, 2)\n",
      "        # shape of tf.squeeze(x, axis=known_axes): (None, 2)\n",
      "        # shape of tf.squeeze(x): <unknown>\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The `input` to squeeze.\n",
      "          axis: An optional list of `ints`. Defaults to `[]`. If specified, only\n",
      "            squeezes the dimensions listed. The dimension index starts at 0. It is an\n",
      "            error to squeeze a dimension that is not 1. Must be in the range\n",
      "            `[-rank(input), rank(input))`. Must be specified if `input` is a\n",
      "            `RaggedTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "          Contains the same data as `input`, but has one or more dimensions of\n",
      "          size 1 removed.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: The input cannot be converted to a tensor, or the specified\n",
      "            axis cannot be squeezed.\n",
      "    \n",
      "    stack(values, axis=0, name='stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.\n",
      "        \n",
      "        See also `tf.concat`, `tf.tile`, `tf.repeat`.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the `axis` dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
      "        \n",
      "        if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
      "        if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
      "        Etc.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 4])\n",
      "        >>> y = tf.constant([2, 5])\n",
      "        >>> z = tf.constant([3, 6])\n",
      "        >>> tf.stack([x, y, z])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)>\n",
      "        >>> tf.stack([x, y, z], axis=1)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is `np.stack`\n",
      "        \n",
      "        >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))\n",
      "        True\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          axis: An `int`. The axis to stack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-(R+1), R+1)`.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range [-(R+1), R+1).\n",
      "    \n",
      "    stop_gradient(input, name=None)\n",
      "        Stops gradient computation.\n",
      "        \n",
      "        When executed in a graph, this op outputs its input tensor as-is.\n",
      "        \n",
      "        \n",
      "        \n",
      "        When building ops to compute gradients, this op prevents the contribution of\n",
      "        \n",
      "        its inputs to be taken into account.  Normally, the gradient generator adds ops\n",
      "        \n",
      "        to a graph to compute the derivatives of a specified 'loss' by recursively\n",
      "        \n",
      "        finding out inputs that contributed to its computation.  If you insert this op\n",
      "        \n",
      "        in the graph it inputs are masked from the gradient generator.  They are not\n",
      "        \n",
      "        taken into account for computing gradients.\n",
      "        \n",
      "        \n",
      "        \n",
      "        This is useful any time you want to compute a value with TensorFlow but need\n",
      "        \n",
      "        to pretend that the value was a constant. For example, the softmax function\n",
      "        \n",
      "        for a vector x can be written as\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        \n",
      "        \n",
      "          def softmax(x):\n",
      "        \n",
      "            numerator = tf.exp(x)\n",
      "        \n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "        \n",
      "            return numerator / denominator\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        This however is susceptible to overflow if the values in x are large. An\n",
      "        \n",
      "        alternative more stable way is to subtract the maximum of x from each of the\n",
      "        \n",
      "        values.\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        \n",
      "        \n",
      "          def stable_softmax(x):\n",
      "        \n",
      "            z = x - tf.reduce_max(x)\n",
      "        \n",
      "            numerator = tf.exp(z)\n",
      "        \n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "        \n",
      "            return numerator / denominator\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        However, when we backprop through the softmax to x, we dont want to backprop\n",
      "        \n",
      "        through the `tf.reduce_max(x)` (if the max values are not unique then the\n",
      "        \n",
      "        gradient could flow to the wrong input) calculation and treat that as a\n",
      "        \n",
      "        constant. Therefore, we should write this out as\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        \n",
      "        \n",
      "          def stable_softmax(x):\n",
      "        \n",
      "            z = x - tf.stop_gradient(tf.reduce_max(x))\n",
      "        \n",
      "            numerator = tf.exp(z)\n",
      "        \n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "        \n",
      "            return numerator / denominator\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        Some other examples include:\n",
      "        \n",
      "        \n",
      "        \n",
      "        *  The *EM* algorithm where the *M-step* should not involve backpropagation\n",
      "        \n",
      "           through the output of the *E-step*.\n",
      "        \n",
      "        *  Contrastive divergence training of Boltzmann machines where, when\n",
      "        \n",
      "           differentiating the energy function, the training must not backpropagate\n",
      "        \n",
      "           through the graph that generated the samples from the model.\n",
      "        \n",
      "        *  Adversarial training, where no backprop should happen through the adversarial\n",
      "        \n",
      "           example generation process.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    strided_slice(input_, begin, end, strides=None, begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0, var=None, name=None)\n",
      "        Extracts a strided slice of a tensor (generalized Python array indexing).\n",
      "        \n",
      "        See also `tf.slice`.\n",
      "        \n",
      "        **Instead of calling this op directly most users will want to use the\n",
      "        NumPy-style slicing syntax (e.g. `tensor[..., 3:4:-1, tf.newaxis, 3]`), which\n",
      "        is supported via `tf.Tensor.__getitem__` and `tf.Variable.__getitem__`.**\n",
      "        The interface of this op is a low-level encoding of the slicing syntax.\n",
      "        \n",
      "        Roughly speaking, this op extracts a slice of size `(end-begin)/stride`\n",
      "        from the given `input_` tensor. Starting at the location specified by `begin`\n",
      "        the slice continues by adding `stride` to the index until all dimensions are\n",
      "        not less than `end`.\n",
      "        Note that a stride can be negative, which causes a reverse slice.\n",
      "        \n",
      "        Given a Python slice `input[spec0, spec1, ..., specn]`,\n",
      "        this function will be called as follows.\n",
      "        \n",
      "        `begin`, `end`, and `strides` will be vectors of length n.\n",
      "        n in general is not equal to the rank of the `input_` tensor.\n",
      "        \n",
      "        In each mask field (`begin_mask`, `end_mask`, `ellipsis_mask`,\n",
      "        `new_axis_mask`, `shrink_axis_mask`) the ith bit will correspond to\n",
      "        the ith spec.\n",
      "        \n",
      "        If the ith bit of `begin_mask` is set, `begin[i]` is ignored and\n",
      "        the fullest possible range in that dimension is used instead.\n",
      "        `end_mask` works analogously, except with the end range.\n",
      "        \n",
      "        `foo[5:,:,:3]` on a 7x8x9 tensor is equivalent to `foo[5:7,0:8,0:3]`.\n",
      "        `foo[::-1]` reverses a tensor with shape 8.\n",
      "        \n",
      "        If the ith bit of `ellipsis_mask` is set, as many unspecified dimensions\n",
      "        as needed will be inserted between other dimensions. Only one\n",
      "        non-zero bit is allowed in `ellipsis_mask`.\n",
      "        \n",
      "        For example `foo[3:5,...,4:5]` on a shape 10x3x3x10 tensor is\n",
      "        equivalent to `foo[3:5,:,:,4:5]` and\n",
      "        `foo[3:5,...]` is equivalent to `foo[3:5,:,:,:]`.\n",
      "        \n",
      "        If the ith bit of `new_axis_mask` is set, then `begin`,\n",
      "        `end`, and `stride` are ignored and a new length 1 dimension is\n",
      "        added at this point in the output tensor.\n",
      "        \n",
      "        For example,\n",
      "        `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.\n",
      "        \n",
      "        If the ith bit of `shrink_axis_mask` is set, it implies that the ith\n",
      "        specification shrinks the dimensionality by 1, taking on the value at index\n",
      "        `begin[i]`. `end[i]` and `strides[i]` are ignored in this case. For example in\n",
      "        Python one might do `foo[:, 3, :]` which would result in `shrink_axis_mask`\n",
      "        equal to 2.\n",
      "        \n",
      "        \n",
      "        NOTE: `begin` and `end` are zero-indexed.\n",
      "        `strides` entries must be non-zero.\n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])  # [[[3, 3, 3]]]\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])  # [[[3, 3, 3],\n",
      "                                                              #   [4, 4, 4]]]\n",
      "        tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])  # [[[4, 4, 4],\n",
      "                                                                 #   [3, 3, 3]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          end: An `int32` or `int64` `Tensor`.\n",
      "          strides: An `int32` or `int64` `Tensor`.\n",
      "          begin_mask: An `int32` mask.\n",
      "          end_mask: An `int32` mask.\n",
      "          ellipsis_mask: An `int32` mask.\n",
      "          new_axis_mask: An `int32` mask.\n",
      "          shrink_axis_mask: An `int32` mask.\n",
      "          var: The variable corresponding to `input_` or None\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input`.\n",
      "    \n",
      "    subtract(x, y, name=None)\n",
      "        Returns x - y element-wise.\n",
      "        \n",
      "        *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Both input and output have a range `(-inf, inf)`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Subtract operation between an array and a scalar:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        \n",
      "        >>> y = 1\n",
      "        \n",
      "        >>> tf.subtract(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        >>> tf.subtract(y, x)\n",
      "        \n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        \n",
      "        numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note that binary `-` operator can be used instead:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        \n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        \n",
      "        >>> x - y\n",
      "        \n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Subtract operation between an array and a tensor of same shape:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        \n",
      "        >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "        \n",
      "        >>> tf.subtract(y, x)\n",
      "        \n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        \n",
      "        numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        \n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        \n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        \n",
      "        conversion.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        \n",
      "        >>> y = [2**8 + 1, 2**8 + 2]\n",
      "        \n",
      "        >>> tf.subtract(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "        \n",
      "        [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "        \n",
      "        . The two input array shapes are compared element-wise. Starting with the\n",
      "        \n",
      "        trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "        \n",
      "        needs to be `1`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        \n",
      "        >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "        \n",
      "        >>> tf.subtract(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "        \n",
      "        array([[[0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0.]],\n",
      "        \n",
      "               [[0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0.]]])>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example with inputs of different dimensions:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        \n",
      "        >>> y = np.ones(6).reshape(1, 6)\n",
      "        \n",
      "        >>> tf.subtract(x, y)\n",
      "        \n",
      "        <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "        \n",
      "        array([[[0., 0., 0., 0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0., 0., 0., 0.]],\n",
      "        \n",
      "               [[0., 0., 0., 0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "        \n",
      "                [0., 0., 0., 0., 0., 0.]]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    switch_case(branch_index, branch_fns, default=None, name='switch_case')\n",
      "        Create a switch/case operation, i.e.\n",
      "        \n",
      "        an integer-indexed conditional.\n",
      "        \n",
      "        See also `tf.case`.\n",
      "        \n",
      "        This op can be substantially more efficient than `tf.case` when exactly one\n",
      "        branch will be selected. `tf.switch_case` is more like a C++ switch/case\n",
      "        statement than `tf.case`, which is more like an if/elif/elif/else chain.\n",
      "        \n",
      "        The `branch_fns` parameter is either a dict from `int` to callables, or list\n",
      "        of (`int`, callable) pairs, or simply a list of callables (in which case the\n",
      "        index is implicitly the key). The `branch_index` `Tensor` is used to select an\n",
      "        element in `branch_fns` with matching `int` key, falling back to `default`\n",
      "        if none match, or `max(keys)` if no `default` is provided. The keys must form\n",
      "        a contiguous set from `0` to `len(branch_fns) - 1`.\n",
      "        \n",
      "        `tf.switch_case` supports nested structures as implemented in `tf.nest`. All\n",
      "        callables must return the same (possibly nested) value structure of lists,\n",
      "        tuples, and/or named tuples.\n",
      "        \n",
      "        **Example:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```c++\n",
      "        switch (branch_index) {  // c-style switch\n",
      "          case 0: return 17;\n",
      "          case 1: return 31;\n",
      "          default: return -1;\n",
      "        }\n",
      "        ```\n",
      "        or\n",
      "        ```python\n",
      "        branches = {0: lambda: 17, 1: lambda: 31}\n",
      "        branches.get(branch_index, lambda: -1)()\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(31)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.switch_case(branch_index, branch_fns={0: f1, 1: f2}, default=f3)\n",
      "        # Equivalent: tf.switch_case(branch_index, branch_fns={0: f1, 1: f2, 2: f3})\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          branch_index: An int Tensor specifying which of `branch_fns` should be\n",
      "            executed.\n",
      "          branch_fns: A `dict` mapping `int`s to callables, or a `list` of (`int`,\n",
      "            callable) pairs, or simply a list of callables (in which case the index\n",
      "            serves as the key). Each callable must return a matching structure of\n",
      "            tensors.\n",
      "          default: Optional callable that returns a structure of tensors.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the callable identified by `branch_index`, or those\n",
      "          returned by `default` if no key matches and `default` was provided, or those\n",
      "          returned by the max-keyed `branch_fn` if no `default` is provided.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `branch_fns` is not a list/dictionary.\n",
      "          TypeError: If `branch_fns` is a list but does not contain 2-tuples or\n",
      "                     callables.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    tan(x, name=None)\n",
      "        Computes tan of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes tangent of every\n",
      "        \n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "        \n",
      "          output range is `(-inf, inf)`. If input lies outside the boundary, `nan`\n",
      "        \n",
      "          is returned.\n",
      "        \n",
      "        \n",
      "        \n",
      "          ```python\n",
      "        \n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        \n",
      "          tf.math.tan(x) ==> [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]\n",
      "        \n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tanh(x, name=None)\n",
      "        Computes hyperbolic tangent of `x` element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic tangent of every\n",
      "        \n",
      "          element in the tensor. Input range is `[-inf, inf]` and\n",
      "        \n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "          >>> x = tf.constant([-float(\"inf\"), -5, -0.5, 1, 1.2, 2, 3, float(\"inf\")])\n",
      "        \n",
      "          >>> tf.math.tanh(x)\n",
      "        \n",
      "          <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
      "        \n",
      "          array([-1.0, -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,\n",
      "        \n",
      "                  0.9640276 ,  0.9950547 ,  1.0], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.tanh(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    tensor_scatter_nd_add = tensor_scatter_add(tensor, indices, updates, name=None)\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        \n",
      "        in `tensor`.\n",
      "        \n",
      "        This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the\n",
      "        \n",
      "        updates are added onto an existing tensor (as opposed to a variable). If the\n",
      "        \n",
      "        memory for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        \n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        \n",
      "        `tensor.shape`.  The last dimension of `indices` can be at most the rank of\n",
      "        \n",
      "        `tensor.shape`:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        indices.shape[-1] <= tensor.shape.rank\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        \n",
      "        (if `indices.shape[-1] = tensor.shape.rank`) or slices\n",
      "        \n",
      "        (if `indices.shape[-1] < tensor.shape.rank`) along dimension\n",
      "        \n",
      "        `indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        indices.shape[:-1] + tensor.shape[indices.shape[-1]:]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The simplest form of `tensor_scatter_nd_add` is to add individual elements to a\n",
      "        \n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        \n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> indices = tf.constant([[4], [3], [1], [7]])\n",
      "        \n",
      "        >>> updates = tf.constant([9, 10, 11, 12])\n",
      "        \n",
      "        >>> tensor = tf.ones([8], dtype=tf.int32)\n",
      "        \n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        \n",
      "        >>> updated\n",
      "        \n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        \n",
      "        numpy=array([ 1, 12,  1, 11, 10,  1,  1, 13], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        \n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        \n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> indices = tf.constant([[0], [2]])\n",
      "        \n",
      "        >>> updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        \n",
      "        ...                        [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        \n",
      "        >>> tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        \n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        \n",
      "        >>> updated\n",
      "        \n",
      "        <tf.Tensor: shape=(4, 4, 4), dtype=int32,\n",
      "        \n",
      "        numpy=array([[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "        \n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "        \n",
      "                     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "        \n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note: on CPU, if an out of bound index is found, an error is returned.\n",
      "        \n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_max = tensor_scatter_max(tensor, indices, updates, name=None)\n",
      "        Apply a sparse update to a tensor taking the element-wise maximum.\n",
      "        \n",
      "        Returns a new tensor copied from `tensor` whose values are element-wise maximum between\n",
      "        \n",
      "        tensor and updates according to the indices.\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "        \n",
      "        >>> indices = [[1], [4], [5]]\n",
      "        \n",
      "        >>> updates = [1, -1, 1]\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_max(tensor, indices, updates).numpy()\n",
      "        \n",
      "        array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int32)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Refer to `tf.tensor_scatter_nd_update` for more details.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_min = tensor_scatter_min(tensor, indices, updates, name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_sub = tensor_scatter_sub(tensor, indices, updates, name=None)\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        \n",
      "        passed in `tensor`.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        \n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        \n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        \n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        \n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "        \n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        \n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        \n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        \n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        \n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        \n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        \n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        \n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        \n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "        \n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "        \n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "        \n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "        \n",
      "            print(updated)\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        \n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        \n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        \n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        \n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        \n",
      "            indices = tf.constant([[0], [2]])\n",
      "        \n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        \n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        \n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        \n",
      "            tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        \n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "        \n",
      "            print(updated)\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "        \n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "        \n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "        \n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "        \n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        \n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the\n",
      "        input `tensor`. This is similar to an index assignment.\n",
      "        \n",
      "        ```\n",
      "        # Not implemented: tensors cannot be updated inplace.\n",
      "        tensor[indices] = updates\n",
      "        ```\n",
      "        \n",
      "        If an out of bound index is found on CPU, an error is returned.\n",
      "        \n",
      "        > **WARNING**: There are some GPU specific semantics for this operation.\n",
      "        >\n",
      "        > - If an out of bound index is found, the index is ignored.\n",
      "        > - The order in which updates are applied is nondeterministic, so the output\n",
      "        >   will be nondeterministic if `indices` contains duplicates.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        In general:\n",
      "        \n",
      "        * `indices` is an integer tensor - the indices to update in `tensor`.\n",
      "        * `indices` has **at least two** axes, the last axis is the depth of the\n",
      "          index vectors.\n",
      "        * For each index vector in `indices` there is a corresponding entry in\n",
      "          `updates`.\n",
      "        * If the length of the index vectors matches the rank of the `tensor`, then\n",
      "          the index vectors each point to scalars in `tensor` and each update is a\n",
      "          scalar.\n",
      "        * If the length of the index vectors is less than the rank of `tensor`, then\n",
      "          the index vectors each point to the slices of `tensor` and shape of the updates\n",
      "          must match that slice.\n",
      "        \n",
      "        Overall this leads to the following shape constraints:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Typical usage is often much simpler than this general form, and it\n",
      "        can be better understood starting with simple examples:\n",
      "        \n",
      "        ### Scalar updates\n",
      "        \n",
      "        The simplest usage inserts scalar elements into a tensor by index.\n",
      "        In this case, the `index_depth` must equal the rank of the\n",
      "        input `tensor`, slice each column of `indices` is an index into an axis of the\n",
      "        input `tensor`.\n",
      "        \n",
      "        In this simplest case the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        assert updates.shape == [num_updates]\n",
      "        assert index_depth == tf.rank(tensor)`\n",
      "        ```\n",
      "        \n",
      "        For example, to insert 4 scattered elements in a rank-1 tensor with\n",
      "        8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "          src=\"https://www.tensorflow.org/images/ScatterNd1.png\">\n",
      "        </div>\n",
      "        \n",
      "        This scatter operation would look like this:\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
      "        >>> indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
      "        >>> updates = [9, 10, 11, 12]            # num_updates == 4\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor([ 0 9  0 10  11  0  0 12], shape=(8,), dtype=int32)\n",
      "        \n",
      "        The length (first axis) of `updates` must equal the length of the `indices`:\n",
      "        `num_updates`. This is the number of updates being inserted. Each scalar\n",
      "        update is inserted into `tensor` at the indexed location.\n",
      "        \n",
      "        For a higher rank input `tensor` scalar updates can be inserted by using an\n",
      "        `index_depth` that matches `tf.rank(tensor)`:\n",
      "        \n",
      "        >>> tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
      "        >>> indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
      "        >>> updates = [5, 10]                    # num_updates == 2\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor(\n",
      "            [[ 1  5]\n",
      "             [ 1  1]\n",
      "             [10  1]], shape=(3, 2), dtype=int32)\n",
      "        \n",
      "        ### Slice updates\n",
      "        \n",
      "        When the input `tensor` has more than one axis scatter can be used to update\n",
      "        entire slices.\n",
      "        \n",
      "        In this case it's helpful to think of the input `tensor` as being a two level\n",
      "        array-of-arrays. The shape of this two level array is split into the\n",
      "        `outer_shape` and the `inner_shape`.\n",
      "        \n",
      "        `indices` indexes into the outer level of the input tensor (`outer_shape`).\n",
      "        and replaces the sub-array at that location with the corresponding item from\n",
      "        the `updates` list. The shape of each update is `inner_shape`.\n",
      "        \n",
      "        When updating a list of slices the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == [num_updates, inner_shape]\n",
      "        ```\n",
      "        \n",
      "        For example, to update rows of a `(6, 3)` `tensor`:\n",
      "        \n",
      "        >>> tensor = tf.zeros([6, 3], dtype=tf.int32)\n",
      "        \n",
      "        Use an index depth of one.\n",
      "        \n",
      "        >>> indices = tf.constant([[2], [4]])     # num_updates == 2, index_depth == 1\n",
      "        >>> num_updates, index_depth = indices.shape.as_list()\n",
      "        \n",
      "        The `outer_shape` is `6`, the inner shape is `3`:\n",
      "        \n",
      "        >>> outer_shape = tensor.shape[:index_depth]\n",
      "        >>> inner_shape = tensor.shape[index_depth:]\n",
      "        \n",
      "        2 rows are being indexed so 2 `updates` must be supplied.\n",
      "        Each update must be shaped to match the `inner_shape`.\n",
      "        \n",
      "        >>> # num_updates == 2, inner_shape==3\n",
      "        >>> updates = tf.constant([[1, 2, 3],\n",
      "        ...                        [4, 5, 6]])\n",
      "        \n",
      "        Altogether this gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [1, 2, 3],\n",
      "               [0, 0, 0],\n",
      "               [4, 5, 6],\n",
      "               [0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        #### More slice update examples\n",
      "        \n",
      "        A tensor representing a batch of uniformly sized video clips naturally has 5\n",
      "        axes: `[batch_size, time, width, height, channels]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> batch_size, time, width, height, channels = 13,11,7,5,3\n",
      "        >>> video_batch = tf.zeros([batch_size, time, width, height, channels])\n",
      "        \n",
      "        To replace a selection of video clips:\n",
      "          * Use an `index_depth` of 1 (indexing the `outer_shape`: `[batch_size]`)\n",
      "          * Provide updates each with a shape matching the `inner_shape`:\n",
      "            `[time, width, height, channels]`.\n",
      "        \n",
      "        To replace the first two clips with ones:\n",
      "        \n",
      "        >>> indices = [[0],[1]]\n",
      "        >>> new_clips = tf.ones([2, time, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_clips)\n",
      "        \n",
      "        To replace a selection of frames in the videos:\n",
      "        \n",
      "        * `indices` must have an `index_depth` of 2 for the `outer_shape`:\n",
      "          `[batch_size, time]`.\n",
      "        * `updates` must be shaped like a list of images.  Each update must have a\n",
      "          shape, matching the `inner_shape`: `[width, height, channels]`.\n",
      "        \n",
      "        To replace the first frame of the first three video clips:\n",
      "        \n",
      "        >>> indices = [[0, 0], [1, 0], [2, 0]] # num_updates=3, index_depth=2\n",
      "        >>> new_images = tf.ones([\n",
      "        ...   # num_updates=3, inner_shape=(width, height, channels)\n",
      "        ...   3, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_images)\n",
      "        \n",
      "        ### Folded indices\n",
      "        \n",
      "        In simple cases it's convenient to think of `indices` and `updates` as\n",
      "        lists, but this is not a strict requirement. Instead of a flat `num_updates`,\n",
      "        the `indices` and `updates` can be folded into a `batch_shape`. This\n",
      "        `batch_shape` is all axes of the `indices`, except for the innermost\n",
      "        `index_depth` axis.\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        Note: The one exception is that the `batch_shape` cannot be `[]`. You can't\n",
      "        update a single index by passing indices with shape `[index_depth]`.\n",
      "        \n",
      "        `updates` must have a matching `batch_shape` (the axes before `inner_shape`).\n",
      "        \n",
      "        ```\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Note: The result is equivalent to flattening the `batch_shape` axes of\n",
      "        `indices` and `updates`. This generalization just avoids the need\n",
      "        for reshapes when it is more natural to construct \"folded\" indices and\n",
      "        updates.\n",
      "        \n",
      "        With this generalization the full shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        For example, to draw an `X` on a `(5,5)` matrix start with these indices:\n",
      "        \n",
      "        >>> tensor = tf.zeros([5,5])\n",
      "        >>> indices = tf.constant([\n",
      "        ...  [[0,0],\n",
      "        ...   [1,1],\n",
      "        ...   [2,2],\n",
      "        ...   [3,3],\n",
      "        ...   [4,4]],\n",
      "        ...  [[0,4],\n",
      "        ...   [1,3],\n",
      "        ...   [2,2],\n",
      "        ...   [3,1],\n",
      "        ...   [4,0]],\n",
      "        ... ])\n",
      "        >>> indices.shape.as_list()  # batch_shape == [2, 5], index_depth == 2\n",
      "        [2, 5, 2]\n",
      "        \n",
      "        Here the `indices` do not have a shape of `[num_updates, index_depth]`, but a\n",
      "        shape of `batch_shape+[index_depth]`.\n",
      "        \n",
      "        Since the `index_depth` is equal to the rank of `tensor`:\n",
      "        \n",
      "        * `outer_shape` is `(5,5)`\n",
      "        * `inner_shape` is `()` - each update is scalar\n",
      "        * `updates.shape` is `batch_shape + inner_shape == (5,2) + ()`\n",
      "        \n",
      "        >>> updates = [\n",
      "        ...   [1,1,1,1,1],\n",
      "        ...   [1,1,1,1,1],\n",
      "        ... ]\n",
      "        \n",
      "        Putting this together gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[1., 0., 0., 0., 1.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [0., 0., 1., 0., 0.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [1., 0., 0., 0., 1.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          tensor: Tensor to copy/update.\n",
      "          indices: Indices to update.\n",
      "          updates: Updates to apply at the indices.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A new tensor with the given shape and updates applied according to the\n",
      "          indices.\n",
      "    \n",
      "    tensordot(a, b, axes, name=None)\n",
      "        Tensor contraction of a and b along specified axes and outer product.\n",
      "        \n",
      "        Tensordot (also known as tensor contraction) sums the product of elements\n",
      "        from `a` and `b` over the indices specified by `axes`.\n",
      "        \n",
      "        This operation corresponds to `numpy.tensordot(a, b, axes)`.\n",
      "        \n",
      "        Example 1: When `a` and `b` are matrices (order 2), the case `axes=1`\n",
      "        is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 2: When `a` and `b` are matrices (order 2), the case\n",
      "        `axes = [[1], [0]]` is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 3: When `a` and `b` are matrices (order 2), the case `axes=0` gives\n",
      "        the outer product, a tensor of order 4.\n",
      "        \n",
      "        Example 4: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n",
      "        tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n",
      "        \\\\(c_{jklm}\\\\) whose entry\n",
      "        corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n",
      "        \n",
      "        \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n",
      "        \n",
      "        In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n",
      "        \n",
      "        Args:\n",
      "          a: `Tensor` of type `float32` or `float64`.\n",
      "          b: `Tensor` with the same type as `a`.\n",
      "          axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n",
      "            If axes is a scalar, sum over the last N axes of a and the first N axes of\n",
      "            b in order. If axes is a list or `Tensor` the first and second row contain\n",
      "            the set of unique integers specifying axes along which the contraction is\n",
      "            computed, for `a` and `b`, respectively. The number of axes for `a` and\n",
      "            `b` must be equal. If `axes=0`, computes the outer product between `a` and\n",
      "            `b`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type as `a`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n",
      "          IndexError: If the values in axes exceed the rank of the corresponding\n",
      "            tensor.\n",
      "    \n",
      "    tile(input, multiples, name=None)\n",
      "        Constructs a tensor by tiling a given tensor.\n",
      "        \n",
      "        This operation creates a new tensor by replicating `input` `multiples` times.\n",
      "        \n",
      "        The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,\n",
      "        \n",
      "        and the values of `input` are replicated `multiples[i]` times along the 'i'th\n",
      "        \n",
      "        dimension. For example, tiling `[a b c d]` by `[2]` produces\n",
      "        \n",
      "        `[a b c d a b c d]`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
      "        \n",
      "        >>> b = tf.constant([1,2], tf.int32)\n",
      "        \n",
      "        >>> tf.tile(a, b)\n",
      "        \n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        \n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "        \n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        >>> c = tf.constant([2,1], tf.int32)\n",
      "        \n",
      "        >>> tf.tile(a, c)\n",
      "        \n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        \n",
      "        array([[1, 2, 3],\n",
      "        \n",
      "               [4, 5, 6],\n",
      "        \n",
      "               [1, 2, 3],\n",
      "        \n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        >>> d = tf.constant([2,2], tf.int32)\n",
      "        \n",
      "        >>> tf.tile(a, d)\n",
      "        \n",
      "        <tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
      "        \n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "        \n",
      "               [4, 5, 6, 4, 5, 6],\n",
      "        \n",
      "               [1, 2, 3, 1, 2, 3],\n",
      "        \n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 1-D or higher.\n",
      "          multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. Length must be the same as the number of dimensions in `input`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    timestamp(name=None)\n",
      "        Provides the time since epoch in seconds.\n",
      "        \n",
      "        Returns the timestamp as a `float64` for seconds since the Unix epoch.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Common usages include:\n",
      "        \n",
      "        * Logging\n",
      "        \n",
      "        * Providing a random number seed\n",
      "        \n",
      "        * Debugging graph execution\n",
      "        \n",
      "        * Generating timing information, mainly through comparison of timestamps\n",
      "        \n",
      "        \n",
      "        \n",
      "        Note: In graph mode, the timestamp is computed when the op is executed,\n",
      "        \n",
      "        not when it is added to the graph.  In eager mode, the timestamp is computed\n",
      "        \n",
      "        when the op is eagerly executed.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float64`.\n",
      "    \n",
      "    transpose = transpose_v2(a, perm=None, conjugate=False, name='transpose')\n",
      "        Transposes `a`, where `a` is a Tensor.\n",
      "        \n",
      "        Permutes the dimensions according to the value of `perm`.\n",
      "        \n",
      "        The returned tensor's dimension `i` will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
      "        of the input tensor. Hence, by default, this operation performs a regular\n",
      "        matrix transpose on 2-D input Tensors.\n",
      "        \n",
      "        If conjugate is `True` and `a.dtype` is either `complex64` or `complex128`\n",
      "        then the values of `a` are conjugated and transposed.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
      "        the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        >>> tf.transpose(x)\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)>\n",
      "        \n",
      "        Equivalently, you could call `tf.transpose(x, perm=[1, 0])`.\n",
      "        \n",
      "        If `x` is complex, setting conjugate=True gives the conjugate transpose:\n",
      "        \n",
      "        >>> x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "        ...                  [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        >>> tf.transpose(x, conjugate=True)\n",
      "        <tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
      "        array([[1.-1.j, 4.-4.j],\n",
      "               [2.-2.j, 5.-5.j],\n",
      "               [3.-3.j, 6.-6.j]])>\n",
      "        \n",
      "        'perm' is more useful for n-dimensional tensors where n > 2:\n",
      "        \n",
      "        >>> x = tf.constant([[[ 1,  2,  3],\n",
      "        ...                   [ 4,  5,  6]],\n",
      "        ...                  [[ 7,  8,  9],\n",
      "        ...                   [10, 11, 12]]])\n",
      "        \n",
      "        As above, simply calling `tf.transpose` will default to `perm=[2,1,0]`.\n",
      "        \n",
      "        To take the transpose of the matrices in dimension-0 (such as when you are\n",
      "        transposing matrices where 0 is the batch dimension), you would set\n",
      "        `perm=[0,2,1]`.\n",
      "        \n",
      "        >>> tf.transpose(x, perm=[0, 2, 1])\n",
      "        <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "        array([[[ 1,  4],\n",
      "                [ 2,  5],\n",
      "                [ 3,  6]],\n",
      "                [[ 7, 10],\n",
      "                [ 8, 11],\n",
      "                [ 9, 12]]], dtype=int32)>\n",
      "        \n",
      "        Note: This has a shorthand `linalg.matrix_transpose`):\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`.\n",
      "          perm: A permutation of the dimensions of `a`.  This should be a vector.\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.transpose(input)).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `Tensor`.\n",
      "    \n",
      "    truediv(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "        \n",
      "        NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "        division operator semantics.\n",
      "        \n",
      "        This function forces Python 3 division operator semantics where all integer\n",
      "        arguments are cast to floating types first.   This op is generated by normal\n",
      "        `x / y` division in Python 3 and in Python 2.7 with\n",
      "        `from __future__ import division`.  If you want integer division that rounds\n",
      "        down, use `x // y` or `tf.math.floordiv`.\n",
      "        \n",
      "        `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "        point, the output will have the same type.  If the inputs are integral, the\n",
      "        inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "        and `int64` (matching the behavior of Numpy).\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of numeric type.\n",
      "          y: `Tensor` denominator of numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` evaluated in floating point.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` and `y` have different dtypes.\n",
      "    \n",
      "    truncatediv = truncate_div(x, y, name=None)\n",
      "        Returns x / y element-wise, rounded towards zero.\n",
      "        \n",
      "        Truncation designates that negative numbers will round fractional quantities\n",
      "        \n",
      "        toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different\n",
      "        \n",
      "        than Python semantics. See `FloorDiv` for a division function that matches\n",
      "        \n",
      "        Python Semantics.\n",
      "        \n",
      "        \n",
      "        \n",
      "        *NOTE*: `truncatediv` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    truncatemod = truncate_mod(x, y, name=None)\n",
      "        Returns element-wise remainder of division. This emulates C semantics in that\n",
      "        \n",
      "        the result here is consistent with a truncating divide. E.g. `truncate(x / y) *\n",
      "        \n",
      "        y + truncate_mod(x, y) = x`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        *NOTE*: `truncatemod` supports broadcasting. More about broadcasting\n",
      "        \n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tuple = tuple_v2(tensors, control_inputs=None, name=None)\n",
      "        Groups tensors together.\n",
      "        \n",
      "        The returned tensors have the same value as the input tensors, but they\n",
      "        are computed only after all the input tensors have been computed.\n",
      "        \n",
      "        Note: *In TensorFlow 2 with eager and/or Autograph, you should not require\n",
      "        this method, as ops execute in the expected order thanks to automatic control\n",
      "        dependencies.* Only use `tf.tuple` when working with v1 `tf.Graph` code.\n",
      "        \n",
      "        See also `tf.group` and `tf.control_dependencies`.\n",
      "        \n",
      "        Example:\n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     v = tf.Variable(0.0)\n",
      "        ...     a = tf.constant(1.0)\n",
      "        ...     sess.run(tf.compat.v1.global_variables_initializer())\n",
      "        ...     for i in range(5):\n",
      "        ...       update_op = v.assign_add(1.0)\n",
      "        ...       b = a + v\n",
      "        ...       res_b = sess.run(b)\n",
      "        ...       res_v = sess.run(v)\n",
      "        ...       print(res_v)\n",
      "        0.0\n",
      "        0.0\n",
      "        0.0\n",
      "        0.0\n",
      "        0.0\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     v = tf.Variable(0.0)\n",
      "        ...     a = tf.constant(1.0)\n",
      "        ...     sess.run(tf.compat.v1.global_variables_initializer())\n",
      "        ...     for i in range(5):\n",
      "        ...       update_op = v.assign_add(1.0)\n",
      "        ...       calc = [a + v]\n",
      "        ...       # `tf.tuple` ensures `update_op` is run before `b`\n",
      "        ...       b = tf.tuple(calc, [tf.group(update_op)])\n",
      "        ...       res_b = sess.run(b)\n",
      "        ...       res_v = sess.run(v)\n",
      "        ...       print(res_v)\n",
      "        1.0\n",
      "        2.0\n",
      "        3.0\n",
      "        4.0\n",
      "        5.0\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          tensors: A list of `Tensor`s or `IndexedSlices`, some entries can be `None`.\n",
      "          control_inputs: List of additional ops to finish before returning.\n",
      "          name: (optional) A name to use as a `name_scope` for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          Same as `tensors`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `tensors` does not contain any `Tensor` or `IndexedSlices`.\n",
      "          TypeError: If `control_inputs` is not a list of `Operation` or `Tensor`\n",
      "            objects.\n",
      "    \n",
      "    type_spec_from_value(value) -> tensorflow.python.framework.type_spec.TypeSpec\n",
      "        Returns a `tf.TypeSpec` that represents the given `value`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tf.type_spec_from_value(tf.constant([1, 2, 3]))\n",
      "          TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "          >>> tf.type_spec_from_value(np.array([4.0, 5.0], np.float64))\n",
      "          TensorSpec(shape=(2,), dtype=tf.float64, name=None)\n",
      "          >>> tf.type_spec_from_value(tf.ragged.constant([[1, 2], [3, 4, 5]]))\n",
      "          RaggedTensorSpec(TensorShape([2, None]), tf.int32, 1, tf.int64)\n",
      "        \n",
      "          >>> example_input = tf.ragged.constant([[1, 2], [3]])\n",
      "          >>> @tf.function(input_signature=[tf.type_spec_from_value(example_input)])\n",
      "          ... def f(x):\n",
      "          ...   return tf.reduce_sum(x, axis=1)\n",
      "        \n",
      "        Args:\n",
      "          value: A value that can be accepted or returned by TensorFlow APIs. Accepted\n",
      "            types for `value` include `tf.Tensor`, any value that can be converted to\n",
      "            `tf.Tensor` using `tf.convert_to_tensor`, and any subclass of\n",
      "            `CompositeTensor` (such as `tf.RaggedTensor`).\n",
      "        \n",
      "        Returns:\n",
      "          A `TypeSpec` that is compatible with `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If a TypeSpec cannot be built for `value`, because its type\n",
      "            is not supported.\n",
      "    \n",
      "    unique(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        \n",
      "        sorted in the same order that they occur in `x`; `x` does not need to be sorted.\n",
      "        \n",
      "        This operation also returns a tensor `idx` the same size as `x` that contains\n",
      "        \n",
      "        the index of each value of `x` in the unique output `y`. In other words:\n",
      "        \n",
      "        \n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        \n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        \n",
      "        y, idx = unique(x)\n",
      "        \n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        \n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        # tensor 'x' is [4, 5, 1, 2, 3, 3, 4, 5]\n",
      "        \n",
      "        y, idx = unique(x)\n",
      "        \n",
      "        y ==> [4, 5, 1, 2, 3]\n",
      "        \n",
      "        idx ==> [0, 1, 2, 3, 4, 4, 0, 1]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unique_with_counts(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        \n",
      "        sorted in the same order that they occur in `x`. This operation also returns a\n",
      "        \n",
      "        tensor `idx` the same size as `x` that contains the index of each value of `x`\n",
      "        \n",
      "        in the unique output `y`. Finally, it returns a third tensor `count` that\n",
      "        \n",
      "        contains the count of each element of `y` in `x`. In other words:\n",
      "        \n",
      "        \n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        \n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        \n",
      "        y, idx, count = unique_with_counts(x)\n",
      "        \n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        \n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        \n",
      "        count ==> [2, 1, 3, 1, 2]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx, count).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "          count: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unravel_index(indices, dims, name=None)\n",
      "        Converts an array of flat indices into a tuple of coordinate arrays.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ```\n",
      "        \n",
      "        y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])\n",
      "        \n",
      "        # 'dims' represent a hypothetical (3, 3) tensor of indices:\n",
      "        \n",
      "        # [[0, 1, *2*],\n",
      "        \n",
      "        #  [3, 4, *5*],\n",
      "        \n",
      "        #  [6, *7*, 8]]\n",
      "        \n",
      "        # For each entry from 'indices', this operation returns\n",
      "        \n",
      "        # its coordinates (marked with '*'), such as\n",
      "        \n",
      "        # 2 ==> (0, 2)\n",
      "        \n",
      "        # 5 ==> (1, 2)\n",
      "        \n",
      "        # 7 ==> (2, 1)\n",
      "        \n",
      "        y ==> [[0, 1, 2], [2, 2, 1]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        \n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        \n",
      "        Equivalent to np.unravel_index\n",
      "        \n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 0-D or 1-D `int` Tensor whose elements are indices into the\n",
      "        \n",
      "            flattened version of an array of dimensions dims.\n",
      "          dims: A `Tensor`. Must have the same type as `indices`.\n",
      "            An 1-D `int` Tensor. The shape of the array to use for unraveling\n",
      "        \n",
      "            indices.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `indices`.\n",
      "    \n",
      "    unstack(value, num=None, axis=0, name='unstack')\n",
      "        Unpacks the given dimension of a rank-`R` tensor into rank-`(R-1)` tensors.\n",
      "        \n",
      "        Unpacks tensors from `value` by chipping it along the `axis` dimension.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(12), (3,4))\n",
      "        >>>\n",
      "        >>> p, q, r = tf.unstack(x)\n",
      "        >>> p.shape.as_list()\n",
      "        [4]\n",
      "        \n",
      "        >>> i, j, k, l = tf.unstack(x, axis=1)\n",
      "        >>> i.shape.as_list()\n",
      "        [3]\n",
      "        \n",
      "        This is the opposite of stack.\n",
      "        \n",
      "        >>> x = tf.stack([i, j, k, l], axis=1)\n",
      "        \n",
      "        More generally if you have a tensor of shape `(A, B, C, D)`:\n",
      "        \n",
      "        >>> A, B, C, D = [2, 3, 4, 5]\n",
      "        >>> t = tf.random.normal(shape=[A, B, C, D])\n",
      "        \n",
      "        The number of tensor returned is equal to the length of the target `axis`:\n",
      "        \n",
      "        >>> axis = 2\n",
      "        >>> items = tf.unstack(t, axis=axis)\n",
      "        >>> len(items) == t.shape[axis]\n",
      "        True\n",
      "        \n",
      "        The shape of each result tensor is equal to the shape of the input tensor,\n",
      "        with the target `axis` removed.\n",
      "        \n",
      "        >>> items[0].shape.as_list()  # [A, B, D]\n",
      "        [2, 3, 5]\n",
      "        \n",
      "        The value of each tensor `items[i]` is equal to the slice of `input` across\n",
      "        `axis` at index `i`:\n",
      "        \n",
      "        >>> for i in range(len(items)):\n",
      "        ...   slice = t[:,:,i,:]\n",
      "        ...   assert tf.reduce_all(slice == items[i])\n",
      "        \n",
      "        #### Python iterable unpacking\n",
      "        \n",
      "        With eager execution you _can_ unstack the 0th axis of a tensor using python's\n",
      "        iterable unpacking:\n",
      "        \n",
      "        >>> t = tf.constant([1,2,3])\n",
      "        >>> a,b,c = t\n",
      "        \n",
      "        `unstack` is still necessary because Iterable unpacking doesn't work in\n",
      "        a `@tf.function`: Symbolic tensors are not iterable.\n",
      "        \n",
      "        You need to use `tf.unstack` here:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad(t):\n",
      "        ...   a,b,c = t\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> bad(t)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        OperatorNotAllowedInGraphError: ...\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def good(t):\n",
      "        ...   a,b,c = tf.unstack(t)\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> good(t).numpy()\n",
      "        1\n",
      "        \n",
      "        #### Unknown shapes\n",
      "        \n",
      "        Eager tensors have concrete values, so their shape is always known.\n",
      "        Inside a `tf.function` the symbolic tensors may have unknown shapes.\n",
      "        If the length of `axis` is unknown `tf.unstack` will fail because it cannot\n",
      "        handle an unknown number of tensors:\n",
      "        \n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec([None], tf.float32)])\n",
      "        ... def bad(t):\n",
      "        ...   tensors = tf.unstack(t)\n",
      "        ...   return tensors[0]\n",
      "        >>>\n",
      "        >>> bad(tf.constant([1.0, 2.0, 3.0]))\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Cannot infer argument `num` from shape (None,)\n",
      "        \n",
      "        If you know the `axis` length you can pass it as the `num` argument. But this\n",
      "        must be a constant value.\n",
      "        \n",
      "        If you actually need a variable number of tensors in a single `tf.function`\n",
      "        trace, you will need to use exlicit loops and a `tf.TensorArray` instead.\n",
      "        \n",
      "        Args:\n",
      "          value: A rank `R > 0` `Tensor` to be unstacked.\n",
      "          num: An `int`. The length of the dimension `axis`. Automatically inferred if\n",
      "            `None` (the default).\n",
      "          axis: An `int`. The axis to unstack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-R, R)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The list of `Tensor` objects unstacked from `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range `[-R, R)`.\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          InvalidArgumentError: If `num` does not match the shape of `value`.\n",
      "    \n",
      "    variable_creator_scope(variable_creator)\n",
      "        Scope which defines a variable creation function to be used by variable().\n",
      "        \n",
      "        variable_creator is expected to be a function with the following signature:\n",
      "        \n",
      "        ```\n",
      "          def variable_creator(next_creator, **kwargs)\n",
      "        ```\n",
      "        \n",
      "        The creator is supposed to eventually call the next_creator to create a\n",
      "        variable if it does want to create a variable and not call Variable or\n",
      "        ResourceVariable directly. This helps make creators composable. A creator may\n",
      "        choose to create multiple variables, return already existing variables, or\n",
      "        simply register that a variable was created and defer to the next creators in\n",
      "        line. Creators can also modify the keyword arguments seen by the next\n",
      "        creators.\n",
      "        \n",
      "        Custom getters in the variable scope will eventually resolve down to these\n",
      "        custom creators when they do create variables.\n",
      "        \n",
      "        The valid keyword arguments in kwds are:\n",
      "        \n",
      "         * initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "              which is the initial value for the Variable. The initial value must have\n",
      "              a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "              callable with no argument that returns the initial value when called. In\n",
      "              that case, `dtype` must be specified. (Note that initializer functions\n",
      "              from init_ops.py must first be bound to a shape before being used here.)\n",
      "         * trainable: If `True`, the default, GradientTapes automatically watch\n",
      "              uses of this Variable.\n",
      "         * validate_shape: If `False`, allows the variable to be initialized with a\n",
      "              value of unknown shape. If `True`, the default, the shape of\n",
      "              `initial_value` must be known.\n",
      "         * caching_device: Optional device string describing where the Variable\n",
      "              should be cached for reading.  Defaults to the Variable's device.\n",
      "              If not `None`, caches on another device.  Typical use is to cache\n",
      "              on the device where the Ops using the Variable reside, to deduplicate\n",
      "              copying through `Switch` and other conditional statements.\n",
      "         * name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "              uniquified automatically.\n",
      "            dtype: If set, initial_value will be converted to the given type.\n",
      "              If `None`, either the datatype will be kept (if `initial_value` is\n",
      "              a Tensor), or `convert_to_tensor` will decide.\n",
      "         * constraint: A constraint function to be applied to the variable after\n",
      "              updates by some algorithms.\n",
      "         * synchronization: Indicates when a distributed a variable will be\n",
      "              aggregated. Accepted values are constants defined in the class\n",
      "              `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "              `AUTO` and the current `DistributionStrategy` chooses\n",
      "              when to synchronize.\n",
      "         * aggregation: Indicates how a distributed variable will be aggregated.\n",
      "              Accepted values are constants defined in the class\n",
      "              `tf.VariableAggregation`.\n",
      "        \n",
      "        This set may grow over time, so it's important the signature of creators is as\n",
      "        mentioned above.\n",
      "        \n",
      "        Args:\n",
      "          variable_creator: the passed creator\n",
      "        \n",
      "        Yields:\n",
      "          A scope in which the creator is active\n",
      "    \n",
      "    vectorized_map(fn, elems, fallback_to_while_loop=True, warn=True)\n",
      "        Parallel map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This method works similar to `tf.map_fn` but is optimized to run much faster,\n",
      "        possibly with a much larger memory footprint. The speedups are obtained by\n",
      "        vectorization (see [Auto-Vectorizing TensorFlow Graphs: Jacobians,\n",
      "        Auto-Batching and Beyond](https://arxiv.org/pdf/1903.04243.pdf)). The idea\n",
      "        behind vectorization is to semantically launch all the invocations of `fn` in\n",
      "        parallel and fuse corresponding operations across all these invocations. This\n",
      "        fusion is done statically at graph generation time and the generated code is\n",
      "        often similar in performance to a manually fused version.\n",
      "        \n",
      "        Because `tf.vectorized_map` fully parallelizes the batch, this method will\n",
      "        generally be significantly faster than using `tf.map_fn`, especially in eager\n",
      "        mode. However this is an experimental feature and currently has a lot of\n",
      "        limitations:\n",
      "          - There should be no data dependency between the different semantic\n",
      "            invocations of `fn`, i.e. it should be safe to map the elements of the\n",
      "            inputs in any order.\n",
      "          - Stateful kernels may mostly not be supported since these often imply a\n",
      "            data dependency. We do support a limited set of such stateful kernels\n",
      "            though (like RandomFoo, Variable operations like reads, etc).\n",
      "          - `fn` has limited support for control flow operations.\n",
      "          - `fn` should return nested structure of Tensors or Operations. However\n",
      "            if an Operation is returned, it should have zero outputs.\n",
      "          - The shape and dtype of any intermediate or output tensors in the\n",
      "            computation of `fn` should not depend on the input to `fn`.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "        def outer_product(a):\n",
      "          return tf.tensordot(a, a, 0)\n",
      "        \n",
      "        batch_size = 100\n",
      "        a = tf.ones((batch_size, 32, 32))\n",
      "        c = tf.vectorized_map(outer_product, a)\n",
      "        assert c.shape == (batch_size, 32, 32, 32, 32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "        # Computing per-example gradients\n",
      "        \n",
      "        batch_size = 10\n",
      "        num_features = 32\n",
      "        layer = tf.keras.layers.Dense(1)\n",
      "        \n",
      "        def model_fn(arg):\n",
      "          with tf.GradientTape() as g:\n",
      "            inp, label = arg\n",
      "            inp = tf.expand_dims(inp, 0)\n",
      "            label = tf.expand_dims(label, 0)\n",
      "            prediction = layer(inp)\n",
      "            loss = tf.nn.l2_loss(label - prediction)\n",
      "          return g.gradient(loss, (layer.kernel, layer.bias))\n",
      "        \n",
      "        inputs = tf.random.uniform([batch_size, num_features])\n",
      "        labels = tf.random.uniform([batch_size, 1])\n",
      "        per_example_gradients = tf.vectorized_map(model_fn, (inputs, labels))\n",
      "        assert per_example_gradients[0].shape == (batch_size, num_features, 1)\n",
      "        assert per_example_gradients[1].shape == (batch_size, 1)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed. It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`, and returns a possibly\n",
      "            nested structure of Tensors and Operations, which may be different than\n",
      "            the structure of `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension. The nested sequence of the\n",
      "            resulting slices will be mapped over by `fn`. The first dimensions of all\n",
      "            elements must broadcast to a consistent value; equivalently, each\n",
      "            element tensor must have first dimension of either `B` or `1`, for some\n",
      "            common batch size `B >= 1`.\n",
      "          fallback_to_while_loop: If true, on failing to vectorize an operation,\n",
      "            the unsupported op is wrapped in a tf.while_loop to execute the map\n",
      "            iterations. Note that this fallback only happens for unsupported ops and\n",
      "            other parts of `fn` are still vectorized. If false, on encountering an\n",
      "            unsupported op, a ValueError is thrown. Note that the fallbacks can result\n",
      "            in slowdowns since vectorization often yields speedup of one to two orders\n",
      "            of magnitude.\n",
      "          warn: If set to `false`, this will supress any warnings due to operation\n",
      "          conversions in the provided `fn` falling back to while loops.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors. Each tensor packs the\n",
      "          results of applying fn to tensors unpacked from elems along the first\n",
      "          dimension, from first to last.\n",
      "        \n",
      "          Although they are less common as user-visible inputs and outputs, note that\n",
      "          tensors of type `tf.variant` which represent tensor lists (for example from\n",
      "          `tf.raw_ops.TensorListFromTensor`) are vectorized by stacking the list\n",
      "          contents rather than the variant itself, and so the container tensor will\n",
      "          have a scalar shape when returned rather than the usual stacked shape. This\n",
      "          improves the performance of control flow gradient vectorization.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If vectorization fails and fallback_to_while_loop is False.\n",
      "    \n",
      "    where = where_v2(condition, x=None, y=None, name=None)\n",
      "        Returns the indices of non-zero elements, or multiplexes `x` and `y`.\n",
      "        \n",
      "        This operation has two modes:\n",
      "        \n",
      "        1. **Return the indices of non-zero elements** - When only\n",
      "           `condition` is provided the result is an `int64` tensor where each row is\n",
      "           the index of a non-zero element of `condition`. The result's shape\n",
      "           is `[tf.math.count_nonzero(condition), tf.rank(condition)]`.\n",
      "        2. **Multiplex `x` and `y`** - When both `x` and `y` are provided the\n",
      "           result has the shape of `x`, `y`, and `condition` broadcast together. The\n",
      "           result is taken from `x` where `condition` is non-zero\n",
      "           or `y` where `condition` is zero.\n",
      "        \n",
      "        #### 1. Return the indices of non-zero elements\n",
      "        \n",
      "        Note: In this mode `condition` can have a dtype of `bool` or any numeric\n",
      "        dtype.\n",
      "        \n",
      "        If `x` and `y` are not provided (both are None):\n",
      "        \n",
      "        `tf.where` will return the indices of `condition` that are non-zero,\n",
      "        in the form of a 2-D tensor with shape `[n, d]`, where `n` is the number of\n",
      "        non-zero elements in `condition` (`tf.count_nonzero(condition)`), and `d` is\n",
      "        the number of axes of `condition` (`tf.rank(condition)`).\n",
      "        \n",
      "        Indices are output in row-major order. The `condition` can have a `dtype` of\n",
      "        `tf.bool`, or any numeric `dtype`.\n",
      "        \n",
      "        Here `condition` is a 1-axis `bool` tensor with 2 `True` values. The result\n",
      "        has a shape of `[2,1]`\n",
      "        \n",
      "        >>> tf.where([True, False, False, True]).numpy()\n",
      "        array([[0],\n",
      "               [3]])\n",
      "        \n",
      "        Here `condition` is a 2-axis integer tensor, with 3 non-zero values. The\n",
      "        result has a shape of `[3, 2]`.\n",
      "        \n",
      "        >>> tf.where([[1, 0, 0], [1, 0, 1]]).numpy()\n",
      "        array([[0, 0],\n",
      "               [1, 0],\n",
      "               [1, 2]])\n",
      "        \n",
      "        Here `condition` is a 3-axis float tensor, with 5 non-zero values. The output\n",
      "        shape is `[5, 3]`.\n",
      "        \n",
      "        >>> float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],\n",
      "        ...                 [[0,   0], [0,   0], [99,    0]]]\n",
      "        >>> tf.where(float_tensor).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        These indices are the same that `tf.sparse.SparseTensor` would use to\n",
      "        represent the condition tensor:\n",
      "        \n",
      "        >>> sparse = tf.sparse.from_dense(float_tensor)\n",
      "        >>> sparse.indices.numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        A complex number is considered non-zero if either the real or imaginary\n",
      "        component is non-zero:\n",
      "        \n",
      "        >>> tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()\n",
      "        array([[1],\n",
      "               [2],\n",
      "               [3]])\n",
      "        \n",
      "        #### 2. Multiplex `x` and `y`\n",
      "        \n",
      "        Note: In this mode `condition` must have a dtype of `bool`.\n",
      "        \n",
      "        If `x` and `y` are also provided (both have non-None values) the `condition`\n",
      "        tensor acts as a mask that chooses whether the corresponding\n",
      "        element / row in the output should be taken from `x` (if the element in\n",
      "        `condition` is `True`) or `y` (if it is `False`).\n",
      "        \n",
      "        The shape of the result is formed by\n",
      "        [broadcasting](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\n",
      "        together the shapes of `condition`, `x`, and `y`.\n",
      "        \n",
      "        When all three inputs have the same size, each is handled element-wise.\n",
      "        \n",
      "        >>> tf.where([True, False, False, True],\n",
      "        ...          [1, 2, 3, 4],\n",
      "        ...          [100, 200, 300, 400]).numpy()\n",
      "        array([  1, 200, 300,   4], dtype=int32)\n",
      "        \n",
      "        There are two main rules for broadcasting:\n",
      "        \n",
      "        1. If a tensor has fewer axes than the others, length-1 axes are added to the\n",
      "           left of the shape.\n",
      "        2. Axes with length-1 are streched to match the coresponding axes of the other\n",
      "           tensors.\n",
      "        \n",
      "        A length-1 vector is streched to match the other vectors:\n",
      "        \n",
      "        >>> tf.where([True, False, False, True], [1, 2, 3, 4], [100]).numpy()\n",
      "        array([  1, 100, 100,   4], dtype=int32)\n",
      "        \n",
      "        A scalar is expanded to match the other arguments:\n",
      "        \n",
      "        >>> tf.where([[True, False], [False, True]], [[1, 2], [3, 4]], 100).numpy()\n",
      "        array([[  1, 100], [100,   4]], dtype=int32)\n",
      "        >>> tf.where([[True, False], [False, True]], 1, 100).numpy()\n",
      "        array([[  1, 100], [100,   1]], dtype=int32)\n",
      "        \n",
      "        A scalar `condition` returns the complete `x` or `y` tensor, with\n",
      "        broadcasting applied.\n",
      "        \n",
      "        >>> tf.where(True, [1, 2, 3, 4], 100).numpy()\n",
      "        array([1, 2, 3, 4], dtype=int32)\n",
      "        >>> tf.where(False, [1, 2, 3, 4], 100).numpy()\n",
      "        array([100, 100, 100, 100], dtype=int32)\n",
      "        \n",
      "        For a non-trivial example of broadcasting, here `condition` has a shape of\n",
      "        `[3]`, `x` has a shape of `[3,3]`, and `y` has a shape of `[3,1]`.\n",
      "        Broadcasting first expands the shape of `condition` to `[1,3]`. The final\n",
      "        broadcast shape is `[3,3]`. `condition` will select columns from `x` and `y`.\n",
      "        Since `y` only has one column, all columns from `y` will be identical.\n",
      "        \n",
      "        >>> tf.where([True, False, True],\n",
      "        ...          x=[[1, 2, 3],\n",
      "        ...             [4, 5, 6],\n",
      "        ...             [7, 8, 9]],\n",
      "        ...          y=[[100],\n",
      "        ...             [200],\n",
      "        ...             [300]]\n",
      "        ... ).numpy()\n",
      "        array([[ 1, 100, 3],\n",
      "               [ 4, 200, 6],\n",
      "               [ 7, 300, 9]], dtype=int32)\n",
      "        \n",
      "        Note that if the gradient of either branch of the `tf.where` generates\n",
      "        a `NaN`, then the gradient of the entire `tf.where` will be `NaN`. This is\n",
      "        because the gradient calculation for `tf.where` combines the two branches, for\n",
      "        performance reasons.\n",
      "        \n",
      "        A workaround is to use an inner `tf.where` to ensure the function has\n",
      "        no asymptote, and to avoid computing a value whose gradient is `NaN` by\n",
      "        replacing dangerous inputs with safe inputs.\n",
      "        \n",
      "        Instead of this,\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(nan, shape=(), dtype=float32)\n",
      "        \n",
      "        Although, the `1. / x` values are never used, its gradient is a `NaN` when\n",
      "        `x = 0`. Instead, we should guard that with another `tf.where`\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   safe_x = tf.where(tf.equal(x, 0.), 1., x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / safe_x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.sparse` - The indices returned by the first form of `tf.where` can be\n",
      "           useful in `tf.sparse.SparseTensor` objects.\n",
      "        * `tf.gather_nd`, `tf.scatter_nd`, and related ops - Given the\n",
      "          list of indices returned from `tf.where` the `scatter` and `gather` family\n",
      "          of ops can be used fetch values or insert values at those indices.\n",
      "        * `tf.strings.length` - `tf.string` is not an allowed dtype for the\n",
      "          `condition`. Use the string length instead.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `tf.Tensor` of dtype bool, or any numeric dtype. `condition`\n",
      "            must have dtype `bool` when `x` and `y` are provided.\n",
      "          x: If provided, a Tensor which is of the same type as `y`, and has a shape\n",
      "            broadcastable with `condition` and `y`.\n",
      "          y: If provided, a Tensor which is of the same type as `x`, and has a shape\n",
      "            broadcastable with `condition` and `x`.\n",
      "          name: A name of the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          If `x` and `y` are provided:\n",
      "            A `Tensor` with the same type as `x` and `y`, and shape that\n",
      "            is broadcast from `condition`, `x`, and `y`.\n",
      "          Otherwise, a `Tensor` with shape `[tf.math.count_nonzero(condition),\n",
      "          tf.rank(condition)]`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None, or the shapes\n",
      "            are not all broadcastable.\n",
      "    \n",
      "    while_loop = while_loop_v2(cond, body, loop_vars, shape_invariants=None, parallel_iterations=10, back_prop=True, swap_memory=False, maximum_iterations=None, name=None)\n",
      "        Repeat `body` while the condition `cond` is true. (deprecated argument values)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(back_prop=False)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "        Instead of:\n",
      "        results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "        Use:\n",
      "        results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "        \n",
      "        Note: This op is automatically used in a `tf.function` to convert Python for-\n",
      "        and while- loops when the loop variable is a `tf.Tensor`, unless\n",
      "        `autograph=False` is explicitly specified in `tf.function` args. For example,\n",
      "        the following are equivalent:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def sumSquare(n):\n",
      "        ...   i, result = tf.constant(0), tf.constant(0)\n",
      "        ...   while i < n: # AutoGraph converts while-loop to tf.while_loop().\n",
      "        ...     result += i * i\n",
      "        ...     i += 1\n",
      "        ...   return result\n",
      "        >>> sumSquare(10).numpy()\n",
      "        285\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def sumSquare2(n):\n",
      "        ...   i, result = tf.constant(0), tf.constant(0)\n",
      "        ...   c = lambda i, _: tf.less(i, n)\n",
      "        ...   b = lambda i, result: (i + 1, result + i * i)\n",
      "        ...   return tf.while_loop(c, b, [i, result])[1]\n",
      "        >>> sumSquare2(10).numpy()\n",
      "        285\n",
      "        \n",
      "        For more information, see [tf.function and AutoGraph guide\n",
      "        ](https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "        \n",
      "        `cond` is a callable returning a boolean scalar tensor. `body` is a callable\n",
      "        returning a (possibly nested) tuple, namedtuple or list of tensors of the same\n",
      "        arity (length and structure) and types as `loop_vars`. `loop_vars` is a\n",
      "        (possibly nested) tuple, namedtuple or list of tensors that is passed to both\n",
      "        `cond` and `body`. `cond` and `body` both take as many arguments as there are\n",
      "        `loop_vars`.\n",
      "        \n",
      "        In addition to regular Tensors or IndexedSlices, the body may accept and\n",
      "        return TensorArray objects.  The flows of the TensorArray objects will\n",
      "        be appropriately forwarded between loops and during gradient calculations.\n",
      "        \n",
      "        Note that `while_loop` calls `cond` and `body` *exactly once* (inside the\n",
      "        call to `while_loop`, and not at all during `Session.run()`). `while_loop`\n",
      "        stitches together the graph fragments created during the `cond` and `body`\n",
      "        calls with some additional graph nodes to create the graph flow that\n",
      "        repeats `body` until `cond` returns false.\n",
      "        \n",
      "        For correctness, `tf.while_loop()` strictly enforces shape invariants for\n",
      "        the loop variables. A shape invariant is a (possibly partial) shape that\n",
      "        is unchanged across the iterations of the loop. An error will be raised\n",
      "        if the shape of a loop variable after an iteration is determined to be more\n",
      "        general than or incompatible with its shape invariant. For example, a shape\n",
      "        of `[11, None]` is more general than a shape of `[11, 17]`, and `[11, 21]` is\n",
      "        not compatible with `[11, 17]`. By default (if the argument `shape_invariants`\n",
      "        is not specified), it is assumed that the initial shape of each tensor in\n",
      "        `loop_vars` is the same in every iteration. The `shape_invariants` argument\n",
      "        allows the caller to specify a less specific shape invariant for each loop\n",
      "        variable, which is needed if the shape varies between iterations. The\n",
      "        `tf.Tensor.set_shape`\n",
      "        function may also be used in the `body` function to indicate that\n",
      "        the output loop variable has a particular shape. The shape invariant for\n",
      "        SparseTensor and IndexedSlices are treated specially as follows:\n",
      "        \n",
      "        a) If a loop variable is a SparseTensor, the shape invariant must be\n",
      "        `TensorShape([r])` where `r` is the rank of the dense tensor represented\n",
      "        by the sparse tensor. It means the shapes of the three tensors of the\n",
      "        SparseTensor are `([None], [None, r], [r])`. NOTE: The shape invariant here\n",
      "        is the shape of the SparseTensor.dense_shape property. It must be the shape of\n",
      "        a vector.\n",
      "        \n",
      "        b) If a loop variable is an IndexedSlices, the shape invariant must be\n",
      "        a shape invariant of the values tensor of the IndexedSlices. It means\n",
      "        the shapes of the three tensors of the IndexedSlices are `(shape, [shape[0]],\n",
      "        [shape.ndims])`.\n",
      "        \n",
      "        `while_loop` implements non-strict semantics, enabling multiple iterations\n",
      "        to run in parallel. The maximum number of parallel iterations can be\n",
      "        controlled by `parallel_iterations`, which gives users some control over\n",
      "        memory consumption and execution order. For correct programs, `while_loop`\n",
      "        should return the same result for any `parallel_iterations > 0`.\n",
      "        \n",
      "        For training, TensorFlow stores the tensors that are produced in the\n",
      "        forward inference and are needed in back propagation. These tensors are a\n",
      "        main source of memory consumption and often cause OOM errors when training\n",
      "        on GPUs. When the flag swap_memory is true, we swap out these tensors from\n",
      "        GPU to CPU. This for example allows us to train RNN models with very long\n",
      "        sequences and large batches.\n",
      "        \n",
      "        Args:\n",
      "          cond: A callable that represents the termination condition of the loop.\n",
      "          body: A callable that represents the loop body.\n",
      "          loop_vars: A (possibly nested) tuple, namedtuple or list of numpy array,\n",
      "            `Tensor`, and `TensorArray` objects.\n",
      "          shape_invariants: The shape invariants for the loop variables.\n",
      "          parallel_iterations: The number of iterations allowed to run in parallel. It\n",
      "            must be a positive integer.\n",
      "          back_prop: (optional) Deprecated. False disables support for back\n",
      "            propagation. Prefer using `tf.stop_gradient` instead.\n",
      "          swap_memory: Whether GPU-CPU memory swap is enabled for this loop.\n",
      "          maximum_iterations: Optional maximum number of iterations of the while loop\n",
      "            to run.  If provided, the `cond` output is AND-ed with an additional\n",
      "            condition ensuring the number of iterations executed is no greater than\n",
      "            `maximum_iterations`.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          The output tensors for the loop variables after the loop. The return value\n",
      "            has the same structure as `loop_vars`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `cond` or `body` is not callable.\n",
      "          ValueError: if `loop_vars` is empty.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> i = tf.constant(0)\n",
      "        >>> c = lambda i: tf.less(i, 10)\n",
      "        >>> b = lambda i: (tf.add(i, 1), )\n",
      "        >>> r = tf.while_loop(c, b, [i])[0]\n",
      "        >>> r.numpy()\n",
      "        10\n",
      "        \n",
      "        Example with nesting and a namedtuple:\n",
      "        \n",
      "        >>> import collections\n",
      "        >>> Pair = collections.namedtuple('Pair', 'j, k')\n",
      "        >>> ijk_0 = (tf.constant(0), Pair(tf.constant(1), tf.constant(2)))\n",
      "        >>> c = lambda i, p: i < 10\n",
      "        >>> b = lambda i, p: (i + 1, Pair((p.j + p.k), (p.j - p.k)))\n",
      "        >>> ijk_final = tf.while_loop(c, b, ijk_0)[1]\n",
      "        >>> ijk_final[0].numpy(), ijk_final[1].numpy()\n",
      "        (32, 64)\n",
      "        \n",
      "        Example using shape_invariants:\n",
      "        \n",
      "        >>> i0 = tf.constant(0)\n",
      "        >>> m0 = tf.ones([2, 2])\n",
      "        >>> c = lambda i, m: i < 10\n",
      "        >>> b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
      "        >>> tf.while_loop(\n",
      "        ...     c, b, loop_vars=[i0, m0],\n",
      "        ...     shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])[1]\n",
      "        <tf.Tensor: shape=(2048, 2), dtype=float32, numpy=...>\n",
      "        \n",
      "        Example which demonstrates non-strict semantics: In the following\n",
      "        example, the final value of `counter` does not depend on `x`. So\n",
      "        the `while_loop` can increment the counter parallel to updates of `x`.\n",
      "        However, because the loop counter at one loop iteration depends\n",
      "        on the value at the previous iteration, the loop counter itself cannot\n",
      "        be incremented in parallel. Hence if we just want the final value of the\n",
      "        counter (which we print on the line `print(sess.run(i))`), then\n",
      "        `x` will never be incremented, but the counter will be updated on a\n",
      "        single thread. Conversely, if we want the value of the output (which we\n",
      "        print on the line `print(sess.run(out).shape)`), then the counter may be\n",
      "        incremented on its own thread, while `x` can be incremented in\n",
      "        parallel on a separate thread. In the extreme case, it is conceivable\n",
      "        that the thread incrementing the counter runs until completion before\n",
      "        `x` is incremented even a single time. The only thing that can never\n",
      "        happen is that the thread updating `x` can never get ahead of the\n",
      "        counter thread because the thread incrementing `x` depends on the value\n",
      "        of the counter.\n",
      "        \n",
      "        >>> with tf.compat.v1.Session() as sess:\n",
      "        ...   n = 10\n",
      "        ...   c = lambda i, x: i < n\n",
      "        ...   b = lambda i, x: (\n",
      "        ...       tf.compat.v1.Print(i + 1, [i], \"Updating i based on i == \"),\n",
      "        ...       # Let x depend on i\n",
      "        ...       tf.compat.v1.Print(x + i, [i], \"Updating x based on i == \"))\n",
      "        ...\n",
      "        ...   # Make x to be a big matrix so its updating thread would run slowly\n",
      "        ...   x = tf.zeros([1000, 100], dtype=tf.int32)\n",
      "        ...   counter = tf.constant(0)\n",
      "        ...   counter_out, x_out = tf.while_loop(c, b, (counter, x))\n",
      "        ...\n",
      "        ...   # The following line may increment the counter and x in parallel.\n",
      "        ...   # The counter thread may get ahead of the x thread, but not the\n",
      "        ...   # other way around. For example, the log may contain these messages:\n",
      "        ...   # ```\n",
      "        ...   # Updating i based on i == [9]\n",
      "        ...   # Updating x based on i == [3]\n",
      "        ...   # ```\n",
      "        ...   # meaning that the counter(i) thread is on iteration 9,\n",
      "        ...   # while the x thread is on iteration 3.\n",
      "        ...   print(sess.run(x_out).shape)\n",
      "        (1000, 100)\n",
      "    \n",
      "    zeros(shape, dtype=tf.float32, name=None)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros_like`, `tf.ones`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to zero.\n",
      "        \n",
      "        >>> tf.zeros([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[0, 0, 0, 0],\n",
      "               [0, 0, 0, 0],\n",
      "               [0, 0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or\n",
      "            a 1-D `Tensor` of type `int32`.\n",
      "          dtype: The DType of an element in the resulting `Tensor`.\n",
      "          name: Optional string. A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeros_like = zeros_like_v2(input, dtype=None, name=None)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros`.\n",
      "        \n",
      "        Given a single tensor or array-like object (`input`), this operation returns\n",
      "        a tensor of the same type and shape as `input` with all elements set to zero.\n",
      "        Optionally, you can use `dtype` to specify a new type for the returned tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "          >>> tf.zeros_like(tensor)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[0, 0, 0],\n",
      "                 [0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "          >>> tf.zeros_like(tensor, dtype=tf.float32)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "          array([[0., 0., 0.],\n",
      "                 [0., 0., 0.]], dtype=float32)>\n",
      "        \n",
      "          >>> tf.zeros_like([[1, 2, 3], [4, 5, 6]])\n",
      "          <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[0, 0, 0],\n",
      "                 [0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or array-like object.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float16`, `float32`,\n",
      "            `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,\n",
      "            `complex64`, `complex128`, `bool` or `string` (optional).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['AggregationMethod', 'Assert', 'CriticalSection', 'DType', ...\n",
      "    __compiler_version__ = 'MSVC 192930148'\n",
      "    __cxx11_abi_flag__ = 0\n",
      "    __cxx_version__ = 201703\n",
      "    __git_version__ = 'v2.13.0-rc2-7-g1cb1a030a62'\n",
      "    __monolithic_build__ = 0\n",
      "    bfloat16 = tf.bfloat16\n",
      "    bool = tf.bool\n",
      "    complex128 = tf.complex128\n",
      "    complex64 = tf.complex64\n",
      "    double = tf.float64\n",
      "    float16 = tf.float16\n",
      "    float32 = tf.float32\n",
      "    float64 = tf.float64\n",
      "    half = tf.float16\n",
      "    int16 = tf.int16\n",
      "    int32 = tf.int32\n",
      "    int64 = tf.int64\n",
      "    int8 = tf.int8\n",
      "    newaxis = None\n",
      "    qint16 = tf.qint16\n",
      "    qint32 = tf.qint32\n",
      "    qint8 = tf.qint8\n",
      "    quint16 = tf.quint16\n",
      "    quint8 = tf.quint8\n",
      "    resource = tf.resource\n",
      "    string = tf.string\n",
      "    uint16 = tf.uint16\n",
      "    uint32 = tf.uint32\n",
      "    uint64 = tf.uint64\n",
      "    uint8 = tf.uint8\n",
      "    variant = tf.variant\n",
      "\n",
      "VERSION\n",
      "    2.13.0\n",
      "\n",
      "FILE\n",
      "    c:\\users\\gabriel\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484ed96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c8bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60890a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bec7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning",
   "language": "python",
   "name": "deep_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
